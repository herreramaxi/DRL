import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm

from common import get_device_name, make_env_masking_enabled, parse_arguments_ae
import gymnasium as gym
from ChessGame.ChessEnv import register_chess_env

# ─── Settings ─────────────────────────────────────
# N_SAMPLES   = 50_000
BATCH_SIZE  = 512
AE_LR       = 1e-3
# AE_EPOCHS   = 20
INPUT_DIM   = 5 * 5
HIDDEN_DIM  = 64
LATENT_DIM  = 8

# SAVE_BOARDS = "board_seqs.npy" # I will reuse the same file generated by ae_pretrain.py
# SAVE_AE     = "ae_rnn_pretrained.pth"
# ──────────────────────────────────────────────────

SEQ_LEN = 8
class SimpleLSTMAutoencoder(nn.Module):
    def __init__(self, seq_len=SEQ_LEN, board_size=5, hidden_dim=64, latent_dim=8):
        super().__init__()

        self.seq_len = seq_len
        self.input_dim = board_size * board_size  # 25
        self.hidden_dim = hidden_dim
        self.latent_dim = latent_dim
        # Encoder
        self.encoder_lstm = nn.LSTM(
            input_size=self.input_dim,
            hidden_size=hidden_dim,
            batch_first=True,
        )
        self.to_latent = nn.Linear(hidden_dim, latent_dim)

        # Decoder ← mirror encoder hidden_dim
        self.from_latent  = nn.Linear(latent_dim, hidden_dim)
        self.decoder_lstm = nn.LSTM(
            input_size=hidden_dim,
            hidden_size=hidden_dim,
            batch_first=True,
        )
        self.out_proj = nn.Linear(hidden_dim, self.input_dim)

    def forward(self, x_seq):
        B = x_seq.size(0)
        x_flat = x_seq.view(B, self.seq_len, -1)        # (B,seq_len,25)

        # Encode
        _, (h_n, _) = self.encoder_lstm(x_flat)
        h_last = h_n[-1]                                # (B,64)
        z      = self.to_latent(h_last)                 # (B,8)

        # Decode
        h0     = self.from_latent(z).unsqueeze(0)       # (1,B,64)
        c0     = torch.zeros_like(h0)
        dec_in = h0.transpose(0,1).repeat(1, self.seq_len, 1)  # (B,seq_len,64)
        dec_out, _ = self.decoder_lstm(dec_in, (h0, c0))      # (B,seq_len,64)
        flat_recon = self.out_proj(dec_out)                  # (B,seq_len,25)
        recon = flat_recon.view(B, self.seq_len, 5, 5)       # (B,seq_len,5,5)

        return z, recon

    def encode_single(self, board):
        # board: (batch, 5, 5)
        B = board.shape[0]
        flat = board.view(B, 1, 25)      # (batch, 1, 25)
        _, (h_n, _) = self.encoder_lstm(flat)
        z = self.to_latent(h_n[-1])      # (batch, latent_dim)
        return z

register_chess_env()

def collect_sequences(args):
    seqs = []
    env = make_env_masking_enabled(True)    
    total_sequences = args.n_samples//SEQ_LEN
    pbar = tqdm(total=total_sequences, desc="Collecting sequences")

    while len(seqs) < total_sequences:
        buf = []
        obs, _ = env.reset()
        
        # collect SEQ_LEN boards in a row
        for _ in range(SEQ_LEN):
            legal = list(env.unwrapped.get_legal_moves())
            a = int(np.random.choice(legal))
            obs, _, terminated, truncated, _ = env.step(a)
            buf.append(obs["board"].copy())
            if terminated or truncated:
                obs, _ = env.reset()

        seqs.append(np.stack(buf, axis=0))  # shape (SEQ_LEN,5,5)
        pbar.update(1)

    pbar.close()
    arr = np.stack(seqs).astype(np.float32)  # shape (n_seq, SEQ_LEN,5,5)
    np.save(args.board_file_path, arr)
    print(f"Saved {arr.shape[0]} sequences → {args.board_file_path}")

def pretrain_ae(args):
    # 1) load & normalize boards
    boards = np.load(args.board_file_path)   
    boards = boards.astype(np.float32)
    boards = (boards + 60000.0) / 120000.0

    # 2) dataset & loader
    loader = DataLoader(torch.from_numpy(boards), batch_size=BATCH_SIZE, shuffle=True)
    device = get_device_name()
    ae = SimpleLSTMAutoencoder().to(device)
    opt = optim.Adam(ae.parameters(), lr=AE_LR)
    loss_fn = nn.MSELoss()

    for epoch in range(1, args.n_epochs + 1):
        tot=0
        for seqs in loader:    # seqs: (B,SEQ_LEN,5,5)
            seqs = seqs.to(device)
            z, recon = ae(seqs)
            loss = loss_fn(recon, seqs)
            opt.zero_grad(); loss.backward(); opt.step()
            tot += loss.item()*seqs.size(0)
        print(f"Epoch {epoch}: avg loss {tot/len(loader.dataset):.6f}")

    torch.save(ae.state_dict(), args.weights_file_path)
    print(f"Saved pretrained AE → {args.weights_file_path}")

if __name__ == "__main__":
    args = parse_arguments_ae(50_000,"boards/board_seqs.npy","weights/ae_rnn_pretrained.pth")   

    if args.force_clean == "True":
        if os.path.exists(args.weights_file_path):
            os.remove(args.weights_file_path)
            print(f"Deleted {args.weights_file_path}")
        if os.path.exists(args.board_file_path):
            os.remove(args.board_file_path)
            print(f"Deleted {args.board_file_path}")

    if not os.path.exists(args.board_file_path):
        print("Generating boards for autoencoder")
        collect_sequences(args)
        print("Training autoencoder")
        pretrain_ae(args)
    else:
        print("Skipping autoencoder training, weights already exists")