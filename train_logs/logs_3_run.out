nohup: ignoring input
[0;37mParsed arguments:[0m
[0;37m   n_samples: 100000[0m
[0;37m   board_file_path: boards/boards.npy[0m
[0;37m   weights_file_path: weights/ae_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   n_samples: 100000[0m
[0;37m   board_file_path: boards/board_seqs.npy[0m
[0;37m   weights_file_path: weights/ae_rnn_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 1_PPO[0m
[0;37m   model_path: models/1_PPO_20250804_235511.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '1_PPO' agent using device 'cuda' and '16' parallel environments...
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
MultiInputActorCriticPolicy              --
â”œâ”€CombinedExtractor: 1-1                 --
â”‚    â””â”€ModuleDict: 2-1                   --
â”‚    â”‚    â””â”€Flatten: 3-1                 --
â”‚    â”‚    â””â”€Flatten: 3-2                 --
â”œâ”€CombinedExtractor: 1-2                 --
â”‚    â””â”€ModuleDict: 2-2                   --
â”‚    â”‚    â””â”€Flatten: 3-3                 --
â”‚    â”‚    â””â”€Flatten: 3-4                 --
â”œâ”€CombinedExtractor: 1-3                 --
â”‚    â””â”€ModuleDict: 2-3                   --
â”‚    â”‚    â””â”€Flatten: 3-5                 --
â”‚    â”‚    â””â”€Flatten: 3-6                 --
â”œâ”€MlpExtractor: 1-4                      --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-7                  61,952
â”‚    â”‚    â””â”€Tanh: 3-8                    --
â”‚    â”‚    â””â”€Linear: 3-9                  4,160
â”‚    â”‚    â””â”€Tanh: 3-10                   --
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-11                 61,952
â”‚    â”‚    â””â”€Tanh: 3-12                   --
â”‚    â”‚    â””â”€Linear: 3-13                 4,160
â”‚    â”‚    â””â”€Tanh: 3-14                   --
â”œâ”€Linear: 1-5                            61,230
â”œâ”€Linear: 1-6                            65
=================================================================
Total params: 193,519
Trainable params: 193,519
Non-trainable params: 0
=================================================================
Logging to ./chess_logs/1_PPO_1
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 1        |
|    invalid_moves   | 59501    |
|    losses          | 1        |
|    valid_moves     | 499      |
|    win_rate        | 0        |
|    wins            | 0        |
| rollout/           |          |
|    ep_len_mean     | 100      |
|    ep_rew_mean     | -9.94    |
| time/              |          |
|    fps             | 5770     |
|    iterations      | 1        |
|    time_elapsed    | 11       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 3             |
|    invalid_moves        | 128873        |
|    losses               | 3             |
|    valid_moves          | 1127          |
|    win_rate             | 0             |
|    wins                 | 0             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 5410          |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 0.00054492307 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.85         |
|    explained_variance   | -0.00208      |
|    learning_rate        | 0.0001        |
|    loss                 | -0.0705       |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.00124      |
|    value_loss           | 0.788         |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 4             |
|    invalid_moves        | 188328        |
|    losses               | 4             |
|    valid_moves          | 1672          |
|    win_rate             | 0             |
|    wins                 | 0             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.95         |
| time/                   |               |
|    fps                  | 5381          |
|    iterations           | 3             |
|    time_elapsed         | 36            |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00024153691 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.85         |
|    explained_variance   | 0.00149       |
|    learning_rate        | 0.0001        |
|    loss                 | 0.692         |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.000796     |
|    value_loss           | 0.85          |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 5             |
|    invalid_moves        | 257553        |
|    losses               | 4             |
|    valid_moves          | 2447          |
|    win_rate             | 0.2           |
|    wins                 | 1             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.94         |
| time/                   |               |
|    fps                  | 5331          |
|    iterations           | 4             |
|    time_elapsed         | 49            |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 0.00077163463 |
|    clip_fraction        | 0.00062       |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.85         |
|    explained_variance   | -0.0047       |
|    learning_rate        | 0.0001        |
|    loss                 | -0.0737       |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.00212      |
|    value_loss           | 0.432         |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 7             |
|    invalid_moves        | 316772        |
|    losses               | 5             |
|    valid_moves          | 3228          |
|    win_rate             | 0.286         |
|    wins                 | 2             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.98         |
| time/                   |               |
|    fps                  | 5276          |
|    iterations           | 5             |
|    time_elapsed         | 62            |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 0.00077075756 |
|    clip_fraction        | 0.000462      |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.84         |
|    explained_variance   | -0.00508      |
|    learning_rate        | 0.0001        |
|    loss                 | 0.712         |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.00193      |
|    value_loss           | 0.432         |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 8            |
|    invalid_moves        | 385805       |
|    losses               | 5            |
|    valid_moves          | 4195         |
|    win_rate             | 0.375        |
|    wins                 | 3            |
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -9.92        |
| time/                   |              |
|    fps                  | 5240         |
|    iterations           | 6            |
|    time_elapsed         | 75           |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0005637529 |
|    clip_fraction        | 0.00117      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.84        |
|    explained_variance   | -0.00238     |
|    learning_rate        | 0.0001       |
|    loss                 | 0.00121      |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.0013      |
|    value_loss           | 0.866        |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 9            |
|    invalid_moves        | 444779       |
|    losses               | 6            |
|    valid_moves          | 5221         |
|    win_rate             | 0.333        |
|    wins                 | 3            |
| rollout/                |              |
|    ep_len_mean          | 99.8         |
|    ep_rew_mean          | -11.5        |
| time/                   |              |
|    fps                  | 5202         |
|    iterations           | 7            |
|    time_elapsed         | 88           |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0016569346 |
|    clip_fraction        | 0.00607      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.84        |
|    explained_variance   | -0.00561     |
|    learning_rate        | 0.0001       |
|    loss                 | 0.794        |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00285     |
|    value_loss           | 0.438        |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13           |
|    invalid_moves        | 513397       |
|    losses               | 8            |
|    valid_moves          | 6603         |
|    win_rate             | 0.385        |
|    wins                 | 5            |
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -9.93        |
| time/                   |              |
|    fps                  | 5167         |
|    iterations           | 8            |
|    time_elapsed         | 101          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0011208165 |
|    clip_fraction        | 0.00197      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.83        |
|    explained_variance   | -0.00236     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.56         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00187     |
|    value_loss           | 0.86         |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 14            |
|    invalid_moves        | 572204        |
|    losses               | 8             |
|    valid_moves          | 7796          |
|    win_rate             | 0.429         |
|    wins                 | 6             |
| rollout/                |               |
|    ep_len_mean          | 99.6          |
|    ep_rew_mean          | -6.66         |
| time/                   |               |
|    fps                  | 5140          |
|    iterations           | 9             |
|    time_elapsed         | 114           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 0.00050726824 |
|    clip_fraction        | 0.0017        |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.83         |
|    explained_variance   | -0.000268     |
|    learning_rate        | 0.0001        |
|    loss                 | -0.0703       |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.00139      |
|    value_loss           | 1.29          |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 20            |
|    invalid_moves        | 640681        |
|    losses               | 11            |
|    valid_moves          | 9319          |
|    win_rate             | 0.45          |
|    wins                 | 9             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.85         |
| time/                   |               |
|    fps                  | 5108          |
|    iterations           | 10            |
|    time_elapsed         | 128           |
|    total_timesteps      | 655360        |
| train/                  |               |
|    approx_kl            | 0.00067382574 |
|    clip_fraction        | 0.00215       |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.83         |
|    explained_variance   | -0.0064       |
|    learning_rate        | 0.0001        |
|    loss                 | 0.72          |
|    n_updates            | 90            |
|    policy_gradient_loss | -0.00142      |
|    value_loss           | 1.3           |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 23           |
|    invalid_moves        | 709124       |
|    losses               | 12           |
|    valid_moves          | 10876        |
|    win_rate             | 0.478        |
|    wins                 | 11           |
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -9.96        |
| time/                   |              |
|    fps                  | 5074         |
|    iterations           | 11           |
|    time_elapsed         | 142          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0003469891 |
|    clip_fraction        | 0.000426     |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.82        |
|    explained_variance   | -0.00416     |
|    learning_rate        | 0.0001       |
|    loss                 | 0.774        |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00126     |
|    value_loss           | 1.72         |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 26           |
|    invalid_moves        | 767758       |
|    losses               | 14           |
|    valid_moves          | 12242        |
|    win_rate             | 0.462        |
|    wins                 | 12           |
| rollout/                |              |
|    ep_len_mean          | 99.8         |
|    ep_rew_mean          | -8.3         |
| time/                   |              |
|    fps                  | 5052         |
|    iterations           | 12           |
|    time_elapsed         | 155          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0007181646 |
|    clip_fraction        | 0.00482      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.82        |
|    explained_variance   | -0.000698    |
|    learning_rate        | 0.0001       |
|    loss                 | 1.59         |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00139     |
|    value_loss           | 1.3          |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 34            |
|    invalid_moves        | 836144        |
|    losses               | 19            |
|    valid_moves          | 13856         |
|    win_rate             | 0.441         |
|    wins                 | 15            |
| rollout/                |               |
|    ep_len_mean          | 99.6          |
|    ep_rew_mean          | -9.9          |
| time/                   |               |
|    fps                  | 5035          |
|    iterations           | 13            |
|    time_elapsed         | 169           |
|    total_timesteps      | 851968        |
| train/                  |               |
|    approx_kl            | 0.00068140775 |
|    clip_fraction        | 0.00428       |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.82         |
|    explained_variance   | -0.00197      |
|    learning_rate        | 0.0001        |
|    loss                 | 0.00733       |
|    n_updates            | 120           |
|    policy_gradient_loss | -0.00135      |
|    value_loss           | 1.72          |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 39           |
|    invalid_moves        | 894890       |
|    losses               | 23           |
|    valid_moves          | 15110        |
|    win_rate             | 0.41         |
|    wins                 | 16           |
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -11.5        |
| time/                   |              |
|    fps                  | 5018         |
|    iterations           | 14           |
|    time_elapsed         | 182          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0006146218 |
|    clip_fraction        | 0.00315      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.82        |
|    explained_variance   | 4.55e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.7          |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00145     |
|    value_loss           | 3.01         |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 43            |
|    invalid_moves        | 963468        |
|    losses               | 24            |
|    valid_moves          | 16532         |
|    win_rate             | 0.442         |
|    wins                 | 19            |
| rollout/                |               |
|    ep_len_mean          | 99.9          |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 5002          |
|    iterations           | 15            |
|    time_elapsed         | 196           |
|    total_timesteps      | 983040        |
| train/                  |               |
|    approx_kl            | 0.00076813693 |
|    clip_fraction        | 0.00478       |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.82         |
|    explained_variance   | -0.000612     |
|    learning_rate        | 0.0001        |
|    loss                 | 2.36          |
|    n_updates            | 140           |
|    policy_gradient_loss | -0.00149      |
|    value_loss           | 2.15          |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 47            |
|    invalid_moves        | 1022169       |
|    losses               | 25            |
|    valid_moves          | 17831         |
|    win_rate             | 0.468         |
|    wins                 | 22            |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -8.24         |
| time/                   |               |
|    fps                  | 4981          |
|    iterations           | 16            |
|    time_elapsed         | 210           |
|    total_timesteps      | 1048576       |
| train/                  |               |
|    approx_kl            | 0.00071183033 |
|    clip_fraction        | 0.00427       |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.81         |
|    explained_variance   | 0.000491      |
|    learning_rate        | 0.0001        |
|    loss                 | 0.711         |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.00141      |
|    value_loss           | 1.72          |
-------------------------------------------
[0;32m-> Model saved on models/1_PPO_20250804_235511.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =False, original_step=False
Evaluating 1_PPO agent...
[0;36m-> Mean Reward: -10.00 +/- 0.00[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 2_MaskablePPO_Baseline[0m
[0;37m   model_path: models/2_MaskablePPO_Baseline_20250804_235858.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '2_MaskablePPO_Baseline' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
Active env processes: 16
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
MaskableMultiInputActorCriticPolicy      --
â”œâ”€CombinedExtractor: 1-1                 --
â”‚    â””â”€ModuleDict: 2-1                   --
â”‚    â”‚    â””â”€Flatten: 3-1                 --
â”œâ”€CombinedExtractor: 1-2                 --
â”‚    â””â”€ModuleDict: 2-2                   --
â”‚    â”‚    â””â”€Flatten: 3-2                 --
â”œâ”€CombinedExtractor: 1-3                 --
â”‚    â””â”€ModuleDict: 2-3                   --
â”‚    â”‚    â””â”€Flatten: 3-3                 --
â”œâ”€MlpExtractor: 1-4                      --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-4                  1,664
â”‚    â”‚    â””â”€Tanh: 3-5                    --
â”‚    â”‚    â””â”€Linear: 3-6                  4,160
â”‚    â”‚    â””â”€Tanh: 3-7                    --
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-8                  1,664
â”‚    â”‚    â””â”€Tanh: 3-9                    --
â”‚    â”‚    â””â”€Linear: 3-10                 4,160
â”‚    â”‚    â””â”€Tanh: 3-11                   --
â”œâ”€Linear: 1-5                            61,230
â”œâ”€Linear: 1-6                            65
=================================================================
Total params: 72,943
Trainable params: 72,943
Non-trainable params: 0
=================================================================
Logging to ./chess_logs/2_MaskablePPO_Baseline_1
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3092     |
|    invalid_moves   | 0        |
|    losses          | 1494     |
|    valid_moves     | 60000    |
|    win_rate        | 0.517    |
|    wins            | 1598     |
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 18.3     |
| time/              |          |
|    fps             | 2448     |
|    iterations      | 1        |
|    time_elapsed    | 26       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6747          |
|    invalid_moves        | 0             |
|    losses               | 3195          |
|    valid_moves          | 130000        |
|    win_rate             | 0.526         |
|    wins                 | 3552          |
| rollout/                |               |
|    ep_len_mean          | 19.4          |
|    ep_rew_mean          | 19.6          |
| time/                   |               |
|    fps                  | 2357          |
|    iterations           | 2             |
|    time_elapsed         | 55            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 0.00013176278 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.000432      |
|    learning_rate        | 0.0001        |
|    loss                 | 720           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.00204      |
|    value_loss           | 1.46e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9908          |
|    invalid_moves        | 0             |
|    losses               | 4667          |
|    valid_moves          | 190000        |
|    win_rate             | 0.529         |
|    wins                 | 5241          |
| rollout/                |               |
|    ep_len_mean          | 16.7          |
|    ep_rew_mean          | 19            |
| time/                   |               |
|    fps                  | 2333          |
|    iterations           | 3             |
|    time_elapsed         | 84            |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00014021902 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.00155       |
|    learning_rate        | 0.0001        |
|    loss                 | 730           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00211      |
|    value_loss           | 1.46e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13601        |
|    invalid_moves        | 0            |
|    losses               | 6379         |
|    valid_moves          | 260000       |
|    win_rate             | 0.531        |
|    wins                 | 7222         |
| rollout/                |              |
|    ep_len_mean          | 19.1         |
|    ep_rew_mean          | 34.5         |
| time/                   |              |
|    fps                  | 2317         |
|    iterations           | 4            |
|    time_elapsed         | 113          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0001637664 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.00231      |
|    learning_rate        | 0.0001       |
|    loss                 | 739          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00249     |
|    value_loss           | 1.49e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 16836         |
|    invalid_moves        | 0             |
|    losses               | 7791          |
|    valid_moves          | 320000        |
|    win_rate             | 0.537         |
|    wins                 | 9045          |
| rollout/                |               |
|    ep_len_mean          | 18.7          |
|    ep_rew_mean          | 31.1          |
| time/                   |               |
|    fps                  | 2309          |
|    iterations           | 5             |
|    time_elapsed         | 141           |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 0.00016400809 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.00328       |
|    learning_rate        | 0.0001        |
|    loss                 | 718           |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.00266      |
|    value_loss           | 1.47e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 20582         |
|    invalid_moves        | 0             |
|    losses               | 9387          |
|    valid_moves          | 390000        |
|    win_rate             | 0.544         |
|    wins                 | 11195         |
| rollout/                |               |
|    ep_len_mean          | 19.6          |
|    ep_rew_mean          | 48.5          |
| time/                   |               |
|    fps                  | 2304          |
|    iterations           | 6             |
|    time_elapsed         | 170           |
|    total_timesteps      | 393216        |
| train/                  |               |
|    approx_kl            | 0.00012659786 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00373       |
|    learning_rate        | 0.0001        |
|    loss                 | 757           |
|    n_updates            | 50            |
|    policy_gradient_loss | -0.00232      |
|    value_loss           | 1.52e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 23846         |
|    invalid_moves        | 0             |
|    losses               | 10729         |
|    valid_moves          | 450000        |
|    win_rate             | 0.55          |
|    wins                 | 13117         |
| rollout/                |               |
|    ep_len_mean          | 15.9          |
|    ep_rew_mean          | 4.21          |
| time/                   |               |
|    fps                  | 2299          |
|    iterations           | 7             |
|    time_elapsed         | 199           |
|    total_timesteps      | 458752        |
| train/                  |               |
|    approx_kl            | 0.00018743091 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00403       |
|    learning_rate        | 0.0001        |
|    loss                 | 737           |
|    n_updates            | 60            |
|    policy_gradient_loss | -0.0029       |
|    value_loss           | 1.49e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 27677         |
|    invalid_moves        | 0             |
|    losses               | 12220         |
|    valid_moves          | 520000        |
|    win_rate             | 0.558         |
|    wins                 | 15457         |
| rollout/                |               |
|    ep_len_mean          | 15.5          |
|    ep_rew_mean          | 59            |
| time/                   |               |
|    fps                  | 2295          |
|    iterations           | 8             |
|    time_elapsed         | 228           |
|    total_timesteps      | 524288        |
| train/                  |               |
|    approx_kl            | 0.00019267034 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.00469       |
|    learning_rate        | 0.0001        |
|    loss                 | 779           |
|    n_updates            | 70            |
|    policy_gradient_loss | -0.0033       |
|    value_loss           | 1.54e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 30987         |
|    invalid_moves        | 0             |
|    losses               | 13498         |
|    valid_moves          | 580000        |
|    win_rate             | 0.564         |
|    wins                 | 17489         |
| rollout/                |               |
|    ep_len_mean          | 20            |
|    ep_rew_mean          | 39.8          |
| time/                   |               |
|    fps                  | 2294          |
|    iterations           | 9             |
|    time_elapsed         | 257           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 0.00019052712 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.00554       |
|    learning_rate        | 0.0001        |
|    loss                 | 734           |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.00318      |
|    value_loss           | 1.53e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 35026         |
|    invalid_moves        | 0             |
|    losses               | 14980         |
|    valid_moves          | 650000        |
|    win_rate             | 0.572         |
|    wins                 | 20046         |
| rollout/                |               |
|    ep_len_mean          | 16.9          |
|    ep_rew_mean          | 66.7          |
| time/                   |               |
|    fps                  | 2290          |
|    iterations           | 10            |
|    time_elapsed         | 286           |
|    total_timesteps      | 655360        |
| train/                  |               |
|    approx_kl            | 0.00027753648 |
|    clip_fraction        | 3.05e-06      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.56         |
|    explained_variance   | 0.00541       |
|    learning_rate        | 0.0001        |
|    loss                 | 743           |
|    n_updates            | 90            |
|    policy_gradient_loss | -0.00385      |
|    value_loss           | 1.54e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 39113         |
|    invalid_moves        | 0             |
|    losses               | 16375         |
|    valid_moves          | 720000        |
|    win_rate             | 0.581         |
|    wins                 | 22738         |
| rollout/                |               |
|    ep_len_mean          | 17.7          |
|    ep_rew_mean          | 48.1          |
| time/                   |               |
|    fps                  | 2285          |
|    iterations           | 11            |
|    time_elapsed         | 315           |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 0.00019183439 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.55         |
|    explained_variance   | 0.00525       |
|    learning_rate        | 0.0001        |
|    loss                 | 818           |
|    n_updates            | 100           |
|    policy_gradient_loss | -0.00375      |
|    value_loss           | 1.62e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 42669         |
|    invalid_moves        | 0             |
|    losses               | 17548         |
|    valid_moves          | 780000        |
|    win_rate             | 0.589         |
|    wins                 | 25121         |
| rollout/                |               |
|    ep_len_mean          | 17.5          |
|    ep_rew_mean          | 46.5          |
| time/                   |               |
|    fps                  | 2281          |
|    iterations           | 12            |
|    time_elapsed         | 344           |
|    total_timesteps      | 786432        |
| train/                  |               |
|    approx_kl            | 0.00025234217 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.56         |
|    explained_variance   | 0.00581       |
|    learning_rate        | 0.0001        |
|    loss                 | 815           |
|    n_updates            | 110           |
|    policy_gradient_loss | -0.00383      |
|    value_loss           | 1.63e+03      |
-------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 47057       |
|    invalid_moves        | 0           |
|    losses               | 18943       |
|    valid_moves          | 850000      |
|    win_rate             | 0.597       |
|    wins                 | 28114       |
| rollout/                |             |
|    ep_len_mean          | 16          |
|    ep_rew_mean          | 85.6        |
| time/                   |             |
|    fps                  | 2276        |
|    iterations           | 13          |
|    time_elapsed         | 374         |
|    total_timesteps      | 851968      |
| train/                  |             |
|    approx_kl            | 0.000517748 |
|    clip_fraction        | 0.000168    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.53       |
|    explained_variance   | 0.0069      |
|    learning_rate        | 0.0001      |
|    loss                 | 819         |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00586    |
|    value_loss           | 1.65e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 50898        |
|    invalid_moves        | 0            |
|    losses               | 20120        |
|    valid_moves          | 910000       |
|    win_rate             | 0.605        |
|    wins                 | 30778        |
| rollout/                |              |
|    ep_len_mean          | 14.2         |
|    ep_rew_mean          | 96.2         |
| time/                   |              |
|    fps                  | 2271         |
|    iterations           | 14           |
|    time_elapsed         | 403          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0005160594 |
|    clip_fraction        | 3.05e-06     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.00802      |
|    learning_rate        | 0.0001       |
|    loss                 | 865          |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00567     |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 55561        |
|    invalid_moves        | 0            |
|    losses               | 21376        |
|    valid_moves          | 980000       |
|    win_rate             | 0.615        |
|    wins                 | 34185        |
| rollout/                |              |
|    ep_len_mean          | 14           |
|    ep_rew_mean          | 93           |
| time/                   |              |
|    fps                  | 2267         |
|    iterations           | 15           |
|    time_elapsed         | 433          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0003415985 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.00845      |
|    learning_rate        | 0.0001       |
|    loss                 | 890          |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00512     |
|    value_loss           | 1.77e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 59651         |
|    invalid_moves        | 0             |
|    losses               | 22431         |
|    valid_moves          | 1040000       |
|    win_rate             | 0.624         |
|    wins                 | 37220         |
| rollout/                |               |
|    ep_len_mean          | 13.2          |
|    ep_rew_mean          | 81.3          |
| time/                   |               |
|    fps                  | 2262          |
|    iterations           | 16            |
|    time_elapsed         | 463           |
|    total_timesteps      | 1048576       |
| train/                  |               |
|    approx_kl            | 0.00024546278 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.5          |
|    explained_variance   | 0.00828       |
|    learning_rate        | 0.0001        |
|    loss                 | 931           |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.00412      |
|    value_loss           | 1.83e+03      |
-------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/2_MaskablePPO_Baseline_20250804_235858.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 2_MaskablePPO_Baseline agent...
[0;36m-> Mean Reward: 154.93 +/- 44.80[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 3_MaskableRecurrentPPO[0m
[0;37m   model_path: models/3_MaskableRecurrentPPO_20250805_000654.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '3_MaskableRecurrentPPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableRecurrentMultiInputActorCriticPolicy  --
â”œâ”€CombinedExtractor: 1-1                      --
â”‚    â””â”€ModuleDict: 2-1                        --
â”‚    â”‚    â””â”€Flatten: 3-1                      --
â”œâ”€CombinedExtractor: 1-2                      --
â”‚    â””â”€ModuleDict: 2-2                        --
â”‚    â”‚    â””â”€Flatten: 3-2                      --
â”œâ”€CombinedExtractor: 1-3                      --
â”‚    â””â”€ModuleDict: 2-3                        --
â”‚    â”‚    â””â”€Flatten: 3-3                      --
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-4                        --
â”‚    â”‚    â””â”€Linear: 3-4                       16,448
â”‚    â”‚    â””â”€Tanh: 3-5                         --
â”‚    â”‚    â””â”€Linear: 3-6                       4,160
â”‚    â”‚    â””â”€Tanh: 3-7                         --
â”‚    â””â”€Sequential: 2-5                        --
â”‚    â”‚    â””â”€Linear: 3-8                       16,448
â”‚    â”‚    â””â”€Tanh: 3-9                         --
â”‚    â”‚    â””â”€Linear: 3-10                      4,160
â”‚    â”‚    â””â”€Tanh: 3-11                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
â”œâ”€LSTM: 1-7                                   289,792
â”œâ”€LSTM: 1-8                                   289,792
======================================================================
Total params: 682,095
Trainable params: 682,095
Non-trainable params: 0
======================================================================
Logging to ./chess_logs/3_MaskableRecurrentPPO_1
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3111     |
|    invalid_moves   | 0        |
|    losses          | 1542     |
|    valid_moves     | 60000    |
|    win_rate        | 0.504    |
|    wins            | 1569     |
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | -0.189   |
| time/              |          |
|    fps             | 2100     |
|    iterations      | 1        |
|    time_elapsed    | 31       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6667          |
|    invalid_moves        | 0             |
|    losses               | 3296          |
|    valid_moves          | 130000        |
|    win_rate             | 0.506         |
|    wins                 | 3371          |
| rollout/                |               |
|    ep_len_mean          | 20.9          |
|    ep_rew_mean          | -16           |
| time/                   |               |
|    fps                  | 1522          |
|    iterations           | 2             |
|    time_elapsed         | 86            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 1.2008094e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.6          |
|    explained_variance   | -5.94e-05     |
|    learning_rate        | 0.0001        |
|    loss                 | 705           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000479     |
|    value_loss           | 1.46e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9753          |
|    invalid_moves        | 0             |
|    losses               | 4792          |
|    valid_moves          | 190000        |
|    win_rate             | 0.509         |
|    wins                 | 4961          |
| rollout/                |               |
|    ep_len_mean          | 19.3          |
|    ep_rew_mean          | 10.7          |
| time/                   |               |
|    fps                  | 1396          |
|    iterations           | 3             |
|    time_elapsed         | 140           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 1.5382404e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.00294       |
|    learning_rate        | 0.0001        |
|    loss                 | 708           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.000528     |
|    value_loss           | 1.42e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 13322         |
|    invalid_moves        | 0             |
|    losses               | 6526          |
|    valid_moves          | 260000        |
|    win_rate             | 0.51          |
|    wins                 | 6796          |
| rollout/                |               |
|    ep_len_mean          | 18.1          |
|    ep_rew_mean          | 7.04          |
| time/                   |               |
|    fps                  | 1349          |
|    iterations           | 4             |
|    time_elapsed         | 194           |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 2.3465367e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00464       |
|    learning_rate        | 0.0001        |
|    loss                 | 716           |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.000696     |
|    value_loss           | 1.45e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 16378         |
|    invalid_moves        | 0             |
|    losses               | 7946          |
|    valid_moves          | 320000        |
|    win_rate             | 0.515         |
|    wins                 | 8432          |
| rollout/                |               |
|    ep_len_mean          | 20.6          |
|    ep_rew_mean          | 11.1          |
| time/                   |               |
|    fps                  | 1314          |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 2.2519349e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00624       |
|    learning_rate        | 0.0001        |
|    loss                 | 704           |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.000675     |
|    value_loss           | 1.43e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 20006        |
|    invalid_moves        | 0            |
|    losses               | 9603         |
|    valid_moves          | 390000       |
|    win_rate             | 0.52         |
|    wins                 | 10403        |
| rollout/                |              |
|    ep_len_mean          | 20.7         |
|    ep_rew_mean          | 20.7         |
| time/                   |              |
|    fps                  | 1293         |
|    iterations           | 6            |
|    time_elapsed         | 304          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 3.649634e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.00786      |
|    learning_rate        | 0.0001       |
|    loss                 | 722          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.000926    |
|    value_loss           | 1.42e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 23143         |
|    invalid_moves        | 0             |
|    losses               | 11118         |
|    valid_moves          | 450000        |
|    win_rate             | 0.52          |
|    wins                 | 12025         |
| rollout/                |               |
|    ep_len_mean          | 20.1          |
|    ep_rew_mean          | 21.8          |
| time/                   |               |
|    fps                  | 1279          |
|    iterations           | 7             |
|    time_elapsed         | 358           |
|    total_timesteps      | 458752        |
| train/                  |               |
|    approx_kl            | 2.5174615e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.00847       |
|    learning_rate        | 0.0001        |
|    loss                 | 735           |
|    n_updates            | 60            |
|    policy_gradient_loss | -0.000814     |
|    value_loss           | 1.44e+03      |
-------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 26774       |
|    invalid_moves        | 0           |
|    losses               | 12790       |
|    valid_moves          | 520000      |
|    win_rate             | 0.522       |
|    wins                 | 13984       |
| rollout/                |             |
|    ep_len_mean          | 18.4        |
|    ep_rew_mean          | -0.861      |
| time/                   |             |
|    fps                  | 1268        |
|    iterations           | 8           |
|    time_elapsed         | 413         |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 2.38839e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.00819     |
|    learning_rate        | 0.0001      |
|    loss                 | 730         |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.000776   |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 29923         |
|    invalid_moves        | 0             |
|    losses               | 14221         |
|    valid_moves          | 580000        |
|    win_rate             | 0.525         |
|    wins                 | 15702         |
| rollout/                |               |
|    ep_len_mean          | 18.7          |
|    ep_rew_mean          | 28.1          |
| time/                   |               |
|    fps                  | 1259          |
|    iterations           | 9             |
|    time_elapsed         | 468           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 2.6888763e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.0091        |
|    learning_rate        | 0.0001        |
|    loss                 | 733           |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.000828     |
|    value_loss           | 1.45e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 33606         |
|    invalid_moves        | 0             |
|    losses               | 15895         |
|    valid_moves          | 650000        |
|    win_rate             | 0.527         |
|    wins                 | 17711         |
| rollout/                |               |
|    ep_len_mean          | 19.9          |
|    ep_rew_mean          | 41.5          |
| time/                   |               |
|    fps                  | 1251          |
|    iterations           | 10            |
|    time_elapsed         | 523           |
|    total_timesteps      | 655360        |
| train/                  |               |
|    approx_kl            | 3.2889082e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.00966       |
|    learning_rate        | 0.0001        |
|    loss                 | 726           |
|    n_updates            | 90            |
|    policy_gradient_loss | -0.000961     |
|    value_loss           | 1.47e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 37224         |
|    invalid_moves        | 0             |
|    losses               | 17524         |
|    valid_moves          | 720000        |
|    win_rate             | 0.529         |
|    wins                 | 19700         |
| rollout/                |               |
|    ep_len_mean          | 19.5          |
|    ep_rew_mean          | 13.8          |
| time/                   |               |
|    fps                  | 1247          |
|    iterations           | 11            |
|    time_elapsed         | 578           |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 3.9204464e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.0114        |
|    learning_rate        | 0.0001        |
|    loss                 | 732           |
|    n_updates            | 100           |
|    policy_gradient_loss | -0.0011       |
|    value_loss           | 1.46e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 40415        |
|    invalid_moves        | 0            |
|    losses               | 18927        |
|    valid_moves          | 780000       |
|    win_rate             | 0.532        |
|    wins                 | 21488        |
| rollout/                |              |
|    ep_len_mean          | 18.4         |
|    ep_rew_mean          | 15.6         |
| time/                   |              |
|    fps                  | 1242         |
|    iterations           | 12           |
|    time_elapsed         | 633          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 3.009161e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.00967      |
|    learning_rate        | 0.0001       |
|    loss                 | 733          |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.000998    |
|    value_loss           | 1.44e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 44192        |
|    invalid_moves        | 0            |
|    losses               | 20572        |
|    valid_moves          | 850000       |
|    win_rate             | 0.534        |
|    wins                 | 23620        |
| rollout/                |              |
|    ep_len_mean          | 18.5         |
|    ep_rew_mean          | 32.6         |
| time/                   |              |
|    fps                  | 1238         |
|    iterations           | 13           |
|    time_elapsed         | 687          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 4.564773e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.0104       |
|    learning_rate        | 0.0001       |
|    loss                 | 751          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00132     |
|    value_loss           | 1.49e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 47470        |
|    invalid_moves        | 0            |
|    losses               | 21941        |
|    valid_moves          | 910000       |
|    win_rate             | 0.538        |
|    wins                 | 25529        |
| rollout/                |              |
|    ep_len_mean          | 18.8         |
|    ep_rew_mean          | 33.4         |
| time/                   |              |
|    fps                  | 1234         |
|    iterations           | 14           |
|    time_elapsed         | 743          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 4.993363e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.0107       |
|    learning_rate        | 0.0001       |
|    loss                 | 749          |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.0014      |
|    value_loss           | 1.5e+03      |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 51250         |
|    invalid_moves        | 0             |
|    losses               | 23542         |
|    valid_moves          | 980000        |
|    win_rate             | 0.541         |
|    wins                 | 27708         |
| rollout/                |               |
|    ep_len_mean          | 19.9          |
|    ep_rew_mean          | 25.5          |
| time/                   |               |
|    fps                  | 1230          |
|    iterations           | 15            |
|    time_elapsed         | 799           |
|    total_timesteps      | 983040        |
| train/                  |               |
|    approx_kl            | 6.6536144e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.0143        |
|    learning_rate        | 0.0001        |
|    loss                 | 763           |
|    n_updates            | 140           |
|    policy_gradient_loss | -0.00168      |
|    value_loss           | 1.51e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 54524         |
|    invalid_moves        | 0             |
|    losses               | 24847         |
|    valid_moves          | 1040000       |
|    win_rate             | 0.544         |
|    wins                 | 29677         |
| rollout/                |               |
|    ep_len_mean          | 18.2          |
|    ep_rew_mean          | 38.3          |
| time/                   |               |
|    fps                  | 1227          |
|    iterations           | 16            |
|    time_elapsed         | 854           |
|    total_timesteps      | 1048576       |
| train/                  |               |
|    approx_kl            | 4.6772962e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.012         |
|    learning_rate        | 0.0001        |
|    loss                 | 731           |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.00127      |
|    value_loss           | 1.5e+03       |
-------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/3_MaskableRecurrentPPO_20250805_000654.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 3_MaskableRecurrentPPO agent...
[0;36m-> Mean Reward: 161.28 +/- 3.16[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/boards.npy[0m
[0;37m   weights_file_path: weights/ae_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 4_FF_Autoencoder_MaskablePPO[0m
[0;37m   model_path: models/4_FF_Autoencoder_MaskablePPO_20250805_002143.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
MaskableMultiInputActorCriticPolicy      --
â”œâ”€FrozenAEFeatureExtractor: 1-1          --
â”‚    â””â”€Sequential: 2-1                   --
â”‚    â”‚    â””â”€Flatten: 3-1                 --
â”‚    â”‚    â””â”€Linear: 3-2                  (1,664)
â”‚    â”‚    â””â”€ReLU: 3-3                    --
â”‚    â”‚    â””â”€Linear: 3-4                  (520)
â”œâ”€FrozenAEFeatureExtractor: 1-2          (recursive)
â”‚    â””â”€Sequential: 2-2                   (recursive)
â”‚    â”‚    â””â”€Flatten: 3-5                 --
â”‚    â”‚    â””â”€Linear: 3-6                  (recursive)
â”‚    â”‚    â””â”€ReLU: 3-7                    --
â”‚    â”‚    â””â”€Linear: 3-8                  (recursive)
â”œâ”€FrozenAEFeatureExtractor: 1-3          (recursive)
â”‚    â””â”€Sequential: 2-3                   (recursive)
â”‚    â”‚    â””â”€Flatten: 3-9                 --
â”‚    â”‚    â””â”€Linear: 3-10                 (recursive)
â”‚    â”‚    â””â”€ReLU: 3-11                   --
â”‚    â”‚    â””â”€Linear: 3-12                 (recursive)
â”œâ”€MlpExtractor: 1-4                      --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-13                 576
â”‚    â”‚    â””â”€Tanh: 3-14                   --
â”‚    â”‚    â””â”€Linear: 3-15                 4,160
â”‚    â”‚    â””â”€Tanh: 3-16                   --
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-17                 576
â”‚    â”‚    â””â”€Tanh: 3-18                   --
â”‚    â”‚    â””â”€Linear: 3-19                 4,160
â”‚    â”‚    â””â”€Tanh: 3-20                   --
â”œâ”€Linear: 1-5                            61,230
â”œâ”€Linear: 1-6                            65
=================================================================
Total params: 72,951
Trainable params: 70,767
Non-trainable params: 2,184
=================================================================
Logging to ./chess_logs/4_FF_Autoencoder_MaskablePPO_1
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3133     |
|    invalid_moves   | 0        |
|    losses          | 1555     |
|    valid_moves     | 60000    |
|    win_rate        | 0.504    |
|    wins            | 1578     |
| rollout/           |          |
|    ep_len_mean     | 22.9     |
|    ep_rew_mean     | -5.04    |
| time/              |          |
|    fps             | 2416     |
|    iterations      | 1        |
|    time_elapsed    | 27       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6723          |
|    invalid_moves        | 0             |
|    losses               | 3290          |
|    valid_moves          | 130000        |
|    win_rate             | 0.511         |
|    wins                 | 3433          |
| rollout/                |               |
|    ep_len_mean          | 21            |
|    ep_rew_mean          | 21.7          |
| time/                   |               |
|    fps                  | 2334          |
|    iterations           | 2             |
|    time_elapsed         | 56            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 0.00046426203 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 6.23e-05      |
|    learning_rate        | 0.0001        |
|    loss                 | 704           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.00307      |
|    value_loss           | 1.46e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 9950         |
|    invalid_moves        | 0            |
|    losses               | 4774         |
|    valid_moves          | 190000       |
|    win_rate             | 0.52         |
|    wins                 | 5176         |
| rollout/                |              |
|    ep_len_mean          | 17.1         |
|    ep_rew_mean          | 30.4         |
| time/                   |              |
|    fps                  | 2308         |
|    iterations           | 3            |
|    time_elapsed         | 85           |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0006937147 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.000156     |
|    learning_rate        | 0.0001       |
|    loss                 | 724          |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00341     |
|    value_loss           | 1.45e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13749        |
|    invalid_moves        | 0            |
|    losses               | 6419         |
|    valid_moves          | 260000       |
|    win_rate             | 0.533        |
|    wins                 | 7330         |
| rollout/                |              |
|    ep_len_mean          | 19.3         |
|    ep_rew_mean          | 38.2         |
| time/                   |              |
|    fps                  | 2293         |
|    iterations           | 4            |
|    time_elapsed         | 114          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0011692314 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.000264     |
|    learning_rate        | 0.0001       |
|    loss                 | 750          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00454     |
|    value_loss           | 1.51e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 17077        |
|    invalid_moves        | 0            |
|    losses               | 7812         |
|    valid_moves          | 320000       |
|    win_rate             | 0.543        |
|    wins                 | 9265         |
| rollout/                |              |
|    ep_len_mean          | 17.3         |
|    ep_rew_mean          | 49.1         |
| time/                   |              |
|    fps                  | 2284         |
|    iterations           | 5            |
|    time_elapsed         | 143          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0008887687 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.000413     |
|    learning_rate        | 0.0001       |
|    loss                 | 790          |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00469     |
|    value_loss           | 1.53e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 20945        |
|    invalid_moves        | 0            |
|    losses               | 9275         |
|    valid_moves          | 390000       |
|    win_rate             | 0.557        |
|    wins                 | 11670        |
| rollout/                |              |
|    ep_len_mean          | 16.6         |
|    ep_rew_mean          | 40.2         |
| time/                   |              |
|    fps                  | 2279         |
|    iterations           | 6            |
|    time_elapsed         | 172          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0012235085 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.000433     |
|    learning_rate        | 0.0001       |
|    loss                 | 782          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00516     |
|    value_loss           | 1.57e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 24511        |
|    invalid_moves        | 0            |
|    losses               | 10501        |
|    valid_moves          | 450000       |
|    win_rate             | 0.572        |
|    wins                 | 14010        |
| rollout/                |              |
|    ep_len_mean          | 17.5         |
|    ep_rew_mean          | 71.4         |
| time/                   |              |
|    fps                  | 2271         |
|    iterations           | 7            |
|    time_elapsed         | 201          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0011675757 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.000469     |
|    learning_rate        | 0.0001       |
|    loss                 | 784          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00577     |
|    value_loss           | 1.55e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 28723         |
|    invalid_moves        | 0             |
|    losses               | 11822         |
|    valid_moves          | 520000        |
|    win_rate             | 0.588         |
|    wins                 | 16901         |
| rollout/                |               |
|    ep_len_mean          | 16.6          |
|    ep_rew_mean          | 42.6          |
| time/                   |               |
|    fps                  | 2265          |
|    iterations           | 8             |
|    time_elapsed         | 231           |
|    total_timesteps      | 524288        |
| train/                  |               |
|    approx_kl            | 0.00091090426 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.53         |
|    explained_variance   | 0.000589      |
|    learning_rate        | 0.0001        |
|    loss                 | 836           |
|    n_updates            | 70            |
|    policy_gradient_loss | -0.00546      |
|    value_loss           | 1.66e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 32550         |
|    invalid_moves        | 0             |
|    losses               | 12961         |
|    valid_moves          | 580000        |
|    win_rate             | 0.602         |
|    wins                 | 19589         |
| rollout/                |               |
|    ep_len_mean          | 16.3          |
|    ep_rew_mean          | 57.1          |
| time/                   |               |
|    fps                  | 2257          |
|    iterations           | 9             |
|    time_elapsed         | 261           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 0.00085441064 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.51         |
|    explained_variance   | 0.000546      |
|    learning_rate        | 0.0001        |
|    loss                 | 851           |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.00536      |
|    value_loss           | 1.69e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 37208        |
|    invalid_moves        | 0            |
|    losses               | 14249        |
|    valid_moves          | 650000       |
|    win_rate             | 0.617        |
|    wins                 | 22959        |
| rollout/                |              |
|    ep_len_mean          | 14.1         |
|    ep_rew_mean          | 81.5         |
| time/                   |              |
|    fps                  | 2250         |
|    iterations           | 10           |
|    time_elapsed         | 291          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0010307578 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.000532     |
|    learning_rate        | 0.0001       |
|    loss                 | 919          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.0066      |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 42074        |
|    invalid_moves        | 0            |
|    losses               | 15487        |
|    valid_moves          | 720000       |
|    win_rate             | 0.632        |
|    wins                 | 26587        |
| rollout/                |              |
|    ep_len_mean          | 14.3         |
|    ep_rew_mean          | 68.1         |
| time/                   |              |
|    fps                  | 2243         |
|    iterations           | 11           |
|    time_elapsed         | 321          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0012216268 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.000404     |
|    learning_rate        | 0.0001       |
|    loss                 | 926          |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00769     |
|    value_loss           | 1.85e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 46418       |
|    invalid_moves        | 0           |
|    losses               | 16452       |
|    valid_moves          | 780000      |
|    win_rate             | 0.646       |
|    wins                 | 29966       |
| rollout/                |             |
|    ep_len_mean          | 13.7        |
|    ep_rew_mean          | 98.4        |
| time/                   |             |
|    fps                  | 2235        |
|    iterations           | 12          |
|    time_elapsed         | 351         |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.001282838 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0.000485    |
|    learning_rate        | 0.0001      |
|    loss                 | 934         |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00809    |
|    value_loss           | 1.92e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 51677        |
|    invalid_moves        | 0            |
|    losses               | 17487        |
|    valid_moves          | 850000       |
|    win_rate             | 0.662        |
|    wins                 | 34190        |
| rollout/                |              |
|    ep_len_mean          | 12.8         |
|    ep_rew_mean          | 97.5         |
| time/                   |              |
|    fps                  | 2228         |
|    iterations           | 13           |
|    time_elapsed         | 382          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0011067253 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.000369     |
|    learning_rate        | 0.0001       |
|    loss                 | 958          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00757     |
|    value_loss           | 1.97e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 56480       |
|    invalid_moves        | 0           |
|    losses               | 18389       |
|    valid_moves          | 910000      |
|    win_rate             | 0.674       |
|    wins                 | 38091       |
| rollout/                |             |
|    ep_len_mean          | 12.5        |
|    ep_rew_mean          | 90.6        |
| time/                   |             |
|    fps                  | 2220        |
|    iterations           | 14          |
|    time_elapsed         | 413         |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.001040553 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.37       |
|    explained_variance   | 0.000237    |
|    learning_rate        | 0.0001      |
|    loss                 | 999         |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00776    |
|    value_loss           | 2.06e+03    |
-----------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 62411       |
|    invalid_moves        | 0           |
|    losses               | 19409       |
|    valid_moves          | 980000      |
|    win_rate             | 0.689       |
|    wins                 | 43002       |
| rollout/                |             |
|    ep_len_mean          | 11          |
|    ep_rew_mean          | 97.9        |
| time/                   |             |
|    fps                  | 2212        |
|    iterations           | 15          |
|    time_elapsed         | 444         |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.001032087 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.34       |
|    explained_variance   | 0.000216    |
|    learning_rate        | 0.0001      |
|    loss                 | 1.04e+03    |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.00785    |
|    value_loss           | 2.17e+03    |
-----------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 67689         |
|    invalid_moves        | 0             |
|    losses               | 20257         |
|    valid_moves          | 1040000       |
|    win_rate             | 0.701         |
|    wins                 | 47432         |
| rollout/                |               |
|    ep_len_mean          | 11.2          |
|    ep_rew_mean          | 119           |
| time/                   |               |
|    fps                  | 2204          |
|    iterations           | 16            |
|    time_elapsed         | 475           |
|    total_timesteps      | 1048576       |
| train/                  |               |
|    approx_kl            | 0.00097280263 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.29         |
|    explained_variance   | 0.000216      |
|    learning_rate        | 0.0001        |
|    loss                 | 1.09e+03      |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.00758      |
|    value_loss           | 2.28e+03      |
-------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/4_FF_Autoencoder_MaskablePPO_20250805_002143.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 4_FF_Autoencoder_MaskablePPO agent...
[0;36m-> Mean Reward: 156.18 +/- 45.59[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/boards.npy[0m
[0;37m   weights_file_path: weights/ae_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 5_FF_Autoencoder_MaskableRecurrentPPO[0m
[0;37m   model_path: models/5_FF_Autoencoder_MaskableRecurrentPPO_20250805_002954.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '5_FF_Autoencoder_MaskableRecurrentPPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableRecurrentMultiInputActorCriticPolicy  --
â”œâ”€FrozenAEFeatureExtractor: 1-1               --
â”‚    â””â”€Sequential: 2-1                        --
â”‚    â”‚    â””â”€Flatten: 3-1                      --
â”‚    â”‚    â””â”€Linear: 3-2                       (1,664)
â”‚    â”‚    â””â”€ReLU: 3-3                         --
â”‚    â”‚    â””â”€Linear: 3-4                       (520)
â”œâ”€FrozenAEFeatureExtractor: 1-2               (recursive)
â”‚    â””â”€Sequential: 2-2                        (recursive)
â”‚    â”‚    â””â”€Flatten: 3-5                      --
â”‚    â”‚    â””â”€Linear: 3-6                       (recursive)
â”‚    â”‚    â””â”€ReLU: 3-7                         --
â”‚    â”‚    â””â”€Linear: 3-8                       (recursive)
â”œâ”€FrozenAEFeatureExtractor: 1-3               (recursive)
â”‚    â””â”€Sequential: 2-3                        (recursive)
â”‚    â”‚    â””â”€Flatten: 3-9                      --
â”‚    â”‚    â””â”€Linear: 3-10                      (recursive)
â”‚    â”‚    â””â”€ReLU: 3-11                        --
â”‚    â”‚    â””â”€Linear: 3-12                      (recursive)
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-4                        --
â”‚    â”‚    â””â”€Linear: 3-13                      16,448
â”‚    â”‚    â””â”€Tanh: 3-14                        --
â”‚    â”‚    â””â”€Linear: 3-15                      4,160
â”‚    â”‚    â””â”€Tanh: 3-16                        --
â”‚    â””â”€Sequential: 2-5                        --
â”‚    â”‚    â””â”€Linear: 3-17                      16,448
â”‚    â”‚    â””â”€Tanh: 3-18                        --
â”‚    â”‚    â””â”€Linear: 3-19                      4,160
â”‚    â”‚    â””â”€Tanh: 3-20                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
â”œâ”€LSTM: 1-7                                   272,384
â”œâ”€LSTM: 1-8                                   272,384
======================================================================
Total params: 649,463
Trainable params: 647,279
Non-trainable params: 2,184
======================================================================
Logging to ./chess_logs/5_FF_Autoencoder_MaskableRecurrentPPO_1
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3030     |
|    invalid_moves   | 0        |
|    losses          | 1535     |
|    valid_moves     | 60000    |
|    win_rate        | 0.493    |
|    wins            | 1495     |
| rollout/           |          |
|    ep_len_mean     | 18.5     |
|    ep_rew_mean     | -14.2    |
| time/              |          |
|    fps             | 2094     |
|    iterations      | 1        |
|    time_elapsed    | 31       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6630          |
|    invalid_moves        | 0             |
|    losses               | 3295          |
|    valid_moves          | 130000        |
|    win_rate             | 0.503         |
|    wins                 | 3335          |
| rollout/                |               |
|    ep_len_mean          | 19.6          |
|    ep_rew_mean          | 3.92          |
| time/                   |               |
|    fps                  | 1512          |
|    iterations           | 2             |
|    time_elapsed         | 86            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 3.0683826e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | -2.98e-05     |
|    learning_rate        | 0.0001        |
|    loss                 | 718           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000657     |
|    value_loss           | 1.43e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9718          |
|    invalid_moves        | 0             |
|    losses               | 4739          |
|    valid_moves          | 190000        |
|    win_rate             | 0.512         |
|    wins                 | 4979          |
| rollout/                |               |
|    ep_len_mean          | 21.5          |
|    ep_rew_mean          | 11.8          |
| time/                   |               |
|    fps                  | 1390          |
|    iterations           | 3             |
|    time_elapsed         | 141           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00020055214 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.000167      |
|    learning_rate        | 0.0001        |
|    loss                 | 713           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00161      |
|    value_loss           | 1.45e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13329        |
|    invalid_moves        | 0            |
|    losses               | 6425         |
|    valid_moves          | 260000       |
|    win_rate             | 0.518        |
|    wins                 | 6904         |
| rollout/                |              |
|    ep_len_mean          | 17.7         |
|    ep_rew_mean          | 33.8         |
| time/                   |              |
|    fps                  | 1333         |
|    iterations           | 4            |
|    time_elapsed         | 196          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0009023941 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.000762     |
|    learning_rate        | 0.0001       |
|    loss                 | 712          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00383     |
|    value_loss           | 1.44e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 16609        |
|    invalid_moves        | 0            |
|    losses               | 7770         |
|    valid_moves          | 320000       |
|    win_rate             | 0.532        |
|    wins                 | 8839         |
| rollout/                |              |
|    ep_len_mean          | 18.7         |
|    ep_rew_mean          | 16.4         |
| time/                   |              |
|    fps                  | 1299         |
|    iterations           | 5            |
|    time_elapsed         | 252          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0013043105 |
|    clip_fraction        | 8.85e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.00124      |
|    learning_rate        | 0.0001       |
|    loss                 | 730          |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00542     |
|    value_loss           | 1.46e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 20588       |
|    invalid_moves        | 0           |
|    losses               | 9205        |
|    valid_moves          | 390000      |
|    win_rate             | 0.553       |
|    wins                 | 11383       |
| rollout/                |             |
|    ep_len_mean          | 18.1        |
|    ep_rew_mean          | 66          |
| time/                   |             |
|    fps                  | 1271        |
|    iterations           | 6           |
|    time_elapsed         | 309         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.005281691 |
|    clip_fraction        | 0.0129      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.57       |
|    explained_variance   | 0.00215     |
|    learning_rate        | 0.0001      |
|    loss                 | 765         |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00875    |
|    value_loss           | 1.53e+03    |
-----------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 24337       |
|    invalid_moves        | 0           |
|    losses               | 10200       |
|    valid_moves          | 450000      |
|    win_rate             | 0.581       |
|    wins                 | 14137       |
| rollout/                |             |
|    ep_len_mean          | 16.3        |
|    ep_rew_mean          | 99.2        |
| time/                   |             |
|    fps                  | 1251        |
|    iterations           | 7           |
|    time_elapsed         | 366         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.009492947 |
|    clip_fraction        | 0.0426      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.54       |
|    explained_variance   | 0.0037      |
|    learning_rate        | 0.0001      |
|    loss                 | 790         |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0134     |
|    value_loss           | 1.59e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 29037        |
|    invalid_moves        | 0            |
|    losses               | 11306        |
|    valid_moves          | 520000       |
|    win_rate             | 0.611        |
|    wins                 | 17731        |
| rollout/                |              |
|    ep_len_mean          | 13.9         |
|    ep_rew_mean          | 103          |
| time/                   |              |
|    fps                  | 1228         |
|    iterations           | 8            |
|    time_elapsed         | 426          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0025734112 |
|    clip_fraction        | 0.000908     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.00728      |
|    learning_rate        | 0.0001       |
|    loss                 | 890          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00931     |
|    value_loss           | 1.72e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 33422       |
|    invalid_moves        | 0           |
|    losses               | 12152       |
|    valid_moves          | 580000      |
|    win_rate             | 0.636       |
|    wins                 | 21270       |
| rollout/                |             |
|    ep_len_mean          | 10.7        |
|    ep_rew_mean          | 97.6        |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 9           |
|    time_elapsed         | 489         |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.004327502 |
|    clip_fraction        | 0.0103      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.43       |
|    explained_variance   | 0.00852     |
|    learning_rate        | 0.0001      |
|    loss                 | 888         |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 1.84e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 38864        |
|    invalid_moves        | 0            |
|    losses               | 13078        |
|    valid_moves          | 650000       |
|    win_rate             | 0.663        |
|    wins                 | 25786        |
| rollout/                |              |
|    ep_len_mean          | 12.8         |
|    ep_rew_mean          | 121          |
| time/                   |              |
|    fps                  | 1186         |
|    iterations           | 10           |
|    time_elapsed         | 552          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0027072332 |
|    clip_fraction        | 0.000479     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.0105       |
|    learning_rate        | 0.0001       |
|    loss                 | 994          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.0119      |
|    value_loss           | 1.97e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 44893        |
|    invalid_moves        | 0            |
|    losses               | 13998        |
|    valid_moves          | 720000       |
|    win_rate             | 0.688        |
|    wins                 | 30895        |
| rollout/                |              |
|    ep_len_mean          | 11.1         |
|    ep_rew_mean          | 121          |
| time/                   |              |
|    fps                  | 1167         |
|    iterations           | 11           |
|    time_elapsed         | 617          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0027606124 |
|    clip_fraction        | 0.00259      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.05e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.0129      |
|    value_loss           | 2.07e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 50396        |
|    invalid_moves        | 0            |
|    losses               | 14720        |
|    valid_moves          | 780000       |
|    win_rate             | 0.708        |
|    wins                 | 35676        |
| rollout/                |              |
|    ep_len_mean          | 10.2         |
|    ep_rew_mean          | 122          |
| time/                   |              |
|    fps                  | 1150         |
|    iterations           | 12           |
|    time_elapsed         | 683          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0021213733 |
|    clip_fraction        | 0.000395     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | 0.0134       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.17e+03     |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.0113      |
|    value_loss           | 2.27e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 57136        |
|    invalid_moves        | 0            |
|    losses               | 15518        |
|    valid_moves          | 850000       |
|    win_rate             | 0.728        |
|    wins                 | 41618        |
| rollout/                |              |
|    ep_len_mean          | 10.2         |
|    ep_rew_mean          | 130          |
| time/                   |              |
|    fps                  | 1128         |
|    iterations           | 13           |
|    time_elapsed         | 754          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0017769969 |
|    clip_fraction        | 1.37e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.0141       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.2e+03      |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.0105      |
|    value_loss           | 2.39e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 63220        |
|    invalid_moves        | 0            |
|    losses               | 16147        |
|    valid_moves          | 910000       |
|    win_rate             | 0.745        |
|    wins                 | 47073        |
| rollout/                |              |
|    ep_len_mean          | 10.6         |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 1109         |
|    iterations           | 14           |
|    time_elapsed         | 827          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0016190193 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.0151       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.26e+03     |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00974     |
|    value_loss           | 2.48e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 70751        |
|    invalid_moves        | 0            |
|    losses               | 16889        |
|    valid_moves          | 980000       |
|    win_rate             | 0.761        |
|    wins                 | 53862        |
| rollout/                |              |
|    ep_len_mean          | 8.2          |
|    ep_rew_mean          | 137          |
| time/                   |              |
|    fps                  | 1093         |
|    iterations           | 15           |
|    time_elapsed         | 898          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0012583963 |
|    clip_fraction        | 1.53e-06     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.0162       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.3e+03      |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00821     |
|    value_loss           | 2.58e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 77436        |
|    invalid_moves        | 0            |
|    losses               | 17480        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.774        |
|    wins                 | 59956        |
| rollout/                |              |
|    ep_len_mean          | 10.5         |
|    ep_rew_mean          | 115          |
| time/                   |              |
|    fps                  | 1077         |
|    iterations           | 16           |
|    time_elapsed         | 972          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0010047972 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.0174       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.38e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00714     |
|    value_loss           | 2.74e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/5_FF_Autoencoder_MaskableRecurrentPPO_20250805_002954.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 5_FF_Autoencoder_MaskableRecurrentPPO agent...
[0;36m-> Mean Reward: 161.72 +/- 1.66[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/board_seqs.npy[0m
[0;37m   weights_file_path: weights/ae_rnn_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 6_LSTM_Autoencoder_MaskablePPO[0m
[0;37m   model_path: models/6_LSTM_Autoencoder_MaskablePPO_20250805_004701.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '6_LSTM_Autoencoder_MaskablePPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/DRL/Chess_6_LSTM_Autoencoder_MaskablePPO.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ae.load_state_dict(torch.load(AE_WEIGHTS_PATH, map_location=device))
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableMultiInputActorCriticPolicy           --
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-1        --
â”‚    â””â”€SimpleLSTMAutoencoder: 2-1             --
â”‚    â”‚    â””â”€LSTM: 3-1                         (23,296)
â”‚    â”‚    â””â”€Linear: 3-2                       (520)
â”‚    â”‚    â””â”€Linear: 3-3                       (576)
â”‚    â”‚    â””â”€LSTM: 3-4                         (33,280)
â”‚    â”‚    â””â”€Linear: 3-5                       (1,625)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-2             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-6                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-7                       (recursive)
â”‚    â”‚    â””â”€Linear: 3-8                       (recursive)
â”‚    â”‚    â””â”€LSTM: 3-9                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-10                      (recursive)
â”‚    â””â”€LSTM: 2-3                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-2        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-4             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-11                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-12                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-13                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-14                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-15                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-5             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-16                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-17                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-18                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-19                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-20                      (recursive)
â”‚    â””â”€LSTM: 2-6                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-3        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-7             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-21                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-22                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-23                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-24                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-25                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-8             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-26                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-27                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-28                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-29                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-30                      (recursive)
â”‚    â””â”€LSTM: 2-9                              (recursive)
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-10                       --
â”‚    â”‚    â””â”€Linear: 3-31                      576
â”‚    â”‚    â””â”€Tanh: 3-32                        --
â”‚    â”‚    â””â”€Linear: 3-33                      4,160
â”‚    â”‚    â””â”€Tanh: 3-34                        --
â”‚    â””â”€Sequential: 2-11                       --
â”‚    â”‚    â””â”€Linear: 3-35                      576
â”‚    â”‚    â””â”€Tanh: 3-36                        --
â”‚    â”‚    â””â”€Linear: 3-37                      4,160
â”‚    â”‚    â””â”€Tanh: 3-38                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
======================================================================
Total params: 130,064
Trainable params: 70,767
Non-trainable params: 59,297
======================================================================
Logging to ./chess_logs/6_LSTM_Autoencoder_MaskablePPO_1
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3143     |
|    invalid_moves   | 0        |
|    losses          | 1593     |
|    valid_moves     | 60000    |
|    win_rate        | 0.493    |
|    wins            | 1550     |
| rollout/           |          |
|    ep_len_mean     | 20.8     |
|    ep_rew_mean     | 8.83     |
| time/              |          |
|    fps             | 2347     |
|    iterations      | 1        |
|    time_elapsed    | 27       |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 6784         |
|    invalid_moves        | 0            |
|    losses               | 3374         |
|    valid_moves          | 130000       |
|    win_rate             | 0.503        |
|    wins                 | 3410         |
| rollout/                |              |
|    ep_len_mean          | 18.2         |
|    ep_rew_mean          | 1.48         |
| time/                   |              |
|    fps                  | 2259         |
|    iterations           | 2            |
|    time_elapsed         | 58           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 6.954529e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | -2.87e-05    |
|    learning_rate        | 0.0001       |
|    loss                 | 713          |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00106     |
|    value_loss           | 1.47e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9855          |
|    invalid_moves        | 0             |
|    losses               | 4802          |
|    valid_moves          | 190000        |
|    win_rate             | 0.513         |
|    wins                 | 5053          |
| rollout/                |               |
|    ep_len_mean          | 19.2          |
|    ep_rew_mean          | 14.2          |
| time/                   |               |
|    fps                  | 2244          |
|    iterations           | 3             |
|    time_elapsed         | 87            |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00014690639 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 1.25e-05      |
|    learning_rate        | 0.0001        |
|    loss                 | 721           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00155      |
|    value_loss           | 1.47e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13469        |
|    invalid_moves        | 0            |
|    losses               | 6503         |
|    valid_moves          | 260000       |
|    win_rate             | 0.517        |
|    wins                 | 6966         |
| rollout/                |              |
|    ep_len_mean          | 17.9         |
|    ep_rew_mean          | -0.047       |
| time/                   |              |
|    fps                  | 2235         |
|    iterations           | 4            |
|    time_elapsed         | 117          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0001455943 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 5.67e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 723          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00164     |
|    value_loss           | 1.45e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 16704         |
|    invalid_moves        | 0             |
|    losses               | 7899          |
|    valid_moves          | 320000        |
|    win_rate             | 0.527         |
|    wins                 | 8805          |
| rollout/                |               |
|    ep_len_mean          | 19.5          |
|    ep_rew_mean          | 13.4          |
| time/                   |               |
|    fps                  | 2227          |
|    iterations           | 5             |
|    time_elapsed         | 147           |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 0.00068143266 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.000105      |
|    learning_rate        | 0.0001        |
|    loss                 | 708           |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.00319      |
|    value_loss           | 1.45e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 20447         |
|    invalid_moves        | 0             |
|    losses               | 9448          |
|    valid_moves          | 390000        |
|    win_rate             | 0.538         |
|    wins                 | 10999         |
| rollout/                |               |
|    ep_len_mean          | 16.8          |
|    ep_rew_mean          | 7.57          |
| time/                   |               |
|    fps                  | 2223          |
|    iterations           | 6             |
|    time_elapsed         | 176           |
|    total_timesteps      | 393216        |
| train/                  |               |
|    approx_kl            | 0.00042056304 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.000171      |
|    learning_rate        | 0.0001        |
|    loss                 | 736           |
|    n_updates            | 50            |
|    policy_gradient_loss | -0.00315      |
|    value_loss           | 1.5e+03       |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 23784         |
|    invalid_moves        | 0             |
|    losses               | 10877         |
|    valid_moves          | 450000        |
|    win_rate             | 0.543         |
|    wins                 | 12907         |
| rollout/                |               |
|    ep_len_mean          | 18.1          |
|    ep_rew_mean          | 9.52          |
| time/                   |               |
|    fps                  | 2217          |
|    iterations           | 7             |
|    time_elapsed         | 206           |
|    total_timesteps      | 458752        |
| train/                  |               |
|    approx_kl            | 0.00028600325 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.000187      |
|    learning_rate        | 0.0001        |
|    loss                 | 782           |
|    n_updates            | 60            |
|    policy_gradient_loss | -0.00256      |
|    value_loss           | 1.52e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 27729        |
|    invalid_moves        | 0            |
|    losses               | 12380        |
|    valid_moves          | 520000       |
|    win_rate             | 0.554        |
|    wins                 | 15349        |
| rollout/                |              |
|    ep_len_mean          | 17.3         |
|    ep_rew_mean          | 42.1         |
| time/                   |              |
|    fps                  | 2212         |
|    iterations           | 8            |
|    time_elapsed         | 236          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0013738766 |
|    clip_fraction        | 2.29e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.000229     |
|    learning_rate        | 0.0001       |
|    loss                 | 801          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00538     |
|    value_loss           | 1.57e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 31194        |
|    invalid_moves        | 0            |
|    losses               | 13590        |
|    valid_moves          | 580000       |
|    win_rate             | 0.564        |
|    wins                 | 17604        |
| rollout/                |              |
|    ep_len_mean          | 18.2         |
|    ep_rew_mean          | 34.1         |
| time/                   |              |
|    fps                  | 2208         |
|    iterations           | 9            |
|    time_elapsed         | 267          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0008143037 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.00026      |
|    learning_rate        | 0.0001       |
|    loss                 | 770          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00536     |
|    value_loss           | 1.59e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 35301         |
|    invalid_moves        | 0             |
|    losses               | 14947         |
|    valid_moves          | 650000        |
|    win_rate             | 0.577         |
|    wins                 | 20354         |
| rollout/                |               |
|    ep_len_mean          | 14.6          |
|    ep_rew_mean          | 54.1          |
| time/                   |               |
|    fps                  | 2203          |
|    iterations           | 10            |
|    time_elapsed         | 297           |
|    total_timesteps      | 655360        |
| train/                  |               |
|    approx_kl            | 0.00054104347 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.55         |
|    explained_variance   | 0.00031       |
|    learning_rate        | 0.0001        |
|    loss                 | 798           |
|    n_updates            | 90            |
|    policy_gradient_loss | -0.00411      |
|    value_loss           | 1.61e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 39532         |
|    invalid_moves        | 0             |
|    losses               | 16292         |
|    valid_moves          | 720000        |
|    win_rate             | 0.588         |
|    wins                 | 23240         |
| rollout/                |               |
|    ep_len_mean          | 16.4          |
|    ep_rew_mean          | 69.9          |
| time/                   |               |
|    fps                  | 2199          |
|    iterations           | 11            |
|    time_elapsed         | 327           |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 0.00048258802 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.54         |
|    explained_variance   | 0.000369      |
|    learning_rate        | 0.0001        |
|    loss                 | 826           |
|    n_updates            | 100           |
|    policy_gradient_loss | -0.00408      |
|    value_loss           | 1.66e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 43238         |
|    invalid_moves        | 0             |
|    losses               | 17392         |
|    valid_moves          | 780000        |
|    win_rate             | 0.598         |
|    wins                 | 25846         |
| rollout/                |               |
|    ep_len_mean          | 14.5          |
|    ep_rew_mean          | 63.5          |
| time/                   |               |
|    fps                  | 2195          |
|    iterations           | 12            |
|    time_elapsed         | 358           |
|    total_timesteps      | 786432        |
| train/                  |               |
|    approx_kl            | 0.00064067106 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.52         |
|    explained_variance   | 0.000362      |
|    learning_rate        | 0.0001        |
|    loss                 | 859           |
|    n_updates            | 110           |
|    policy_gradient_loss | -0.00475      |
|    value_loss           | 1.68e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 47732        |
|    invalid_moves        | 0            |
|    losses               | 18624        |
|    valid_moves          | 850000       |
|    win_rate             | 0.61         |
|    wins                 | 29108        |
| rollout/                |              |
|    ep_len_mean          | 15.7         |
|    ep_rew_mean          | 88.4         |
| time/                   |              |
|    fps                  | 2190         |
|    iterations           | 13           |
|    time_elapsed         | 388          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0007929502 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.000433     |
|    learning_rate        | 0.0001       |
|    loss                 | 876          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.0055      |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 51786        |
|    invalid_moves        | 0            |
|    losses               | 19622        |
|    valid_moves          | 910000       |
|    win_rate             | 0.621        |
|    wins                 | 32164        |
| rollout/                |              |
|    ep_len_mean          | 15.6         |
|    ep_rew_mean          | 82.9         |
| time/                   |              |
|    fps                  | 2186         |
|    iterations           | 14           |
|    time_elapsed         | 419          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0008590518 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.000363     |
|    learning_rate        | 0.0001       |
|    loss                 | 861          |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00622     |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 56719        |
|    invalid_moves        | 0            |
|    losses               | 20776        |
|    valid_moves          | 980000       |
|    win_rate             | 0.634        |
|    wins                 | 35943        |
| rollout/                |              |
|    ep_len_mean          | 13.5         |
|    ep_rew_mean          | 71.2         |
| time/                   |              |
|    fps                  | 2180         |
|    iterations           | 15           |
|    time_elapsed         | 450          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0008081553 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.000438     |
|    learning_rate        | 0.0001       |
|    loss                 | 929          |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00629     |
|    value_loss           | 1.86e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 61164        |
|    invalid_moves        | 0            |
|    losses               | 21718        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.645        |
|    wins                 | 39446        |
| rollout/                |              |
|    ep_len_mean          | 14.3         |
|    ep_rew_mean          | 94.6         |
| time/                   |              |
|    fps                  | 2174         |
|    iterations           | 16           |
|    time_elapsed         | 482          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0008937263 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.000485     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.01e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00676     |
|    value_loss           | 1.93e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/6_LSTM_Autoencoder_MaskablePPO_20250805_004701.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 6_LSTM_Autoencoder_MaskablePPO agent...
[0;36m-> Mean Reward: 148.67 +/- 60.80[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/board_seqs.npy[0m
[0;37m   weights_file_path: weights/ae_rnn_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 7_LSTM_Autoencoder_MaskableRecurrentPPO[0m
[0;37m   model_path: models/7_LSTM_Autoencoder_MaskableRecurrentPPO_20250805_005518.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '7_LSTM_Autoencoder_MaskableRecurrentPPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/DRL/Chess_7_LSTM_Autoencoder_MaskableRecurrentPPO.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ae.load_state_dict(torch.load(AE_WEIGHTS_PATH, map_location=device))
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableRecurrentMultiInputActorCriticPolicy  --
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-1        --
â”‚    â””â”€SimpleLSTMAutoencoder: 2-1             --
â”‚    â”‚    â””â”€LSTM: 3-1                         (23,296)
â”‚    â”‚    â””â”€Linear: 3-2                       (520)
â”‚    â”‚    â””â”€Linear: 3-3                       (576)
â”‚    â”‚    â””â”€LSTM: 3-4                         (33,280)
â”‚    â”‚    â””â”€Linear: 3-5                       (1,625)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-2             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-6                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-7                       (recursive)
â”‚    â”‚    â””â”€Linear: 3-8                       (recursive)
â”‚    â”‚    â””â”€LSTM: 3-9                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-10                      (recursive)
â”‚    â””â”€LSTM: 2-3                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-2        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-4             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-11                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-12                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-13                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-14                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-15                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-5             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-16                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-17                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-18                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-19                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-20                      (recursive)
â”‚    â””â”€LSTM: 2-6                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-3        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-7             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-21                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-22                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-23                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-24                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-25                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-8             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-26                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-27                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-28                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-29                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-30                      (recursive)
â”‚    â””â”€LSTM: 2-9                              (recursive)
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-10                       --
â”‚    â”‚    â””â”€Linear: 3-31                      16,448
â”‚    â”‚    â””â”€Tanh: 3-32                        --
â”‚    â”‚    â””â”€Linear: 3-33                      4,160
â”‚    â”‚    â””â”€Tanh: 3-34                        --
â”‚    â””â”€Sequential: 2-11                       --
â”‚    â”‚    â””â”€Linear: 3-35                      16,448
â”‚    â”‚    â””â”€Tanh: 3-36                        --
â”‚    â”‚    â””â”€Linear: 3-37                      4,160
â”‚    â”‚    â””â”€Tanh: 3-38                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
â”œâ”€LSTM: 1-7                                   272,384
â”œâ”€LSTM: 1-8                                   272,384
======================================================================
Total params: 706,576
Trainable params: 647,279
Non-trainable params: 59,297
======================================================================
Logging to ./chess_logs/7_LSTM_Autoencoder_MaskableRecurrentPPO_1
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3124     |
|    invalid_moves   | 0        |
|    losses          | 1584     |
|    valid_moves     | 60000    |
|    win_rate        | 0.493    |
|    wins            | 1540     |
| rollout/           |          |
|    ep_len_mean     | 18.2     |
|    ep_rew_mean     | 14.5     |
| time/              |          |
|    fps             | 2034     |
|    iterations      | 1        |
|    time_elapsed    | 32       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6830          |
|    invalid_moves        | 0             |
|    losses               | 3386          |
|    valid_moves          | 130000        |
|    win_rate             | 0.504         |
|    wins                 | 3444          |
| rollout/                |               |
|    ep_len_mean          | 17.9          |
|    ep_rew_mean          | 20.7          |
| time/                   |               |
|    fps                  | 1468          |
|    iterations           | 2             |
|    time_elapsed         | 89            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 2.7613496e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 8.34e-07      |
|    learning_rate        | 0.0001        |
|    loss                 | 737           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000642     |
|    value_loss           | 1.48e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 9982         |
|    invalid_moves        | 0            |
|    losses               | 4847         |
|    valid_moves          | 190000       |
|    win_rate             | 0.514        |
|    wins                 | 5135         |
| rollout/                |              |
|    ep_len_mean          | 19.5         |
|    ep_rew_mean          | -1.55        |
| time/                   |              |
|    fps                  | 1340         |
|    iterations           | 3            |
|    time_elapsed         | 146          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0002997076 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 2.05e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 725          |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00197     |
|    value_loss           | 1.49e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 13753       |
|    invalid_moves        | 0           |
|    losses               | 6438        |
|    valid_moves          | 260000      |
|    win_rate             | 0.532       |
|    wins                 | 7315        |
| rollout/                |             |
|    ep_len_mean          | 17.1        |
|    ep_rew_mean          | 33.4        |
| time/                   |             |
|    fps                  | 1293        |
|    iterations           | 4           |
|    time_elapsed         | 202         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.002942259 |
|    clip_fraction        | 0.00318     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.000187    |
|    learning_rate        | 0.0001      |
|    loss                 | 745         |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00644    |
|    value_loss           | 1.48e+03    |
-----------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 17188       |
|    invalid_moves        | 0           |
|    losses               | 7643        |
|    valid_moves          | 320000      |
|    win_rate             | 0.555       |
|    wins                 | 9545        |
| rollout/                |             |
|    ep_len_mean          | 18.7        |
|    ep_rew_mean          | 51.2        |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 5           |
|    time_elapsed         | 260         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.008856825 |
|    clip_fraction        | 0.0436      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.56       |
|    explained_variance   | 0.000634    |
|    learning_rate        | 0.0001      |
|    loss                 | 755         |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0131     |
|    value_loss           | 1.52e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 21533        |
|    invalid_moves        | 0            |
|    losses               | 8932         |
|    valid_moves          | 390000       |
|    win_rate             | 0.585        |
|    wins                 | 12601        |
| rollout/                |              |
|    ep_len_mean          | 14.6         |
|    ep_rew_mean          | 73.2         |
| time/                   |              |
|    fps                  | 1230         |
|    iterations           | 6            |
|    time_elapsed         | 319          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0060093966 |
|    clip_fraction        | 0.0122       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.00191      |
|    learning_rate        | 0.0001       |
|    loss                 | 820          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.0101      |
|    value_loss           | 1.6e+03      |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 25631       |
|    invalid_moves        | 0           |
|    losses               | 9883        |
|    valid_moves          | 450000      |
|    win_rate             | 0.614       |
|    wins                 | 15748       |
| rollout/                |             |
|    ep_len_mean          | 15.9        |
|    ep_rew_mean          | 88.7        |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 7           |
|    time_elapsed         | 381         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.006133017 |
|    clip_fraction        | 0.0165      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.47       |
|    explained_variance   | 0.00456     |
|    learning_rate        | 0.0001      |
|    loss                 | 873         |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 1.73e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 30676        |
|    invalid_moves        | 0            |
|    losses               | 10915        |
|    valid_moves          | 520000       |
|    win_rate             | 0.644        |
|    wins                 | 19761        |
| rollout/                |              |
|    ep_len_mean          | 12.2         |
|    ep_rew_mean          | 78.6         |
| time/                   |              |
|    fps                  | 1177         |
|    iterations           | 8            |
|    time_elapsed         | 445          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0017176606 |
|    clip_fraction        | 3.05e-06     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.42        |
|    explained_variance   | 0.00746      |
|    learning_rate        | 0.0001       |
|    loss                 | 942          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00889     |
|    value_loss           | 1.84e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 35217       |
|    invalid_moves        | 0           |
|    losses               | 11786       |
|    valid_moves          | 580000      |
|    win_rate             | 0.665       |
|    wins                 | 23431       |
| rollout/                |             |
|    ep_len_mean          | 13.8        |
|    ep_rew_mean          | 112         |
| time/                   |             |
|    fps                  | 1153        |
|    iterations           | 9           |
|    time_elapsed         | 511         |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.001400017 |
|    clip_fraction        | 1.07e-05    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.39       |
|    explained_variance   | 0.00897     |
|    learning_rate        | 0.0001      |
|    loss                 | 991         |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00936    |
|    value_loss           | 1.96e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 40874        |
|    invalid_moves        | 0            |
|    losses               | 12718        |
|    valid_moves          | 650000       |
|    win_rate             | 0.689        |
|    wins                 | 28156        |
| rollout/                |              |
|    ep_len_mean          | 12.2         |
|    ep_rew_mean          | 93.8         |
| time/                   |              |
|    fps                  | 1132         |
|    iterations           | 10           |
|    time_elapsed         | 578          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0012824434 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.00956      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.02e+03     |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00881     |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 46771        |
|    invalid_moves        | 0            |
|    losses               | 13646        |
|    valid_moves          | 720000       |
|    win_rate             | 0.708        |
|    wins                 | 33125        |
| rollout/                |              |
|    ep_len_mean          | 13.7         |
|    ep_rew_mean          | 120          |
| time/                   |              |
|    fps                  | 1116         |
|    iterations           | 11           |
|    time_elapsed         | 645          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0011005406 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.0112       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.09e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00842     |
|    value_loss           | 2.16e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 52049        |
|    invalid_moves        | 0            |
|    losses               | 14395        |
|    valid_moves          | 780000       |
|    win_rate             | 0.723        |
|    wins                 | 37654        |
| rollout/                |              |
|    ep_len_mean          | 10.8         |
|    ep_rew_mean          | 110          |
| time/                   |              |
|    fps                  | 1100         |
|    iterations           | 12           |
|    time_elapsed         | 714          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0010921534 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.0115       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.11e+03     |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00821     |
|    value_loss           | 2.21e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 58551        |
|    invalid_moves        | 0            |
|    losses               | 15259        |
|    valid_moves          | 850000       |
|    win_rate             | 0.739        |
|    wins                 | 43292        |
| rollout/                |              |
|    ep_len_mean          | 10.1         |
|    ep_rew_mean          | 108          |
| time/                   |              |
|    fps                  | 1085         |
|    iterations           | 13           |
|    time_elapsed         | 784          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0009533452 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0001       |
|    loss                 | 1.17e+03     |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00783     |
|    value_loss           | 2.31e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 64144        |
|    invalid_moves        | 0            |
|    losses               | 15974        |
|    valid_moves          | 910000       |
|    win_rate             | 0.751        |
|    wins                 | 48170        |
| rollout/                |              |
|    ep_len_mean          | 10.1         |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 1072         |
|    iterations           | 14           |
|    time_elapsed         | 855          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0008953184 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.0136       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.21e+03     |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00733     |
|    value_loss           | 2.41e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 70956        |
|    invalid_moves        | 0            |
|    losses               | 16740        |
|    valid_moves          | 980000       |
|    win_rate             | 0.764        |
|    wins                 | 54216        |
| rollout/                |              |
|    ep_len_mean          | 11.1         |
|    ep_rew_mean          | 122          |
| time/                   |              |
|    fps                  | 1060         |
|    iterations           | 15           |
|    time_elapsed         | 927          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0008536508 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.0136       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.2e+03      |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00694     |
|    value_loss           | 2.41e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 77015         |
|    invalid_moves        | 0             |
|    losses               | 17427         |
|    valid_moves          | 1040000       |
|    win_rate             | 0.774         |
|    wins                 | 59588         |
| rollout/                |               |
|    ep_len_mean          | 9.98          |
|    ep_rew_mean          | 116           |
| time/                   |               |
|    fps                  | 1046          |
|    iterations           | 16            |
|    time_elapsed         | 1001          |
|    total_timesteps      | 1048576       |
| train/                  |               |
|    approx_kl            | 0.00075293425 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.14         |
|    explained_variance   | 0.0146        |
|    learning_rate        | 0.0001        |
|    loss                 | 1.21e+03      |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.00649      |
|    value_loss           | 2.5e+03       |
-------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/7_LSTM_Autoencoder_MaskableRecurrentPPO_20250805_005518.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 7_LSTM_Autoencoder_MaskableRecurrentPPO agent...
[0;36m-> Mean Reward: 131.96 +/- 95.19[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 8_Naive_Transformer_PPO[0m
[0;37m   model_path: models/8_Naive_Transformer_PPO_20250805_011256.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '8_Naive_Transformer_PPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=====================================================================================
Layer (type:depth-idx)                                       Param #
=====================================================================================
MaskableMultiInputActorCriticPolicy                          --
â”œâ”€TransformerFeatureExtractor: 1-1                           --
â”‚    â””â”€TinyGPT2Encoder: 2-1                                  --
â”‚    â”‚    â””â”€GPT2Model: 3-1                                   108,096
â”‚    â””â”€Linear: 2-2                                           1,664
â”œâ”€TransformerFeatureExtractor: 1-2                           (recursive)
â”‚    â””â”€TinyGPT2Encoder: 2-3                                  (recursive)
â”‚    â”‚    â””â”€GPT2Model: 3-2                                   (recursive)
â”‚    â””â”€Linear: 2-4                                           (recursive)
â”œâ”€TransformerFeatureExtractor: 1-3                           (recursive)
â”‚    â””â”€TinyGPT2Encoder: 2-5                                  (recursive)
â”‚    â”‚    â””â”€GPT2Model: 3-3                                   (recursive)
â”‚    â””â”€Linear: 2-6                                           (recursive)
â”œâ”€MlpExtractor: 1-4                                          --
â”‚    â””â”€Sequential: 2-7                                       --
â”‚    â”‚    â””â”€Linear: 3-4                                      4,160
â”‚    â”‚    â””â”€Tanh: 3-5                                        --
â”‚    â”‚    â””â”€Linear: 3-6                                      4,160
â”‚    â”‚    â””â”€Tanh: 3-7                                        --
â”‚    â””â”€Sequential: 2-8                                       --
â”‚    â”‚    â””â”€Linear: 3-8                                      4,160
â”‚    â”‚    â””â”€Tanh: 3-9                                        --
â”‚    â”‚    â””â”€Linear: 3-10                                     4,160
â”‚    â”‚    â””â”€Tanh: 3-11                                       --
â”œâ”€Linear: 1-5                                                61,230
â”œâ”€Linear: 1-6                                                65
=====================================================================================
Total params: 187,695
Trainable params: 187,695
Non-trainable params: 0
=====================================================================================
Logging to ./chess_logs/8_Naive_Transformer_PPO_1
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3069     |
|    invalid_moves   | 0        |
|    losses          | 1494     |
|    valid_moves     | 60000    |
|    win_rate        | 0.513    |
|    wins            | 1575     |
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 17       |
| time/              |          |
|    fps             | 1848     |
|    iterations      | 1        |
|    time_elapsed    | 35       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6710          |
|    invalid_moves        | 0             |
|    losses               | 3212          |
|    valid_moves          | 130000        |
|    win_rate             | 0.521         |
|    wins                 | 3498          |
| rollout/                |               |
|    ep_len_mean          | 18.4          |
|    ep_rew_mean          | 5.38          |
| time/                   |               |
|    fps                  | 1776          |
|    iterations           | 2             |
|    time_elapsed         | 73            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 0.00039118895 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.6          |
|    explained_variance   | 0.000763      |
|    learning_rate        | 0.0001        |
|    loss                 | 737           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.00429      |
|    value_loss           | 1.44e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9792          |
|    invalid_moves        | 0             |
|    losses               | 4603          |
|    valid_moves          | 190000        |
|    win_rate             | 0.53          |
|    wins                 | 5189          |
| rollout/                |               |
|    ep_len_mean          | 16.6          |
|    ep_rew_mean          | 36.4          |
| time/                   |               |
|    fps                  | 1757          |
|    iterations           | 3             |
|    time_elapsed         | 111           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00048208772 |
|    clip_fraction        | 9.16e-06      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.00264       |
|    learning_rate        | 0.0001        |
|    loss                 | 724           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00428      |
|    value_loss           | 1.47e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 13535         |
|    invalid_moves        | 0             |
|    losses               | 6147          |
|    valid_moves          | 260000        |
|    win_rate             | 0.546         |
|    wins                 | 7388          |
| rollout/                |               |
|    ep_len_mean          | 19.6          |
|    ep_rew_mean          | 27.7          |
| time/                   |               |
|    fps                  | 1746          |
|    iterations           | 4             |
|    time_elapsed         | 150           |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 0.00068897166 |
|    clip_fraction        | 0.000378      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.004         |
|    learning_rate        | 0.0001        |
|    loss                 | 760           |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.00491      |
|    value_loss           | 1.45e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 16920         |
|    invalid_moves        | 0             |
|    losses               | 7433          |
|    valid_moves          | 320000        |
|    win_rate             | 0.561         |
|    wins                 | 9487          |
| rollout/                |               |
|    ep_len_mean          | 18.5          |
|    ep_rew_mean          | 69            |
| time/                   |               |
|    fps                  | 1738          |
|    iterations           | 5             |
|    time_elapsed         | 188           |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 0.00092051894 |
|    clip_fraction        | 0.000542      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.56         |
|    explained_variance   | 0.00549       |
|    learning_rate        | 0.0001        |
|    loss                 | 759           |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.00519      |
|    value_loss           | 1.49e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 21100        |
|    invalid_moves        | 0            |
|    losses               | 8821         |
|    valid_moves          | 390000       |
|    win_rate             | 0.582        |
|    wins                 | 12279        |
| rollout/                |              |
|    ep_len_mean          | 16.6         |
|    ep_rew_mean          | 53.6         |
| time/                   |              |
|    fps                  | 1731         |
|    iterations           | 6            |
|    time_elapsed         | 227          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0011245436 |
|    clip_fraction        | 0.00122      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.00607      |
|    learning_rate        | 0.0001       |
|    loss                 | 785          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00557     |
|    value_loss           | 1.58e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 24920        |
|    invalid_moves        | 0            |
|    losses               | 9898         |
|    valid_moves          | 450000       |
|    win_rate             | 0.603        |
|    wins                 | 15022        |
| rollout/                |              |
|    ep_len_mean          | 16.2         |
|    ep_rew_mean          | 60.1         |
| time/                   |              |
|    fps                  | 1723         |
|    iterations           | 7            |
|    time_elapsed         | 266          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0013868436 |
|    clip_fraction        | 0.00165      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.00663      |
|    learning_rate        | 0.0001       |
|    loss                 | 848          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00618     |
|    value_loss           | 1.66e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 29722        |
|    invalid_moves        | 0            |
|    losses               | 11085        |
|    valid_moves          | 520000       |
|    win_rate             | 0.627        |
|    wins                 | 18637        |
| rollout/                |              |
|    ep_len_mean          | 15.4         |
|    ep_rew_mean          | 96.7         |
| time/                   |              |
|    fps                  | 1715         |
|    iterations           | 8            |
|    time_elapsed         | 305          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0012881929 |
|    clip_fraction        | 0.00098      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.00804      |
|    learning_rate        | 0.0001       |
|    loss                 | 897          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00555     |
|    value_loss           | 1.76e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 34210        |
|    invalid_moves        | 0            |
|    losses               | 12098        |
|    valid_moves          | 580000       |
|    win_rate             | 0.646        |
|    wins                 | 22112        |
| rollout/                |              |
|    ep_len_mean          | 12.7         |
|    ep_rew_mean          | 89.6         |
| time/                   |              |
|    fps                  | 1707         |
|    iterations           | 9            |
|    time_elapsed         | 345          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0015630606 |
|    clip_fraction        | 0.00116      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.00754      |
|    learning_rate        | 0.0001       |
|    loss                 | 934          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00604     |
|    value_loss           | 1.89e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 39874        |
|    invalid_moves        | 0            |
|    losses               | 13192        |
|    valid_moves          | 650000       |
|    win_rate             | 0.669        |
|    wins                 | 26682        |
| rollout/                |              |
|    ep_len_mean          | 12.4         |
|    ep_rew_mean          | 92.3         |
| time/                   |              |
|    fps                  | 1699         |
|    iterations           | 10           |
|    time_elapsed         | 385          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0016493942 |
|    clip_fraction        | 0.0011       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | 0.00731      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.01e+03     |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.006       |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 46025        |
|    invalid_moves        | 0            |
|    losses               | 14206        |
|    valid_moves          | 720000       |
|    win_rate             | 0.691        |
|    wins                 | 31819        |
| rollout/                |              |
|    ep_len_mean          | 9.76         |
|    ep_rew_mean          | 113          |
| time/                   |              |
|    fps                  | 1690         |
|    iterations           | 11           |
|    time_elapsed         | 426          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0015623474 |
|    clip_fraction        | 0.00105      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.00792      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.07e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00519     |
|    value_loss           | 2.17e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 51696        |
|    invalid_moves        | 0            |
|    losses               | 15096        |
|    valid_moves          | 780000       |
|    win_rate             | 0.708        |
|    wins                 | 36600        |
| rollout/                |              |
|    ep_len_mean          | 11.3         |
|    ep_rew_mean          | 106          |
| time/                   |              |
|    fps                  | 1682         |
|    iterations           | 12           |
|    time_elapsed         | 467          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0012591847 |
|    clip_fraction        | 0.00116      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.00863      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.15e+03     |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00348     |
|    value_loss           | 2.35e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 58736        |
|    invalid_moves        | 0            |
|    losses               | 16007        |
|    valid_moves          | 850000       |
|    win_rate             | 0.727        |
|    wins                 | 42729        |
| rollout/                |              |
|    ep_len_mean          | 10.7         |
|    ep_rew_mean          | 122          |
| time/                   |              |
|    fps                  | 1675         |
|    iterations           | 13           |
|    time_elapsed         | 508          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0011202208 |
|    clip_fraction        | 0.00141      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.00873      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.26e+03     |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00226     |
|    value_loss           | 2.48e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 65032         |
|    invalid_moves        | 0             |
|    losses               | 16786         |
|    valid_moves          | 910000        |
|    win_rate             | 0.742         |
|    wins                 | 48246         |
| rollout/                |               |
|    ep_len_mean          | 10.5          |
|    ep_rew_mean          | 134           |
| time/                   |               |
|    fps                  | 1668          |
|    iterations           | 14            |
|    time_elapsed         | 549           |
|    total_timesteps      | 917504        |
| train/                  |               |
|    approx_kl            | 0.00092035305 |
|    clip_fraction        | 0.00171       |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.25         |
|    explained_variance   | 0.00858       |
|    learning_rate        | 0.0001        |
|    loss                 | 1.29e+03      |
|    n_updates            | 130           |
|    policy_gradient_loss | -0.00124      |
|    value_loss           | 2.63e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 72854        |
|    invalid_moves        | 0            |
|    losses               | 17624        |
|    valid_moves          | 980000       |
|    win_rate             | 0.758        |
|    wins                 | 55230        |
| rollout/                |              |
|    ep_len_mean          | 9.99         |
|    ep_rew_mean          | 98.3         |
| time/                   |              |
|    fps                  | 1662         |
|    iterations           | 15           |
|    time_elapsed         | 591          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0008254531 |
|    clip_fraction        | 0.00212      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.00967      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.3e+03      |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.000441    |
|    value_loss           | 2.73e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 79674        |
|    invalid_moves        | 0            |
|    losses               | 18404        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.769        |
|    wins                 | 61270        |
| rollout/                |              |
|    ep_len_mean          | 9.62         |
|    ep_rew_mean          | 124          |
| time/                   |              |
|    fps                  | 1656         |
|    iterations           | 16           |
|    time_elapsed         | 633          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0007037113 |
|    clip_fraction        | 0.00241      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.00987      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.45e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | 0.00015      |
|    value_loss           | 2.87e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/8_Naive_Transformer_PPO_20250805_011256.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 8_Naive_Transformer_PPO agent...
[0;36m-> Mean Reward: 162.92 +/- 8.16[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 1_PPO[0m
[0;37m   model_path: models/1_PPO_20250805_012346.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '1_PPO' agent using device 'cuda' and '16' parallel environments...
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
MultiInputActorCriticPolicy              --
â”œâ”€CombinedExtractor: 1-1                 --
â”‚    â””â”€ModuleDict: 2-1                   --
â”‚    â”‚    â””â”€Flatten: 3-1                 --
â”‚    â”‚    â””â”€Flatten: 3-2                 --
â”œâ”€CombinedExtractor: 1-2                 --
â”‚    â””â”€ModuleDict: 2-2                   --
â”‚    â”‚    â””â”€Flatten: 3-3                 --
â”‚    â”‚    â””â”€Flatten: 3-4                 --
â”œâ”€CombinedExtractor: 1-3                 --
â”‚    â””â”€ModuleDict: 2-3                   --
â”‚    â”‚    â””â”€Flatten: 3-5                 --
â”‚    â”‚    â””â”€Flatten: 3-6                 --
â”œâ”€MlpExtractor: 1-4                      --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-7                  61,952
â”‚    â”‚    â””â”€Tanh: 3-8                    --
â”‚    â”‚    â””â”€Linear: 3-9                  4,160
â”‚    â”‚    â””â”€Tanh: 3-10                   --
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-11                 61,952
â”‚    â”‚    â””â”€Tanh: 3-12                   --
â”‚    â”‚    â””â”€Linear: 3-13                 4,160
â”‚    â”‚    â””â”€Tanh: 3-14                   --
â”œâ”€Linear: 1-5                            61,230
â”œâ”€Linear: 1-6                            65
=================================================================
Total params: 193,519
Trainable params: 193,519
Non-trainable params: 0
=================================================================
Logging to ./chess_logs/1_PPO_2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 100      |
|    ep_rew_mean     | -9.96    |
| time/              |          |
|    fps             | 5875     |
|    iterations      | 1        |
|    time_elapsed    | 11       |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -9.93        |
| time/                   |              |
|    fps                  | 5539         |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 0.0010592227 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.85        |
|    explained_variance   | -7.42        |
|    learning_rate        | 0.0001       |
|    loss                 | -0.0714      |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.0023      |
|    value_loss           | 0.275        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 100         |
|    ep_rew_mean          | -9.88       |
| time/                   |             |
|    fps                  | 5455        |
|    iterations           | 3           |
|    time_elapsed         | 36          |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.001171216 |
|    clip_fraction        | 0.0019      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.85       |
|    explained_variance   | -7.81       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0763     |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00439    |
|    value_loss           | 0.00359     |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 1            |
|    invalid_moves        | 257212       |
|    losses               | 0            |
|    valid_moves          | 2788         |
|    win_rate             | 1            |
|    wins                 | 1            |
| rollout/                |              |
|    ep_len_mean          | 99.9         |
|    ep_rew_mean          | -8.35        |
| time/                   |              |
|    fps                  | 5402         |
|    iterations           | 4            |
|    time_elapsed         | 48           |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0012568735 |
|    clip_fraction        | 0.00231      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.84        |
|    explained_variance   | -4.48        |
|    learning_rate        | 0.0001       |
|    loss                 | -0.0773      |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00468     |
|    value_loss           | 0.00322      |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 5             |
|    invalid_moves        | 316327        |
|    losses               | 2             |
|    valid_moves          | 3673          |
|    win_rate             | 0.6           |
|    wins                 | 3             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.96         |
| time/                   |               |
|    fps                  | 5358          |
|    iterations           | 5             |
|    time_elapsed         | 61            |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 0.00051399914 |
|    clip_fraction        | 0.000189      |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.84         |
|    explained_variance   | -0.000797     |
|    learning_rate        | 0.0001        |
|    loss                 | 0.801         |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.0014       |
|    value_loss           | 0.865         |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 7             |
|    invalid_moves        | 385342        |
|    losses               | 3             |
|    valid_moves          | 4658          |
|    win_rate             | 0.571         |
|    wins                 | 4             |
| rollout/                |               |
|    ep_len_mean          | 99.2          |
|    ep_rew_mean          | -9.82         |
| time/                   |               |
|    fps                  | 5312          |
|    iterations           | 6             |
|    time_elapsed         | 74            |
|    total_timesteps      | 393216        |
| train/                  |               |
|    approx_kl            | 0.00028170238 |
|    clip_fraction        | 0.000737      |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.84         |
|    explained_variance   | -0.00218      |
|    learning_rate        | 0.0001        |
|    loss                 | 0.712         |
|    n_updates            | 50            |
|    policy_gradient_loss | -0.0011       |
|    value_loss           | 1.29          |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9             |
|    invalid_moves        | 444470        |
|    losses               | 5             |
|    valid_moves          | 5530          |
|    win_rate             | 0.444         |
|    wins                 | 4             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.9          |
| time/                   |               |
|    fps                  | 5267          |
|    iterations           | 7             |
|    time_elapsed         | 87            |
|    total_timesteps      | 458752        |
| train/                  |               |
|    approx_kl            | 0.00031871093 |
|    clip_fraction        | 1.98e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.84         |
|    explained_variance   | 0.00104       |
|    learning_rate        | 0.0001        |
|    loss                 | 0.0122        |
|    n_updates            | 60            |
|    policy_gradient_loss | -0.00108      |
|    value_loss           | 1.29          |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 11           |
|    invalid_moves        | 513329       |
|    losses               | 6            |
|    valid_moves          | 6671         |
|    win_rate             | 0.455        |
|    wins                 | 5            |
| rollout/                |              |
|    ep_len_mean          | 99.7         |
|    ep_rew_mean          | -8.38        |
| time/                   |              |
|    fps                  | 5224         |
|    iterations           | 8            |
|    time_elapsed         | 100          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0013932018 |
|    clip_fraction        | 0.00423      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.83        |
|    explained_variance   | -0.00292     |
|    learning_rate        | 0.0001       |
|    loss                 | -0.0661      |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00227     |
|    value_loss           | 0.431        |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 13            |
|    invalid_moves        | 572320        |
|    losses               | 6             |
|    valid_moves          | 7680          |
|    win_rate             | 0.538         |
|    wins                 | 7             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.96         |
| time/                   |               |
|    fps                  | 5193          |
|    iterations           | 9             |
|    time_elapsed         | 113           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 0.00041509743 |
|    clip_fraction        | 0.0004        |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.83         |
|    explained_variance   | 0.00196       |
|    learning_rate        | 0.0001        |
|    loss                 | 0.00685       |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.00126      |
|    value_loss           | 1.28          |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 18           |
|    invalid_moves        | 641005       |
|    losses               | 9            |
|    valid_moves          | 8995         |
|    win_rate             | 0.5          |
|    wins                 | 9            |
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -9.84        |
| time/                   |              |
|    fps                  | 5154         |
|    iterations           | 10           |
|    time_elapsed         | 127          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0016004478 |
|    clip_fraction        | 0.00653      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.83        |
|    explained_variance   | -0.0178      |
|    learning_rate        | 0.0001       |
|    loss                 | -0.0769      |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00284     |
|    value_loss           | 0.438        |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 21           |
|    invalid_moves        | 709686       |
|    losses               | 11           |
|    valid_moves          | 10314        |
|    win_rate             | 0.476        |
|    wins                 | 10           |
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -9.91        |
| time/                   |              |
|    fps                  | 5126         |
|    iterations           | 11           |
|    time_elapsed         | 140          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0003466098 |
|    clip_fraction        | 0.000999     |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.82        |
|    explained_variance   | 0.00186      |
|    learning_rate        | 0.0001       |
|    loss                 | 0.00824      |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00121     |
|    value_loss           | 2.14         |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 27            |
|    invalid_moves        | 768498        |
|    losses               | 12            |
|    valid_moves          | 11502         |
|    win_rate             | 0.556         |
|    wins                 | 15            |
| rollout/                |               |
|    ep_len_mean          | 99.7          |
|    ep_rew_mean          | -6.65         |
| time/                   |               |
|    fps                  | 5090          |
|    iterations           | 12            |
|    time_elapsed         | 154           |
|    total_timesteps      | 786432        |
| train/                  |               |
|    approx_kl            | 0.00050239795 |
|    clip_fraction        | 0.00179       |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.82         |
|    explained_variance   | 0.00144       |
|    learning_rate        | 0.0001        |
|    loss                 | 0.856         |
|    n_updates            | 110           |
|    policy_gradient_loss | -0.00121      |
|    value_loss           | 1.29          |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 31            |
|    invalid_moves        | 837175        |
|    losses               | 13            |
|    valid_moves          | 12825         |
|    win_rate             | 0.581         |
|    wins                 | 18            |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.91         |
| time/                   |               |
|    fps                  | 5064          |
|    iterations           | 13            |
|    time_elapsed         | 168           |
|    total_timesteps      | 851968        |
| train/                  |               |
|    approx_kl            | 0.00051993475 |
|    clip_fraction        | 0.00331       |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.82         |
|    explained_variance   | 0.00171       |
|    learning_rate        | 0.0001        |
|    loss                 | 0.0146        |
|    n_updates            | 120           |
|    policy_gradient_loss | -0.00169      |
|    value_loss           | 3.02          |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 39           |
|    invalid_moves        | 895886       |
|    losses               | 17           |
|    valid_moves          | 14114        |
|    win_rate             | 0.564        |
|    wins                 | 22           |
| rollout/                |              |
|    ep_len_mean          | 99.4         |
|    ep_rew_mean          | -8.19        |
| time/                   |              |
|    fps                  | 5037         |
|    iterations           | 14           |
|    time_elapsed         | 182          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0007197679 |
|    clip_fraction        | 0.00207      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.81        |
|    explained_variance   | 0.000578     |
|    learning_rate        | 0.0001       |
|    loss                 | 0.787        |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00145     |
|    value_loss           | 1.29         |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 44           |
|    invalid_moves        | 964340       |
|    losses               | 17           |
|    valid_moves          | 15660        |
|    win_rate             | 0.614        |
|    wins                 | 27           |
| rollout/                |              |
|    ep_len_mean          | 99.6         |
|    ep_rew_mean          | -8.23        |
| time/                   |              |
|    fps                  | 5017         |
|    iterations           | 15           |
|    time_elapsed         | 195          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0005669214 |
|    clip_fraction        | 0.00239      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.81        |
|    explained_variance   | 0.000167     |
|    learning_rate        | 0.0001       |
|    loss                 | 4            |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00163     |
|    value_loss           | 3.86         |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 52          |
|    invalid_moves        | 1022976     |
|    losses               | 18          |
|    valid_moves          | 17024       |
|    win_rate             | 0.654       |
|    wins                 | 34          |
| rollout/                |             |
|    ep_len_mean          | 99.6        |
|    ep_rew_mean          | -8.22       |
| time/                   |             |
|    fps                  | 4991        |
|    iterations           | 16          |
|    time_elapsed         | 210         |
|    total_timesteps      | 1048576     |
| train/                  |             |
|    approx_kl            | 0.000633704 |
|    clip_fraction        | 0.0032      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.81       |
|    explained_variance   | -0.000104   |
|    learning_rate        | 0.0001      |
|    loss                 | 0.815       |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0016     |
|    value_loss           | 1.74        |
-----------------------------------------
[0;32m-> Model saved on models/1_PPO_20250805_012346.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =False, original_step=False
Evaluating 1_PPO agent...
[0;36m-> Mean Reward: -10.00 +/- 0.00[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 2_MaskablePPO_Baseline[0m
[0;37m   model_path: models/2_MaskablePPO_Baseline_20250805_012731.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '2_MaskablePPO_Baseline' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
Active env processes: 16
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
MaskableMultiInputActorCriticPolicy      --
â”œâ”€CombinedExtractor: 1-1                 --
â”‚    â””â”€ModuleDict: 2-1                   --
â”‚    â”‚    â””â”€Flatten: 3-1                 --
â”œâ”€CombinedExtractor: 1-2                 --
â”‚    â””â”€ModuleDict: 2-2                   --
â”‚    â”‚    â””â”€Flatten: 3-2                 --
â”œâ”€CombinedExtractor: 1-3                 --
â”‚    â””â”€ModuleDict: 2-3                   --
â”‚    â”‚    â””â”€Flatten: 3-3                 --
â”œâ”€MlpExtractor: 1-4                      --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-4                  1,664
â”‚    â”‚    â””â”€Tanh: 3-5                    --
â”‚    â”‚    â””â”€Linear: 3-6                  4,160
â”‚    â”‚    â””â”€Tanh: 3-7                    --
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-8                  1,664
â”‚    â”‚    â””â”€Tanh: 3-9                    --
â”‚    â”‚    â””â”€Linear: 3-10                 4,160
â”‚    â”‚    â””â”€Tanh: 3-11                   --
â”œâ”€Linear: 1-5                            61,230
â”œâ”€Linear: 1-6                            65
=================================================================
Total params: 72,943
Trainable params: 72,943
Non-trainable params: 0
=================================================================
Logging to ./chess_logs/2_MaskablePPO_Baseline_2
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3058     |
|    invalid_moves   | 0        |
|    losses          | 1505     |
|    valid_moves     | 60000    |
|    win_rate        | 0.508    |
|    wins            | 1553     |
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 12.9     |
| time/              |          |
|    fps             | 2473     |
|    iterations      | 1        |
|    time_elapsed    | 26       |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 6640         |
|    invalid_moves        | 0            |
|    losses               | 3217         |
|    valid_moves          | 130000       |
|    win_rate             | 0.516        |
|    wins                 | 3423         |
| rollout/                |              |
|    ep_len_mean          | 19.2         |
|    ep_rew_mean          | 20.2         |
| time/                   |              |
|    fps                  | 2376         |
|    iterations           | 2            |
|    time_elapsed         | 55           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 0.0001235703 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | -0.000661    |
|    learning_rate        | 0.0001       |
|    loss                 | 703          |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00188     |
|    value_loss           | 1.44e+03     |
------------------------------------------
--------------------------------------------
| custom/                 |                |
|    draws                | 0              |
|    episodes             | 9750           |
|    invalid_moves        | 0              |
|    losses               | 4642           |
|    valid_moves          | 190000         |
|    win_rate             | 0.524          |
|    wins                 | 5108           |
| rollout/                |                |
|    ep_len_mean          | 18.3           |
|    ep_rew_mean          | 26.7           |
| time/                   |                |
|    fps                  | 2352           |
|    iterations           | 3              |
|    time_elapsed         | 83             |
|    total_timesteps      | 196608         |
| train/                  |                |
|    approx_kl            | 0.000113867354 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -2.59          |
|    explained_variance   | -0.000264      |
|    learning_rate        | 0.0001         |
|    loss                 | 741            |
|    n_updates            | 20             |
|    policy_gradient_loss | -0.00198       |
|    value_loss           | 1.44e+03       |
--------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 13454         |
|    invalid_moves        | 0             |
|    losses               | 6287          |
|    valid_moves          | 260000        |
|    win_rate             | 0.533         |
|    wins                 | 7167          |
| rollout/                |               |
|    ep_len_mean          | 18.6          |
|    ep_rew_mean          | 42.9          |
| time/                   |               |
|    fps                  | 2341          |
|    iterations           | 4             |
|    time_elapsed         | 111           |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 0.00022503063 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.000655      |
|    learning_rate        | 0.0001        |
|    loss                 | 726           |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.00282      |
|    value_loss           | 1.46e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 16653         |
|    invalid_moves        | 0             |
|    losses               | 7667          |
|    valid_moves          | 320000        |
|    win_rate             | 0.54          |
|    wins                 | 8986          |
| rollout/                |               |
|    ep_len_mean          | 19.8          |
|    ep_rew_mean          | 2.23          |
| time/                   |               |
|    fps                  | 2331          |
|    iterations           | 5             |
|    time_elapsed         | 140           |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 0.00017589668 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00123       |
|    learning_rate        | 0.0001        |
|    loss                 | 739           |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.00265      |
|    value_loss           | 1.49e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 20365        |
|    invalid_moves        | 0            |
|    losses               | 9332         |
|    valid_moves          | 390000       |
|    win_rate             | 0.542        |
|    wins                 | 11033        |
| rollout/                |              |
|    ep_len_mean          | 16.2         |
|    ep_rew_mean          | 33.8         |
| time/                   |              |
|    fps                  | 2324         |
|    iterations           | 6            |
|    time_elapsed         | 169          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0002070592 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.00225      |
|    learning_rate        | 0.0001       |
|    loss                 | 738          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.003       |
|    value_loss           | 1.5e+03      |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 23674        |
|    invalid_moves        | 0            |
|    losses               | 10678        |
|    valid_moves          | 450000       |
|    win_rate             | 0.549        |
|    wins                 | 12996        |
| rollout/                |              |
|    ep_len_mean          | 17.5         |
|    ep_rew_mean          | 52.3         |
| time/                   |              |
|    fps                  | 2319         |
|    iterations           | 7            |
|    time_elapsed         | 197          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0003640998 |
|    clip_fraction        | 0.000121     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.00278      |
|    learning_rate        | 0.0001       |
|    loss                 | 736          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00405     |
|    value_loss           | 1.5e+03      |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 27626         |
|    invalid_moves        | 0             |
|    losses               | 12124         |
|    valid_moves          | 520000        |
|    win_rate             | 0.561         |
|    wins                 | 15502         |
| rollout/                |               |
|    ep_len_mean          | 18.1          |
|    ep_rew_mean          | 50.9          |
| time/                   |               |
|    fps                  | 2314          |
|    iterations           | 8             |
|    time_elapsed         | 226           |
|    total_timesteps      | 524288        |
| train/                  |               |
|    approx_kl            | 0.00051916286 |
|    clip_fraction        | 0.000516      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.56         |
|    explained_variance   | 0.00337       |
|    learning_rate        | 0.0001        |
|    loss                 | 781           |
|    n_updates            | 70            |
|    policy_gradient_loss | -0.00538      |
|    value_loss           | 1.54e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 31156        |
|    invalid_moves        | 0            |
|    losses               | 13323        |
|    valid_moves          | 580000       |
|    win_rate             | 0.572        |
|    wins                 | 17833        |
| rollout/                |              |
|    ep_len_mean          | 16.4         |
|    ep_rew_mean          | 59.7         |
| time/                   |              |
|    fps                  | 2308         |
|    iterations           | 9            |
|    time_elapsed         | 255          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0007529658 |
|    clip_fraction        | 0.00112      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.00431      |
|    learning_rate        | 0.0001       |
|    loss                 | 813          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00622     |
|    value_loss           | 1.59e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 35479        |
|    invalid_moves        | 0            |
|    losses               | 14726        |
|    valid_moves          | 650000       |
|    win_rate             | 0.585        |
|    wins                 | 20753        |
| rollout/                |              |
|    ep_len_mean          | 18.2         |
|    ep_rew_mean          | 57.5         |
| time/                   |              |
|    fps                  | 2302         |
|    iterations           | 10           |
|    time_elapsed         | 284          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0008663694 |
|    clip_fraction        | 0.000851     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.00439      |
|    learning_rate        | 0.0001       |
|    loss                 | 816          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00645     |
|    value_loss           | 1.65e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 40037         |
|    invalid_moves        | 0             |
|    losses               | 16059         |
|    valid_moves          | 720000        |
|    win_rate             | 0.599         |
|    wins                 | 23978         |
| rollout/                |               |
|    ep_len_mean          | 15.6          |
|    ep_rew_mean          | 62.5          |
| time/                   |               |
|    fps                  | 2294          |
|    iterations           | 11            |
|    time_elapsed         | 314           |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 0.00079744484 |
|    clip_fraction        | 0.000146      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.53         |
|    explained_variance   | 0.00475       |
|    learning_rate        | 0.0001        |
|    loss                 | 839           |
|    n_updates            | 100           |
|    policy_gradient_loss | -0.00759      |
|    value_loss           | 1.72e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 44201        |
|    invalid_moves        | 0            |
|    losses               | 17137        |
|    valid_moves          | 780000       |
|    win_rate             | 0.612        |
|    wins                 | 27064        |
| rollout/                |              |
|    ep_len_mean          | 13.3         |
|    ep_rew_mean          | 73.1         |
| time/                   |              |
|    fps                  | 2287         |
|    iterations           | 12           |
|    time_elapsed         | 343          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0014370813 |
|    clip_fraction        | 0.00184      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.00508      |
|    learning_rate        | 0.0001       |
|    loss                 | 901          |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00889     |
|    value_loss           | 1.81e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 49525        |
|    invalid_moves        | 0            |
|    losses               | 18355        |
|    valid_moves          | 850000       |
|    win_rate             | 0.629        |
|    wins                 | 31170        |
| rollout/                |              |
|    ep_len_mean          | 12.7         |
|    ep_rew_mean          | 68.7         |
| time/                   |              |
|    fps                  | 2277         |
|    iterations           | 13           |
|    time_elapsed         | 374          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0017148331 |
|    clip_fraction        | 0.00145      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.00647      |
|    learning_rate        | 0.0001       |
|    loss                 | 950          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.0108      |
|    value_loss           | 1.91e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 54519        |
|    invalid_moves        | 0            |
|    losses               | 19316        |
|    valid_moves          | 910000       |
|    win_rate             | 0.646        |
|    wins                 | 35203        |
| rollout/                |              |
|    ep_len_mean          | 10.8         |
|    ep_rew_mean          | 103          |
| time/                   |              |
|    fps                  | 2266         |
|    iterations           | 14           |
|    time_elapsed         | 404          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0020168521 |
|    clip_fraction        | 0.00225      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.00749      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.06e+03     |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.0115      |
|    value_loss           | 2.08e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 60856        |
|    invalid_moves        | 0            |
|    losses               | 20384        |
|    valid_moves          | 980000       |
|    win_rate             | 0.665        |
|    wins                 | 40472        |
| rollout/                |              |
|    ep_len_mean          | 11.9         |
|    ep_rew_mean          | 103          |
| time/                   |              |
|    fps                  | 2256         |
|    iterations           | 15           |
|    time_elapsed         | 435          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0021247503 |
|    clip_fraction        | 0.00136      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.00858      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.11e+03     |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.0104      |
|    value_loss           | 2.25e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 66644        |
|    invalid_moves        | 0            |
|    losses               | 21220        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.682        |
|    wins                 | 45424        |
| rollout/                |              |
|    ep_len_mean          | 9.62         |
|    ep_rew_mean          | 136          |
| time/                   |              |
|    fps                  | 2245         |
|    iterations           | 16           |
|    time_elapsed         | 467          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0015900724 |
|    clip_fraction        | 0.000528     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.0103       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.21e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00912     |
|    value_loss           | 2.4e+03      |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/2_MaskablePPO_Baseline_20250805_012731.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 2_MaskablePPO_Baseline agent...
[0;36m-> Mean Reward: 162.25 +/- 5.06[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 3_MaskableRecurrentPPO[0m
[0;37m   model_path: models/3_MaskableRecurrentPPO_20250805_013530.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '3_MaskableRecurrentPPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableRecurrentMultiInputActorCriticPolicy  --
â”œâ”€CombinedExtractor: 1-1                      --
â”‚    â””â”€ModuleDict: 2-1                        --
â”‚    â”‚    â””â”€Flatten: 3-1                      --
â”œâ”€CombinedExtractor: 1-2                      --
â”‚    â””â”€ModuleDict: 2-2                        --
â”‚    â”‚    â””â”€Flatten: 3-2                      --
â”œâ”€CombinedExtractor: 1-3                      --
â”‚    â””â”€ModuleDict: 2-3                        --
â”‚    â”‚    â””â”€Flatten: 3-3                      --
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-4                        --
â”‚    â”‚    â””â”€Linear: 3-4                       16,448
â”‚    â”‚    â””â”€Tanh: 3-5                         --
â”‚    â”‚    â””â”€Linear: 3-6                       4,160
â”‚    â”‚    â””â”€Tanh: 3-7                         --
â”‚    â””â”€Sequential: 2-5                        --
â”‚    â”‚    â””â”€Linear: 3-8                       16,448
â”‚    â”‚    â””â”€Tanh: 3-9                         --
â”‚    â”‚    â””â”€Linear: 3-10                      4,160
â”‚    â”‚    â””â”€Tanh: 3-11                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
â”œâ”€LSTM: 1-7                                   289,792
â”œâ”€LSTM: 1-8                                   289,792
======================================================================
Total params: 682,095
Trainable params: 682,095
Non-trainable params: 0
======================================================================
Logging to ./chess_logs/3_MaskableRecurrentPPO_2
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3078     |
|    invalid_moves   | 0        |
|    losses          | 1488     |
|    valid_moves     | 60000    |
|    win_rate        | 0.517    |
|    wins            | 1590     |
| rollout/           |          |
|    ep_len_mean     | 19.9     |
|    ep_rew_mean     | -29.6    |
| time/              |          |
|    fps             | 2129     |
|    iterations      | 1        |
|    time_elapsed    | 30       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6632          |
|    invalid_moves        | 0             |
|    losses               | 3249          |
|    valid_moves          | 130000        |
|    win_rate             | 0.51          |
|    wins                 | 3383          |
| rollout/                |               |
|    ep_len_mean          | 18.9          |
|    ep_rew_mean          | -9.12         |
| time/                   |               |
|    fps                  | 1529          |
|    iterations           | 2             |
|    time_elapsed         | 85            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 1.5095293e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 8.67e-05      |
|    learning_rate        | 0.0001        |
|    loss                 | 727           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000584     |
|    value_loss           | 1.45e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9716          |
|    invalid_moves        | 0             |
|    losses               | 4730          |
|    valid_moves          | 190000        |
|    win_rate             | 0.513         |
|    wins                 | 4986          |
| rollout/                |               |
|    ep_len_mean          | 18.4          |
|    ep_rew_mean          | -2            |
| time/                   |               |
|    fps                  | 1405          |
|    iterations           | 3             |
|    time_elapsed         | 139           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 2.5449752e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.00236       |
|    learning_rate        | 0.0001        |
|    loss                 | 712           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.000636     |
|    value_loss           | 1.42e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13417        |
|    invalid_moves        | 0            |
|    losses               | 6443         |
|    valid_moves          | 260000       |
|    win_rate             | 0.52         |
|    wins                 | 6974         |
| rollout/                |              |
|    ep_len_mean          | 21.5         |
|    ep_rew_mean          | 19.9         |
| time/                   |              |
|    fps                  | 1348         |
|    iterations           | 4            |
|    time_elapsed         | 194          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 2.943258e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.00471      |
|    learning_rate        | 0.0001       |
|    loss                 | 708          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.000768    |
|    value_loss           | 1.45e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 16489         |
|    invalid_moves        | 0             |
|    losses               | 7877          |
|    valid_moves          | 320000        |
|    win_rate             | 0.522         |
|    wins                 | 8612          |
| rollout/                |               |
|    ep_len_mean          | 19.9          |
|    ep_rew_mean          | -0.417        |
| time/                   |               |
|    fps                  | 1321          |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 2.9304127e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.00504       |
|    learning_rate        | 0.0001        |
|    loss                 | 756           |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.000846     |
|    value_loss           | 1.48e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 20132         |
|    invalid_moves        | 0             |
|    losses               | 9595          |
|    valid_moves          | 390000        |
|    win_rate             | 0.523         |
|    wins                 | 10537         |
| rollout/                |               |
|    ep_len_mean          | 23.9          |
|    ep_rew_mean          | 14.6          |
| time/                   |               |
|    fps                  | 1299          |
|    iterations           | 6             |
|    time_elapsed         | 302           |
|    total_timesteps      | 393216        |
| train/                  |               |
|    approx_kl            | 2.7978589e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00697       |
|    learning_rate        | 0.0001        |
|    loss                 | 703           |
|    n_updates            | 50            |
|    policy_gradient_loss | -0.000776     |
|    value_loss           | 1.44e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 23251         |
|    invalid_moves        | 0             |
|    losses               | 11022         |
|    valid_moves          | 450000        |
|    win_rate             | 0.526         |
|    wins                 | 12229         |
| rollout/                |               |
|    ep_len_mean          | 19.4          |
|    ep_rew_mean          | 8.41          |
| time/                   |               |
|    fps                  | 1285          |
|    iterations           | 7             |
|    time_elapsed         | 356           |
|    total_timesteps      | 458752        |
| train/                  |               |
|    approx_kl            | 3.1294683e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00819       |
|    learning_rate        | 0.0001        |
|    loss                 | 691           |
|    n_updates            | 60            |
|    policy_gradient_loss | -0.000895     |
|    value_loss           | 1.45e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 26910        |
|    invalid_moves        | 0            |
|    losses               | 12688        |
|    valid_moves          | 520000       |
|    win_rate             | 0.529        |
|    wins                 | 14222        |
| rollout/                |              |
|    ep_len_mean          | 18.6         |
|    ep_rew_mean          | 4.59         |
| time/                   |              |
|    fps                  | 1274         |
|    iterations           | 8            |
|    time_elapsed         | 411          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 2.837819e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.00901      |
|    learning_rate        | 0.0001       |
|    loss                 | 731          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.000898    |
|    value_loss           | 1.45e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 30041         |
|    invalid_moves        | 0             |
|    losses               | 14105         |
|    valid_moves          | 580000        |
|    win_rate             | 0.53          |
|    wins                 | 15936         |
| rollout/                |               |
|    ep_len_mean          | 19.7          |
|    ep_rew_mean          | 48.7          |
| time/                   |               |
|    fps                  | 1268          |
|    iterations           | 9             |
|    time_elapsed         | 464           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 2.4714313e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.0103        |
|    learning_rate        | 0.0001        |
|    loss                 | 764           |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.000793     |
|    value_loss           | 1.47e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 33742         |
|    invalid_moves        | 0             |
|    losses               | 15735         |
|    valid_moves          | 650000        |
|    win_rate             | 0.534         |
|    wins                 | 18007         |
| rollout/                |               |
|    ep_len_mean          | 17.6          |
|    ep_rew_mean          | 2.24          |
| time/                   |               |
|    fps                  | 1261          |
|    iterations           | 10            |
|    time_elapsed         | 519           |
|    total_timesteps      | 655360        |
| train/                  |               |
|    approx_kl            | 1.9623443e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.0103        |
|    learning_rate        | 0.0001        |
|    loss                 | 729           |
|    n_updates            | 90            |
|    policy_gradient_loss | -0.000763     |
|    value_loss           | 1.45e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 37491         |
|    invalid_moves        | 0             |
|    losses               | 17421         |
|    valid_moves          | 720000        |
|    win_rate             | 0.535         |
|    wins                 | 20070         |
| rollout/                |               |
|    ep_len_mean          | 17.7          |
|    ep_rew_mean          | 31.9          |
| time/                   |               |
|    fps                  | 1255          |
|    iterations           | 11            |
|    time_elapsed         | 574           |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 2.7959177e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.0103        |
|    learning_rate        | 0.0001        |
|    loss                 | 763           |
|    n_updates            | 100           |
|    policy_gradient_loss | -0.00096      |
|    value_loss           | 1.48e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 40707         |
|    invalid_moves        | 0             |
|    losses               | 18736         |
|    valid_moves          | 780000        |
|    win_rate             | 0.54          |
|    wins                 | 21971         |
| rollout/                |               |
|    ep_len_mean          | 21.5          |
|    ep_rew_mean          | 16.3          |
| time/                   |               |
|    fps                  | 1251          |
|    iterations           | 12            |
|    time_elapsed         | 628           |
|    total_timesteps      | 786432        |
| train/                  |               |
|    approx_kl            | 2.8760662e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.0104        |
|    learning_rate        | 0.0001        |
|    loss                 | 731           |
|    n_updates            | 110           |
|    policy_gradient_loss | -0.000993     |
|    value_loss           | 1.49e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 44445         |
|    invalid_moves        | 0             |
|    losses               | 20305         |
|    valid_moves          | 850000        |
|    win_rate             | 0.543         |
|    wins                 | 24140         |
| rollout/                |               |
|    ep_len_mean          | 19.5          |
|    ep_rew_mean          | -1.34         |
| time/                   |               |
|    fps                  | 1245          |
|    iterations           | 13            |
|    time_elapsed         | 683           |
|    total_timesteps      | 851968        |
| train/                  |               |
|    approx_kl            | 4.3037282e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.0126        |
|    learning_rate        | 0.0001        |
|    loss                 | 748           |
|    n_updates            | 120           |
|    policy_gradient_loss | -0.00125      |
|    value_loss           | 1.49e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 47665         |
|    invalid_moves        | 0             |
|    losses               | 21672         |
|    valid_moves          | 910000        |
|    win_rate             | 0.545         |
|    wins                 | 25993         |
| rollout/                |               |
|    ep_len_mean          | 22.6          |
|    ep_rew_mean          | 33.7          |
| time/                   |               |
|    fps                  | 1241          |
|    iterations           | 14            |
|    time_elapsed         | 739           |
|    total_timesteps      | 917504        |
| train/                  |               |
|    approx_kl            | 2.9553865e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.0103        |
|    learning_rate        | 0.0001        |
|    loss                 | 729           |
|    n_updates            | 130           |
|    policy_gradient_loss | -0.00109      |
|    value_loss           | 1.48e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 51413         |
|    invalid_moves        | 0             |
|    losses               | 23225         |
|    valid_moves          | 980000        |
|    win_rate             | 0.548         |
|    wins                 | 28188         |
| rollout/                |               |
|    ep_len_mean          | 18.8          |
|    ep_rew_mean          | 45.5          |
| time/                   |               |
|    fps                  | 1237          |
|    iterations           | 15            |
|    time_elapsed         | 794           |
|    total_timesteps      | 983040        |
| train/                  |               |
|    approx_kl            | 1.7254522e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.0123        |
|    learning_rate        | 0.0001        |
|    loss                 | 738           |
|    n_updates            | 140           |
|    policy_gradient_loss | -0.00081      |
|    value_loss           | 1.49e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 54656         |
|    invalid_moves        | 0             |
|    losses               | 24596         |
|    valid_moves          | 1040000       |
|    win_rate             | 0.55          |
|    wins                 | 30060         |
| rollout/                |               |
|    ep_len_mean          | 18.3          |
|    ep_rew_mean          | 32.1          |
| time/                   |               |
|    fps                  | 1234          |
|    iterations           | 16            |
|    time_elapsed         | 849           |
|    total_timesteps      | 1048576       |
| train/                  |               |
|    approx_kl            | 1.6114951e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.0127        |
|    learning_rate        | 0.0001        |
|    loss                 | 731           |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.000788     |
|    value_loss           | 1.49e+03      |
-------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/3_MaskableRecurrentPPO_20250805_013530.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 3_MaskableRecurrentPPO agent...
[0;36m-> Mean Reward: 154.99 +/- 44.71[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/boards.npy[0m
[0;37m   weights_file_path: weights/ae_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 4_FF_Autoencoder_MaskablePPO[0m
[0;37m   model_path: models/4_FF_Autoencoder_MaskablePPO_20250805_015014.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
MaskableMultiInputActorCriticPolicy      --
â”œâ”€FrozenAEFeatureExtractor: 1-1          --
â”‚    â””â”€Sequential: 2-1                   --
â”‚    â”‚    â””â”€Flatten: 3-1                 --
â”‚    â”‚    â””â”€Linear: 3-2                  (1,664)
â”‚    â”‚    â””â”€ReLU: 3-3                    --
â”‚    â”‚    â””â”€Linear: 3-4                  (520)
â”œâ”€FrozenAEFeatureExtractor: 1-2          (recursive)
â”‚    â””â”€Sequential: 2-2                   (recursive)
â”‚    â”‚    â””â”€Flatten: 3-5                 --
â”‚    â”‚    â””â”€Linear: 3-6                  (recursive)
â”‚    â”‚    â””â”€ReLU: 3-7                    --
â”‚    â”‚    â””â”€Linear: 3-8                  (recursive)
â”œâ”€FrozenAEFeatureExtractor: 1-3          (recursive)
â”‚    â””â”€Sequential: 2-3                   (recursive)
â”‚    â”‚    â””â”€Flatten: 3-9                 --
â”‚    â”‚    â””â”€Linear: 3-10                 (recursive)
â”‚    â”‚    â””â”€ReLU: 3-11                   --
â”‚    â”‚    â””â”€Linear: 3-12                 (recursive)
â”œâ”€MlpExtractor: 1-4                      --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-13                 576
â”‚    â”‚    â””â”€Tanh: 3-14                   --
â”‚    â”‚    â””â”€Linear: 3-15                 4,160
â”‚    â”‚    â””â”€Tanh: 3-16                   --
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-17                 576
â”‚    â”‚    â””â”€Tanh: 3-18                   --
â”‚    â”‚    â””â”€Linear: 3-19                 4,160
â”‚    â”‚    â””â”€Tanh: 3-20                   --
â”œâ”€Linear: 1-5                            61,230
â”œâ”€Linear: 1-6                            65
=================================================================
Total params: 72,951
Trainable params: 70,767
Non-trainable params: 2,184
=================================================================
Logging to ./chess_logs/4_FF_Autoencoder_MaskablePPO_2
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3181     |
|    invalid_moves   | 0        |
|    losses          | 1616     |
|    valid_moves     | 60000    |
|    win_rate        | 0.492    |
|    wins            | 1565     |
| rollout/           |          |
|    ep_len_mean     | 19       |
|    ep_rew_mean     | 11.6     |
| time/              |          |
|    fps             | 2443     |
|    iterations      | 1        |
|    time_elapsed    | 26       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6815          |
|    invalid_moves        | 0             |
|    losses               | 3312          |
|    valid_moves          | 130000        |
|    win_rate             | 0.514         |
|    wins                 | 3503          |
| rollout/                |               |
|    ep_len_mean          | 19.6          |
|    ep_rew_mean          | 0.505         |
| time/                   |               |
|    fps                  | 2353          |
|    iterations           | 2             |
|    time_elapsed         | 55            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 0.00041682916 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 8.26e-05      |
|    learning_rate        | 0.0001        |
|    loss                 | 711           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.0028       |
|    value_loss           | 1.5e+03       |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9972          |
|    invalid_moves        | 0             |
|    losses               | 4766          |
|    valid_moves          | 190000        |
|    win_rate             | 0.522         |
|    wins                 | 5206          |
| rollout/                |               |
|    ep_len_mean          | 20.5          |
|    ep_rew_mean          | 10.6          |
| time/                   |               |
|    fps                  | 2328          |
|    iterations           | 3             |
|    time_elapsed         | 84            |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00028652546 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.000127      |
|    learning_rate        | 0.0001        |
|    loss                 | 717           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00231      |
|    value_loss           | 1.46e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 13683         |
|    invalid_moves        | 0             |
|    losses               | 6422          |
|    valid_moves          | 260000        |
|    win_rate             | 0.531         |
|    wins                 | 7261          |
| rollout/                |               |
|    ep_len_mean          | 20.1          |
|    ep_rew_mean          | 10.2          |
| time/                   |               |
|    fps                  | 2315          |
|    iterations           | 4             |
|    time_elapsed         | 113           |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 0.00070357753 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.000166      |
|    learning_rate        | 0.0001        |
|    loss                 | 760           |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.00348      |
|    value_loss           | 1.48e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 17002        |
|    invalid_moves        | 0            |
|    losses               | 7751         |
|    valid_moves          | 320000       |
|    win_rate             | 0.544        |
|    wins                 | 9251         |
| rollout/                |              |
|    ep_len_mean          | 19           |
|    ep_rew_mean          | 44.1         |
| time/                   |              |
|    fps                  | 2305         |
|    iterations           | 5            |
|    time_elapsed         | 142          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0021128613 |
|    clip_fraction        | 0.000751     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.000197     |
|    learning_rate        | 0.0001       |
|    loss                 | 754          |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00628     |
|    value_loss           | 1.5e+03      |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 21046        |
|    invalid_moves        | 0            |
|    losses               | 9265         |
|    valid_moves          | 390000       |
|    win_rate             | 0.56         |
|    wins                 | 11781        |
| rollout/                |              |
|    ep_len_mean          | 16.9         |
|    ep_rew_mean          | 38.5         |
| time/                   |              |
|    fps                  | 2295         |
|    iterations           | 6            |
|    time_elapsed         | 171          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0015476362 |
|    clip_fraction        | 2.44e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.000384     |
|    learning_rate        | 0.0001       |
|    loss                 | 788          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00662     |
|    value_loss           | 1.55e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 24521        |
|    invalid_moves        | 0            |
|    losses               | 10457        |
|    valid_moves          | 450000       |
|    win_rate             | 0.574        |
|    wins                 | 14064        |
| rollout/                |              |
|    ep_len_mean          | 18.2         |
|    ep_rew_mean          | 52.5         |
| time/                   |              |
|    fps                  | 2289         |
|    iterations           | 7            |
|    time_elapsed         | 200          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0014136082 |
|    clip_fraction        | 4.27e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.00025      |
|    learning_rate        | 0.0001       |
|    loss                 | 788          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00633     |
|    value_loss           | 1.63e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 28924        |
|    invalid_moves        | 0            |
|    losses               | 11772        |
|    valid_moves          | 520000       |
|    win_rate             | 0.593        |
|    wins                 | 17152        |
| rollout/                |              |
|    ep_len_mean          | 15.6         |
|    ep_rew_mean          | 46.7         |
| time/                   |              |
|    fps                  | 2280         |
|    iterations           | 8            |
|    time_elapsed         | 229          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0015170644 |
|    clip_fraction        | 0.000125     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.000401     |
|    learning_rate        | 0.0001       |
|    loss                 | 845          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00729     |
|    value_loss           | 1.63e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 32873        |
|    invalid_moves        | 0            |
|    losses               | 12827        |
|    valid_moves          | 580000       |
|    win_rate             | 0.61         |
|    wins                 | 20046        |
| rollout/                |              |
|    ep_len_mean          | 13           |
|    ep_rew_mean          | 65.7         |
| time/                   |              |
|    fps                  | 2269         |
|    iterations           | 9            |
|    time_elapsed         | 259          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0014050691 |
|    clip_fraction        | 5.04e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.000273     |
|    learning_rate        | 0.0001       |
|    loss                 | 870          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00794     |
|    value_loss           | 1.76e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 37664        |
|    invalid_moves        | 0            |
|    losses               | 14010        |
|    valid_moves          | 650000       |
|    win_rate             | 0.628        |
|    wins                 | 23654        |
| rollout/                |              |
|    ep_len_mean          | 13.3         |
|    ep_rew_mean          | 102          |
| time/                   |              |
|    fps                  | 2261         |
|    iterations           | 10           |
|    time_elapsed         | 289          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0013750775 |
|    clip_fraction        | 3.05e-06     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.000462     |
|    learning_rate        | 0.0001       |
|    loss                 | 934          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00819     |
|    value_loss           | 1.84e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 42817       |
|    invalid_moves        | 0           |
|    losses               | 15209       |
|    valid_moves          | 720000      |
|    win_rate             | 0.645       |
|    wins                 | 27608       |
| rollout/                |             |
|    ep_len_mean          | 13.4        |
|    ep_rew_mean          | 85.3        |
| time/                   |             |
|    fps                  | 2252        |
|    iterations           | 11          |
|    time_elapsed         | 320         |
|    total_timesteps      | 720896      |
| train/                  |             |
|    approx_kl            | 0.001435294 |
|    clip_fraction        | 1.37e-05    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0.000479    |
|    learning_rate        | 0.0001      |
|    loss                 | 930         |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00856    |
|    value_loss           | 1.89e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 47625        |
|    invalid_moves        | 0            |
|    losses               | 16149        |
|    valid_moves          | 780000       |
|    win_rate             | 0.661        |
|    wins                 | 31476        |
| rollout/                |              |
|    ep_len_mean          | 12.8         |
|    ep_rew_mean          | 89           |
| time/                   |              |
|    fps                  | 2242         |
|    iterations           | 12           |
|    time_elapsed         | 350          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0017726519 |
|    clip_fraction        | 0.000159     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.000578     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.01e+03     |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00989     |
|    value_loss           | 2.03e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 53418        |
|    invalid_moves        | 0            |
|    losses               | 17192        |
|    valid_moves          | 850000       |
|    win_rate             | 0.678        |
|    wins                 | 36226        |
| rollout/                |              |
|    ep_len_mean          | 11.4         |
|    ep_rew_mean          | 98.6         |
| time/                   |              |
|    fps                  | 2232         |
|    iterations           | 13           |
|    time_elapsed         | 381          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0015390323 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.00058      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.08e+03     |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00969     |
|    value_loss           | 2.18e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 58682        |
|    invalid_moves        | 0            |
|    losses               | 18046        |
|    valid_moves          | 910000       |
|    win_rate             | 0.692        |
|    wins                 | 40636        |
| rollout/                |              |
|    ep_len_mean          | 10.2         |
|    ep_rew_mean          | 117          |
| time/                   |              |
|    fps                  | 2223         |
|    iterations           | 14           |
|    time_elapsed         | 412          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0013388275 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.000534     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.11e+03     |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00893     |
|    value_loss           | 2.24e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 65128        |
|    invalid_moves        | 0            |
|    losses               | 18995        |
|    valid_moves          | 980000       |
|    win_rate             | 0.708        |
|    wins                 | 46133        |
| rollout/                |              |
|    ep_len_mean          | 10.9         |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 2213         |
|    iterations           | 15           |
|    time_elapsed         | 444          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0012764828 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | 0.000622     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.2e+03      |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00882     |
|    value_loss           | 2.35e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 70902        |
|    invalid_moves        | 0            |
|    losses               | 19763        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.721        |
|    wins                 | 51139        |
| rollout/                |              |
|    ep_len_mean          | 11.2         |
|    ep_rew_mean          | 104          |
| time/                   |              |
|    fps                  | 2203         |
|    iterations           | 16           |
|    time_elapsed         | 475          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0011206261 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.000606     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.22e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.0081      |
|    value_loss           | 2.45e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/4_FF_Autoencoder_MaskablePPO_20250805_015014.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 4_FF_Autoencoder_MaskablePPO agent...
[0;36m-> Mean Reward: 154.77 +/- 44.96[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/boards.npy[0m
[0;37m   weights_file_path: weights/ae_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 5_FF_Autoencoder_MaskableRecurrentPPO[0m
[0;37m   model_path: models/5_FF_Autoencoder_MaskableRecurrentPPO_20250805_015825.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '5_FF_Autoencoder_MaskableRecurrentPPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableRecurrentMultiInputActorCriticPolicy  --
â”œâ”€FrozenAEFeatureExtractor: 1-1               --
â”‚    â””â”€Sequential: 2-1                        --
â”‚    â”‚    â””â”€Flatten: 3-1                      --
â”‚    â”‚    â””â”€Linear: 3-2                       (1,664)
â”‚    â”‚    â””â”€ReLU: 3-3                         --
â”‚    â”‚    â””â”€Linear: 3-4                       (520)
â”œâ”€FrozenAEFeatureExtractor: 1-2               (recursive)
â”‚    â””â”€Sequential: 2-2                        (recursive)
â”‚    â”‚    â””â”€Flatten: 3-5                      --
â”‚    â”‚    â””â”€Linear: 3-6                       (recursive)
â”‚    â”‚    â””â”€ReLU: 3-7                         --
â”‚    â”‚    â””â”€Linear: 3-8                       (recursive)
â”œâ”€FrozenAEFeatureExtractor: 1-3               (recursive)
â”‚    â””â”€Sequential: 2-3                        (recursive)
â”‚    â”‚    â””â”€Flatten: 3-9                      --
â”‚    â”‚    â””â”€Linear: 3-10                      (recursive)
â”‚    â”‚    â””â”€ReLU: 3-11                        --
â”‚    â”‚    â””â”€Linear: 3-12                      (recursive)
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-4                        --
â”‚    â”‚    â””â”€Linear: 3-13                      16,448
â”‚    â”‚    â””â”€Tanh: 3-14                        --
â”‚    â”‚    â””â”€Linear: 3-15                      4,160
â”‚    â”‚    â””â”€Tanh: 3-16                        --
â”‚    â””â”€Sequential: 2-5                        --
â”‚    â”‚    â””â”€Linear: 3-17                      16,448
â”‚    â”‚    â””â”€Tanh: 3-18                        --
â”‚    â”‚    â””â”€Linear: 3-19                      4,160
â”‚    â”‚    â””â”€Tanh: 3-20                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
â”œâ”€LSTM: 1-7                                   272,384
â”œâ”€LSTM: 1-8                                   272,384
======================================================================
Total params: 649,463
Trainable params: 647,279
Non-trainable params: 2,184
======================================================================
Logging to ./chess_logs/5_FF_Autoencoder_MaskableRecurrentPPO_2
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3044     |
|    invalid_moves   | 0        |
|    losses          | 1481     |
|    valid_moves     | 60000    |
|    win_rate        | 0.513    |
|    wins            | 1563     |
| rollout/           |          |
|    ep_len_mean     | 19.7     |
|    ep_rew_mean     | 4.93     |
| time/              |          |
|    fps             | 2105     |
|    iterations      | 1        |
|    time_elapsed    | 31       |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 6622         |
|    invalid_moves        | 0            |
|    losses               | 3212         |
|    valid_moves          | 130000       |
|    win_rate             | 0.515        |
|    wins                 | 3410         |
| rollout/                |              |
|    ep_len_mean          | 18.2         |
|    ep_rew_mean          | -14.2        |
| time/                   |              |
|    fps                  | 1517         |
|    iterations           | 2            |
|    time_elapsed         | 86           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 5.747157e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 6.79e-06     |
|    learning_rate        | 0.0001       |
|    loss                 | 717          |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000873    |
|    value_loss           | 1.43e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 9775         |
|    invalid_moves        | 0            |
|    losses               | 4661         |
|    valid_moves          | 190000       |
|    win_rate             | 0.523        |
|    wins                 | 5114         |
| rollout/                |              |
|    ep_len_mean          | 17.3         |
|    ep_rew_mean          | 18.8         |
| time/                   |              |
|    fps                  | 1396         |
|    iterations           | 3            |
|    time_elapsed         | 140          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0006172859 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.000153     |
|    learning_rate        | 0.0001       |
|    loss                 | 755          |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00295     |
|    value_loss           | 1.45e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13466        |
|    invalid_moves        | 0            |
|    losses               | 6183         |
|    valid_moves          | 260000       |
|    win_rate             | 0.541        |
|    wins                 | 7283         |
| rollout/                |              |
|    ep_len_mean          | 17.4         |
|    ep_rew_mean          | 37           |
| time/                   |              |
|    fps                  | 1337         |
|    iterations           | 4            |
|    time_elapsed         | 195          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0037145033 |
|    clip_fraction        | 0.00651      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.000454     |
|    learning_rate        | 0.0001       |
|    loss                 | 764          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00814     |
|    value_loss           | 1.48e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 16993        |
|    invalid_moves        | 0            |
|    losses               | 7389         |
|    valid_moves          | 320000       |
|    win_rate             | 0.565        |
|    wins                 | 9604         |
| rollout/                |              |
|    ep_len_mean          | 17.1         |
|    ep_rew_mean          | 45.5         |
| time/                   |              |
|    fps                  | 1298         |
|    iterations           | 5            |
|    time_elapsed         | 252          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0073881717 |
|    clip_fraction        | 0.021        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.000807     |
|    learning_rate        | 0.0001       |
|    loss                 | 756          |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.0101      |
|    value_loss           | 1.49e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 21399        |
|    invalid_moves        | 0            |
|    losses               | 8615         |
|    valid_moves          | 390000       |
|    win_rate             | 0.597        |
|    wins                 | 12784        |
| rollout/                |              |
|    ep_len_mean          | 14.7         |
|    ep_rew_mean          | 53.4         |
| time/                   |              |
|    fps                  | 1264         |
|    iterations           | 6            |
|    time_elapsed         | 310          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0067788754 |
|    clip_fraction        | 0.0182       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.00236      |
|    learning_rate        | 0.0001       |
|    loss                 | 826          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.0126      |
|    value_loss           | 1.63e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 25492       |
|    invalid_moves        | 0           |
|    losses               | 9636        |
|    valid_moves          | 450000      |
|    win_rate             | 0.622       |
|    wins                 | 15856       |
| rollout/                |             |
|    ep_len_mean          | 14.3        |
|    ep_rew_mean          | 90.6        |
| time/                   |             |
|    fps                  | 1238        |
|    iterations           | 7           |
|    time_elapsed         | 370         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.003181605 |
|    clip_fraction        | 0.0028      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.46       |
|    explained_variance   | 0.00491     |
|    learning_rate        | 0.0001      |
|    loss                 | 907         |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0113     |
|    value_loss           | 1.76e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 30484        |
|    invalid_moves        | 0            |
|    losses               | 10719        |
|    valid_moves          | 520000       |
|    win_rate             | 0.648        |
|    wins                 | 19765        |
| rollout/                |              |
|    ep_len_mean          | 12.8         |
|    ep_rew_mean          | 86.1         |
| time/                   |              |
|    fps                  | 1211         |
|    iterations           | 8            |
|    time_elapsed         | 432          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0017278674 |
|    clip_fraction        | 7.02e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.00643      |
|    learning_rate        | 0.0001       |
|    loss                 | 910          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00962     |
|    value_loss           | 1.86e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 35040        |
|    invalid_moves        | 0            |
|    losses               | 11578        |
|    valid_moves          | 580000       |
|    win_rate             | 0.67         |
|    wins                 | 23462        |
| rollout/                |              |
|    ep_len_mean          | 11.5         |
|    ep_rew_mean          | 106          |
| time/                   |              |
|    fps                  | 1192         |
|    iterations           | 9            |
|    time_elapsed         | 494          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0014081853 |
|    clip_fraction        | 1.22e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.00922      |
|    learning_rate        | 0.0001       |
|    loss                 | 956          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00856     |
|    value_loss           | 1.94e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 40474        |
|    invalid_moves        | 0            |
|    losses               | 12577        |
|    valid_moves          | 650000       |
|    win_rate             | 0.689        |
|    wins                 | 27897        |
| rollout/                |              |
|    ep_len_mean          | 11.8         |
|    ep_rew_mean          | 112          |
| time/                   |              |
|    fps                  | 1173         |
|    iterations           | 10           |
|    time_elapsed         | 558          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0010993248 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.0106       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.03e+03     |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00836     |
|    value_loss           | 2.03e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 46259        |
|    invalid_moves        | 0            |
|    losses               | 13550        |
|    valid_moves          | 720000       |
|    win_rate             | 0.707        |
|    wins                 | 32709        |
| rollout/                |              |
|    ep_len_mean          | 12.4         |
|    ep_rew_mean          | 92.7         |
| time/                   |              |
|    fps                  | 1155         |
|    iterations           | 11           |
|    time_elapsed         | 623          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0012869282 |
|    clip_fraction        | 1.68e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.0112       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.04e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00858     |
|    value_loss           | 2.07e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 51373        |
|    invalid_moves        | 0            |
|    losses               | 14316        |
|    valid_moves          | 780000       |
|    win_rate             | 0.721        |
|    wins                 | 37057        |
| rollout/                |              |
|    ep_len_mean          | 12.5         |
|    ep_rew_mean          | 105          |
| time/                   |              |
|    fps                  | 1138         |
|    iterations           | 12           |
|    time_elapsed         | 690          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0012808884 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.0106       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.11e+03     |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00864     |
|    value_loss           | 2.18e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 57789        |
|    invalid_moves        | 0            |
|    losses               | 15206        |
|    valid_moves          | 850000       |
|    win_rate             | 0.737        |
|    wins                 | 42583        |
| rollout/                |              |
|    ep_len_mean          | 11.1         |
|    ep_rew_mean          | 100          |
| time/                   |              |
|    fps                  | 1122         |
|    iterations           | 13           |
|    time_elapsed         | 758          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0010363981 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.0117       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.13e+03     |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00733     |
|    value_loss           | 2.24e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 63493        |
|    invalid_moves        | 0            |
|    losses               | 15996        |
|    valid_moves          | 910000       |
|    win_rate             | 0.748        |
|    wins                 | 47497        |
| rollout/                |              |
|    ep_len_mean          | 10.4         |
|    ep_rew_mean          | 132          |
| time/                   |              |
|    fps                  | 1107         |
|    iterations           | 14           |
|    time_elapsed         | 828          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0011095024 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.0122       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.22e+03     |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00807     |
|    value_loss           | 2.4e+03      |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 70459        |
|    invalid_moves        | 0            |
|    losses               | 16864        |
|    valid_moves          | 980000       |
|    win_rate             | 0.761        |
|    wins                 | 53595        |
| rollout/                |              |
|    ep_len_mean          | 9.14         |
|    ep_rew_mean          | 135          |
| time/                   |              |
|    fps                  | 1092         |
|    iterations           | 15           |
|    time_elapsed         | 900          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0010333584 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.0121       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.21e+03     |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00744     |
|    value_loss           | 2.46e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 76514        |
|    invalid_moves        | 0            |
|    losses               | 17547        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.771        |
|    wins                 | 58967        |
| rollout/                |              |
|    ep_len_mean          | 11.2         |
|    ep_rew_mean          | 116          |
| time/                   |              |
|    fps                  | 1076         |
|    iterations           | 16           |
|    time_elapsed         | 973          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0008909963 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.0132       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.3e+03      |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00698     |
|    value_loss           | 2.57e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/5_FF_Autoencoder_MaskableRecurrentPPO_20250805_015825.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 5_FF_Autoencoder_MaskableRecurrentPPO agent...
[0;36m-> Mean Reward: 149.41 +/- 64.03[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/board_seqs.npy[0m
[0;37m   weights_file_path: weights/ae_rnn_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 6_LSTM_Autoencoder_MaskablePPO[0m
[0;37m   model_path: models/6_LSTM_Autoencoder_MaskablePPO_20250805_021529.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '6_LSTM_Autoencoder_MaskablePPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/DRL/Chess_6_LSTM_Autoencoder_MaskablePPO.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ae.load_state_dict(torch.load(AE_WEIGHTS_PATH, map_location=device))
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableMultiInputActorCriticPolicy           --
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-1        --
â”‚    â””â”€SimpleLSTMAutoencoder: 2-1             --
â”‚    â”‚    â””â”€LSTM: 3-1                         (23,296)
â”‚    â”‚    â””â”€Linear: 3-2                       (520)
â”‚    â”‚    â””â”€Linear: 3-3                       (576)
â”‚    â”‚    â””â”€LSTM: 3-4                         (33,280)
â”‚    â”‚    â””â”€Linear: 3-5                       (1,625)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-2             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-6                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-7                       (recursive)
â”‚    â”‚    â””â”€Linear: 3-8                       (recursive)
â”‚    â”‚    â””â”€LSTM: 3-9                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-10                      (recursive)
â”‚    â””â”€LSTM: 2-3                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-2        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-4             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-11                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-12                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-13                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-14                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-15                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-5             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-16                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-17                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-18                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-19                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-20                      (recursive)
â”‚    â””â”€LSTM: 2-6                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-3        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-7             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-21                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-22                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-23                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-24                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-25                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-8             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-26                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-27                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-28                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-29                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-30                      (recursive)
â”‚    â””â”€LSTM: 2-9                              (recursive)
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-10                       --
â”‚    â”‚    â””â”€Linear: 3-31                      576
â”‚    â”‚    â””â”€Tanh: 3-32                        --
â”‚    â”‚    â””â”€Linear: 3-33                      4,160
â”‚    â”‚    â””â”€Tanh: 3-34                        --
â”‚    â””â”€Sequential: 2-11                       --
â”‚    â”‚    â””â”€Linear: 3-35                      576
â”‚    â”‚    â””â”€Tanh: 3-36                        --
â”‚    â”‚    â””â”€Linear: 3-37                      4,160
â”‚    â”‚    â””â”€Tanh: 3-38                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
======================================================================
Total params: 130,064
Trainable params: 70,767
Non-trainable params: 59,297
======================================================================
Logging to ./chess_logs/6_LSTM_Autoencoder_MaskablePPO_2
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3061     |
|    invalid_moves   | 0        |
|    losses          | 1542     |
|    valid_moves     | 60000    |
|    win_rate        | 0.496    |
|    wins            | 1519     |
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 7.54     |
| time/              |          |
|    fps             | 2382     |
|    iterations      | 1        |
|    time_elapsed    | 27       |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 6666         |
|    invalid_moves        | 0            |
|    losses               | 3232         |
|    valid_moves          | 130000       |
|    win_rate             | 0.515        |
|    wins                 | 3434         |
| rollout/                |              |
|    ep_len_mean          | 19           |
|    ep_rew_mean          | -22.2        |
| time/                   |              |
|    fps                  | 2298         |
|    iterations           | 2            |
|    time_elapsed         | 57           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 8.532418e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | -1.8e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 734          |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00114     |
|    value_loss           | 1.44e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 9791         |
|    invalid_moves        | 0            |
|    losses               | 4714         |
|    valid_moves          | 190000       |
|    win_rate             | 0.519        |
|    wins                 | 5077         |
| rollout/                |              |
|    ep_len_mean          | 20.9         |
|    ep_rew_mean          | 39.7         |
| time/                   |              |
|    fps                  | 2274         |
|    iterations           | 3            |
|    time_elapsed         | 86           |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 5.527059e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 5.9e-06      |
|    learning_rate        | 0.0001       |
|    loss                 | 710          |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.001       |
|    value_loss           | 1.45e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 13371         |
|    invalid_moves        | 0             |
|    losses               | 6325          |
|    valid_moves          | 260000        |
|    win_rate             | 0.527         |
|    wins                 | 7046          |
| rollout/                |               |
|    ep_len_mean          | 19.9          |
|    ep_rew_mean          | -19.2         |
| time/                   |               |
|    fps                  | 2265          |
|    iterations           | 4             |
|    time_elapsed         | 115           |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 0.00017312712 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 2.14e-05      |
|    learning_rate        | 0.0001        |
|    loss                 | 742           |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.00167      |
|    value_loss           | 1.46e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 16611         |
|    invalid_moves        | 0             |
|    losses               | 7794          |
|    valid_moves          | 320000        |
|    win_rate             | 0.531         |
|    wins                 | 8817          |
| rollout/                |               |
|    ep_len_mean          | 18            |
|    ep_rew_mean          | 20.7          |
| time/                   |               |
|    fps                  | 2252          |
|    iterations           | 5             |
|    time_elapsed         | 145           |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 0.00043743194 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 4.6e-05       |
|    learning_rate        | 0.0001        |
|    loss                 | 749           |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.00272      |
|    value_loss           | 1.45e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 20415        |
|    invalid_moves        | 0            |
|    losses               | 9397         |
|    valid_moves          | 390000       |
|    win_rate             | 0.54         |
|    wins                 | 11018        |
| rollout/                |              |
|    ep_len_mean          | 20           |
|    ep_rew_mean          | 6.24         |
| time/                   |              |
|    fps                  | 2248         |
|    iterations           | 6            |
|    time_elapsed         | 174          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0009408357 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 4.81e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 770          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00424     |
|    value_loss           | 1.53e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 23669        |
|    invalid_moves        | 0            |
|    losses               | 10696        |
|    valid_moves          | 450000       |
|    win_rate             | 0.548        |
|    wins                 | 12973        |
| rollout/                |              |
|    ep_len_mean          | 18           |
|    ep_rew_mean          | 18.8         |
| time/                   |              |
|    fps                  | 2242         |
|    iterations           | 7            |
|    time_elapsed         | 204          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0010322934 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 8.88e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 725          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.0049      |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 27641        |
|    invalid_moves        | 0            |
|    losses               | 12126        |
|    valid_moves          | 520000       |
|    win_rate             | 0.561        |
|    wins                 | 15515        |
| rollout/                |              |
|    ep_len_mean          | 16.9         |
|    ep_rew_mean          | 52.8         |
| time/                   |              |
|    fps                  | 2237         |
|    iterations           | 8            |
|    time_elapsed         | 234          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0010394094 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.000117     |
|    learning_rate        | 0.0001       |
|    loss                 | 752          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00527     |
|    value_loss           | 1.54e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 31154       |
|    invalid_moves        | 0           |
|    losses               | 13387       |
|    valid_moves          | 580000      |
|    win_rate             | 0.57        |
|    wins                 | 17767       |
| rollout/                |             |
|    ep_len_mean          | 17.4        |
|    ep_rew_mean          | 36.1        |
| time/                   |             |
|    fps                  | 2231        |
|    iterations           | 9           |
|    time_elapsed         | 264         |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.000538499 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.55       |
|    explained_variance   | 0.000121    |
|    learning_rate        | 0.0001      |
|    loss                 | 770         |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00423    |
|    value_loss           | 1.59e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 35419        |
|    invalid_moves        | 0            |
|    losses               | 14700        |
|    valid_moves          | 650000       |
|    win_rate             | 0.585        |
|    wins                 | 20719        |
| rollout/                |              |
|    ep_len_mean          | 14.7         |
|    ep_rew_mean          | 50.6         |
| time/                   |              |
|    fps                  | 2225         |
|    iterations           | 10           |
|    time_elapsed         | 294          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0007107891 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.000152     |
|    learning_rate        | 0.0001       |
|    loss                 | 824          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00461     |
|    value_loss           | 1.64e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 39755         |
|    invalid_moves        | 0             |
|    losses               | 16030         |
|    valid_moves          | 720000        |
|    win_rate             | 0.597         |
|    wins                 | 23725         |
| rollout/                |               |
|    ep_len_mean          | 16.5          |
|    ep_rew_mean          | 51.8          |
| time/                   |               |
|    fps                  | 2220          |
|    iterations           | 11            |
|    time_elapsed         | 324           |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 0.00065155886 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.52         |
|    explained_variance   | 0.000167      |
|    learning_rate        | 0.0001        |
|    loss                 | 866           |
|    n_updates            | 100           |
|    policy_gradient_loss | -0.00513      |
|    value_loss           | 1.71e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 43731        |
|    invalid_moves        | 0            |
|    losses               | 17123        |
|    valid_moves          | 780000       |
|    win_rate             | 0.608        |
|    wins                 | 26608        |
| rollout/                |              |
|    ep_len_mean          | 16.5         |
|    ep_rew_mean          | 70.3         |
| time/                   |              |
|    fps                  | 2214         |
|    iterations           | 12           |
|    time_elapsed         | 355          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0007404551 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.000152     |
|    learning_rate        | 0.0001       |
|    loss                 | 855          |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00519     |
|    value_loss           | 1.72e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 48412         |
|    invalid_moves        | 0             |
|    losses               | 18321         |
|    valid_moves          | 850000        |
|    win_rate             | 0.622         |
|    wins                 | 30091         |
| rollout/                |               |
|    ep_len_mean          | 15.5          |
|    ep_rew_mean          | 77.8          |
| time/                   |               |
|    fps                  | 2208          |
|    iterations           | 13            |
|    time_elapsed         | 385           |
|    total_timesteps      | 851968        |
| train/                  |               |
|    approx_kl            | 0.00086117245 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.49         |
|    explained_variance   | 0.000196      |
|    learning_rate        | 0.0001        |
|    loss                 | 910           |
|    n_updates            | 120           |
|    policy_gradient_loss | -0.00624      |
|    value_loss           | 1.82e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 52608         |
|    invalid_moves        | 0             |
|    losses               | 19275         |
|    valid_moves          | 910000        |
|    win_rate             | 0.634         |
|    wins                 | 33333         |
| rollout/                |               |
|    ep_len_mean          | 14.7          |
|    ep_rew_mean          | 107           |
| time/                   |               |
|    fps                  | 2203          |
|    iterations           | 14            |
|    time_elapsed         | 416           |
|    total_timesteps      | 917504        |
| train/                  |               |
|    approx_kl            | 0.00090929226 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.47         |
|    explained_variance   | 0.000202      |
|    learning_rate        | 0.0001        |
|    loss                 | 913           |
|    n_updates            | 130           |
|    policy_gradient_loss | -0.00663      |
|    value_loss           | 1.86e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 57766         |
|    invalid_moves        | 0             |
|    losses               | 20393         |
|    valid_moves          | 980000        |
|    win_rate             | 0.647         |
|    wins                 | 37373         |
| rollout/                |               |
|    ep_len_mean          | 12.9          |
|    ep_rew_mean          | 112           |
| time/                   |               |
|    fps                  | 2197          |
|    iterations           | 15            |
|    time_elapsed         | 447           |
|    total_timesteps      | 983040        |
| train/                  |               |
|    approx_kl            | 0.00091615325 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.44         |
|    explained_variance   | 0.000198      |
|    learning_rate        | 0.0001        |
|    loss                 | 970           |
|    n_updates            | 140           |
|    policy_gradient_loss | -0.00694      |
|    value_loss           | 1.92e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 62344        |
|    invalid_moves        | 0            |
|    losses               | 21278        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.659        |
|    wins                 | 41066        |
| rollout/                |              |
|    ep_len_mean          | 13.7         |
|    ep_rew_mean          | 93.6         |
| time/                   |              |
|    fps                  | 2191         |
|    iterations           | 16           |
|    time_elapsed         | 478          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0010141226 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.000183     |
|    learning_rate        | 0.0001       |
|    loss                 | 989          |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00738     |
|    value_loss           | 2.01e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/6_LSTM_Autoencoder_MaskablePPO_20250805_021529.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 6_LSTM_Autoencoder_MaskablePPO agent...
[0;36m-> Mean Reward: 143.75 +/- 74.87[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/board_seqs.npy[0m
[0;37m   weights_file_path: weights/ae_rnn_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 7_LSTM_Autoencoder_MaskableRecurrentPPO[0m
[0;37m   model_path: models/7_LSTM_Autoencoder_MaskableRecurrentPPO_20250805_022343.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '7_LSTM_Autoencoder_MaskableRecurrentPPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/DRL/Chess_7_LSTM_Autoencoder_MaskableRecurrentPPO.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ae.load_state_dict(torch.load(AE_WEIGHTS_PATH, map_location=device))
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableRecurrentMultiInputActorCriticPolicy  --
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-1        --
â”‚    â””â”€SimpleLSTMAutoencoder: 2-1             --
â”‚    â”‚    â””â”€LSTM: 3-1                         (23,296)
â”‚    â”‚    â””â”€Linear: 3-2                       (520)
â”‚    â”‚    â””â”€Linear: 3-3                       (576)
â”‚    â”‚    â””â”€LSTM: 3-4                         (33,280)
â”‚    â”‚    â””â”€Linear: 3-5                       (1,625)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-2             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-6                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-7                       (recursive)
â”‚    â”‚    â””â”€Linear: 3-8                       (recursive)
â”‚    â”‚    â””â”€LSTM: 3-9                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-10                      (recursive)
â”‚    â””â”€LSTM: 2-3                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-2        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-4             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-11                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-12                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-13                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-14                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-15                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-5             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-16                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-17                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-18                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-19                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-20                      (recursive)
â”‚    â””â”€LSTM: 2-6                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-3        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-7             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-21                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-22                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-23                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-24                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-25                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-8             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-26                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-27                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-28                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-29                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-30                      (recursive)
â”‚    â””â”€LSTM: 2-9                              (recursive)
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-10                       --
â”‚    â”‚    â””â”€Linear: 3-31                      16,448
â”‚    â”‚    â””â”€Tanh: 3-32                        --
â”‚    â”‚    â””â”€Linear: 3-33                      4,160
â”‚    â”‚    â””â”€Tanh: 3-34                        --
â”‚    â””â”€Sequential: 2-11                       --
â”‚    â”‚    â””â”€Linear: 3-35                      16,448
â”‚    â”‚    â””â”€Tanh: 3-36                        --
â”‚    â”‚    â””â”€Linear: 3-37                      4,160
â”‚    â”‚    â””â”€Tanh: 3-38                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
â”œâ”€LSTM: 1-7                                   272,384
â”œâ”€LSTM: 1-8                                   272,384
======================================================================
Total params: 706,576
Trainable params: 647,279
Non-trainable params: 59,297
======================================================================
Logging to ./chess_logs/7_LSTM_Autoencoder_MaskableRecurrentPPO_2
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3100     |
|    invalid_moves   | 0        |
|    losses          | 1540     |
|    valid_moves     | 60000    |
|    win_rate        | 0.503    |
|    wins            | 1560     |
| rollout/           |          |
|    ep_len_mean     | 18.9     |
|    ep_rew_mean     | 30.9     |
| time/              |          |
|    fps             | 2039     |
|    iterations      | 1        |
|    time_elapsed    | 32       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6656          |
|    invalid_moves        | 0             |
|    losses               | 3215          |
|    valid_moves          | 130000        |
|    win_rate             | 0.517         |
|    wins                 | 3441          |
| rollout/                |               |
|    ep_len_mean          | 19.1          |
|    ep_rew_mean          | 0.204         |
| time/                   |               |
|    fps                  | 1472          |
|    iterations           | 2             |
|    time_elapsed         | 88            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 4.5939712e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | -1.67e-06     |
|    learning_rate        | 0.0001        |
|    loss                 | 716           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000818     |
|    value_loss           | 1.45e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9766          |
|    invalid_moves        | 0             |
|    losses               | 4707          |
|    valid_moves          | 190000        |
|    win_rate             | 0.518         |
|    wins                 | 5059          |
| rollout/                |               |
|    ep_len_mean          | 19.8          |
|    ep_rew_mean          | 15.4          |
| time/                   |               |
|    fps                  | 1354          |
|    iterations           | 3             |
|    time_elapsed         | 145           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00028590654 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 4.83e-05      |
|    learning_rate        | 0.0001        |
|    loss                 | 707           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00193      |
|    value_loss           | 1.44e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13535        |
|    invalid_moves        | 0            |
|    losses               | 6363         |
|    valid_moves          | 260000       |
|    win_rate             | 0.53         |
|    wins                 | 7172         |
| rollout/                |              |
|    ep_len_mean          | 18.9         |
|    ep_rew_mean          | 18.4         |
| time/                   |              |
|    fps                  | 1308         |
|    iterations           | 4            |
|    time_elapsed         | 200          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0022984091 |
|    clip_fraction        | 0.00123      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.00022      |
|    learning_rate        | 0.0001       |
|    loss                 | 726          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00569     |
|    value_loss           | 1.45e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 17012       |
|    invalid_moves        | 0           |
|    losses               | 7579        |
|    valid_moves          | 320000      |
|    win_rate             | 0.554       |
|    wins                 | 9433        |
| rollout/                |             |
|    ep_len_mean          | 17.4        |
|    ep_rew_mean          | 52          |
| time/                   |             |
|    fps                  | 1269        |
|    iterations           | 5           |
|    time_elapsed         | 258         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.011545413 |
|    clip_fraction        | 0.0511      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.57       |
|    explained_variance   | 0.00033     |
|    learning_rate        | 0.0001      |
|    loss                 | 752         |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0124     |
|    value_loss           | 1.53e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 21332        |
|    invalid_moves        | 0            |
|    losses               | 8838         |
|    valid_moves          | 390000       |
|    win_rate             | 0.586        |
|    wins                 | 12494        |
| rollout/                |              |
|    ep_len_mean          | 15.5         |
|    ep_rew_mean          | 79.9         |
| time/                   |              |
|    fps                  | 1240         |
|    iterations           | 6            |
|    time_elapsed         | 317          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0047570746 |
|    clip_fraction        | 0.00562      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.000924     |
|    learning_rate        | 0.0001       |
|    loss                 | 791          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00947     |
|    value_loss           | 1.63e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 25386        |
|    invalid_moves        | 0            |
|    losses               | 9785         |
|    valid_moves          | 450000       |
|    win_rate             | 0.615        |
|    wins                 | 15601        |
| rollout/                |              |
|    ep_len_mean          | 16.4         |
|    ep_rew_mean          | 62.5         |
| time/                   |              |
|    fps                  | 1213         |
|    iterations           | 7            |
|    time_elapsed         | 378          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0045916922 |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.00402      |
|    learning_rate        | 0.0001       |
|    loss                 | 853          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.0141      |
|    value_loss           | 1.71e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 30250       |
|    invalid_moves        | 0           |
|    losses               | 10868       |
|    valid_moves          | 520000      |
|    win_rate             | 0.641       |
|    wins                 | 19382       |
| rollout/                |             |
|    ep_len_mean          | 13.8        |
|    ep_rew_mean          | 96.1        |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 8           |
|    time_elapsed         | 441         |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.001926162 |
|    clip_fraction        | 5.04e-05    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0.00666     |
|    learning_rate        | 0.0001      |
|    loss                 | 920         |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00963    |
|    value_loss           | 1.84e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 34699        |
|    invalid_moves        | 0            |
|    losses               | 11711        |
|    valid_moves          | 580000       |
|    win_rate             | 0.662        |
|    wins                 | 22988        |
| rollout/                |              |
|    ep_len_mean          | 13.1         |
|    ep_rew_mean          | 94.7         |
| time/                   |              |
|    fps                  | 1166         |
|    iterations           | 9            |
|    time_elapsed         | 505          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0017538366 |
|    clip_fraction        | 0.000595     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.00731      |
|    learning_rate        | 0.0001       |
|    loss                 | 945          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00985     |
|    value_loss           | 1.89e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 40196        |
|    invalid_moves        | 0            |
|    losses               | 12702        |
|    valid_moves          | 650000       |
|    win_rate             | 0.684        |
|    wins                 | 27494        |
| rollout/                |              |
|    ep_len_mean          | 11.6         |
|    ep_rew_mean          | 109          |
| time/                   |              |
|    fps                  | 1145         |
|    iterations           | 10           |
|    time_elapsed         | 572          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0013623924 |
|    clip_fraction        | 3.05e-06     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.00867      |
|    learning_rate        | 0.0001       |
|    loss                 | 989          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00881     |
|    value_loss           | 1.99e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 45886        |
|    invalid_moves        | 0            |
|    losses               | 13587        |
|    valid_moves          | 720000       |
|    win_rate             | 0.704        |
|    wins                 | 32299        |
| rollout/                |              |
|    ep_len_mean          | 11.6         |
|    ep_rew_mean          | 109          |
| time/                   |              |
|    fps                  | 1128         |
|    iterations           | 11           |
|    time_elapsed         | 638          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0012240221 |
|    clip_fraction        | 2.44e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.00974      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.06e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00841     |
|    value_loss           | 2.1e+03      |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 51111        |
|    invalid_moves        | 0            |
|    losses               | 14366        |
|    valid_moves          | 780000       |
|    win_rate             | 0.719        |
|    wins                 | 36745        |
| rollout/                |              |
|    ep_len_mean          | 12.6         |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 1111         |
|    iterations           | 12           |
|    time_elapsed         | 707          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0010440723 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.011        |
|    learning_rate        | 0.0001       |
|    loss                 | 1.12e+03     |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00764     |
|    value_loss           | 2.15e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 57282        |
|    invalid_moves        | 0            |
|    losses               | 15212        |
|    valid_moves          | 850000       |
|    win_rate             | 0.734        |
|    wins                 | 42070        |
| rollout/                |              |
|    ep_len_mean          | 10.3         |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 1096         |
|    iterations           | 13           |
|    time_elapsed         | 777          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0009852389 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | 0.0112       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.16e+03     |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00769     |
|    value_loss           | 2.28e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 62849         |
|    invalid_moves        | 0             |
|    losses               | 15972         |
|    valid_moves          | 910000        |
|    win_rate             | 0.746         |
|    wins                 | 46877         |
| rollout/                |               |
|    ep_len_mean          | 11.5          |
|    ep_rew_mean          | 131           |
| time/                   |               |
|    fps                  | 1082          |
|    iterations           | 14            |
|    time_elapsed         | 847           |
|    total_timesteps      | 917504        |
| train/                  |               |
|    approx_kl            | 0.00095417944 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.22         |
|    explained_variance   | 0.0121        |
|    learning_rate        | 0.0001        |
|    loss                 | 1.15e+03      |
|    n_updates            | 130           |
|    policy_gradient_loss | -0.00739      |
|    value_loss           | 2.31e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 69598         |
|    invalid_moves        | 0             |
|    losses               | 16732         |
|    valid_moves          | 980000        |
|    win_rate             | 0.76          |
|    wins                 | 52866         |
| rollout/                |               |
|    ep_len_mean          | 10.5          |
|    ep_rew_mean          | 124           |
| time/                   |               |
|    fps                  | 1070          |
|    iterations           | 15            |
|    time_elapsed         | 918           |
|    total_timesteps      | 983040        |
| train/                  |               |
|    approx_kl            | 0.00087519165 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.19         |
|    explained_variance   | 0.0125        |
|    learning_rate        | 0.0001        |
|    loss                 | 1.18e+03      |
|    n_updates            | 140           |
|    policy_gradient_loss | -0.0069       |
|    value_loss           | 2.41e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 75496        |
|    invalid_moves        | 0            |
|    losses               | 17416        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.769        |
|    wins                 | 58080        |
| rollout/                |              |
|    ep_len_mean          | 9.91         |
|    ep_rew_mean          | 128          |
| time/                   |              |
|    fps                  | 1059         |
|    iterations           | 16           |
|    time_elapsed         | 990          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0007599791 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.0139       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.2e+03      |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00647     |
|    value_loss           | 2.49e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/7_LSTM_Autoencoder_MaskableRecurrentPPO_20250805_022343.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 7_LSTM_Autoencoder_MaskableRecurrentPPO agent...
[0;36m-> Mean Reward: 157.28 +/- 44.69[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 8_Naive_Transformer_PPO[0m
[0;37m   model_path: models/8_Naive_Transformer_PPO_20250805_024108.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '8_Naive_Transformer_PPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=====================================================================================
Layer (type:depth-idx)                                       Param #
=====================================================================================
MaskableMultiInputActorCriticPolicy                          --
â”œâ”€TransformerFeatureExtractor: 1-1                           --
â”‚    â””â”€TinyGPT2Encoder: 2-1                                  --
â”‚    â”‚    â””â”€GPT2Model: 3-1                                   108,096
â”‚    â””â”€Linear: 2-2                                           1,664
â”œâ”€TransformerFeatureExtractor: 1-2                           (recursive)
â”‚    â””â”€TinyGPT2Encoder: 2-3                                  (recursive)
â”‚    â”‚    â””â”€GPT2Model: 3-2                                   (recursive)
â”‚    â””â”€Linear: 2-4                                           (recursive)
â”œâ”€TransformerFeatureExtractor: 1-3                           (recursive)
â”‚    â””â”€TinyGPT2Encoder: 2-5                                  (recursive)
â”‚    â”‚    â””â”€GPT2Model: 3-3                                   (recursive)
â”‚    â””â”€Linear: 2-6                                           (recursive)
â”œâ”€MlpExtractor: 1-4                                          --
â”‚    â””â”€Sequential: 2-7                                       --
â”‚    â”‚    â””â”€Linear: 3-4                                      4,160
â”‚    â”‚    â””â”€Tanh: 3-5                                        --
â”‚    â”‚    â””â”€Linear: 3-6                                      4,160
â”‚    â”‚    â””â”€Tanh: 3-7                                        --
â”‚    â””â”€Sequential: 2-8                                       --
â”‚    â”‚    â””â”€Linear: 3-8                                      4,160
â”‚    â”‚    â””â”€Tanh: 3-9                                        --
â”‚    â”‚    â””â”€Linear: 3-10                                     4,160
â”‚    â”‚    â””â”€Tanh: 3-11                                       --
â”œâ”€Linear: 1-5                                                61,230
â”œâ”€Linear: 1-6                                                65
=====================================================================================
Total params: 187,695
Trainable params: 187,695
Non-trainable params: 0
=====================================================================================
Logging to ./chess_logs/8_Naive_Transformer_PPO_2
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3100     |
|    invalid_moves   | 0        |
|    losses          | 1483     |
|    valid_moves     | 60000    |
|    win_rate        | 0.522    |
|    wins            | 1617     |
| rollout/           |          |
|    ep_len_mean     | 19       |
|    ep_rew_mean     | 14.1     |
| time/              |          |
|    fps             | 1867     |
|    iterations      | 1        |
|    time_elapsed    | 35       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6729          |
|    invalid_moves        | 0             |
|    losses               | 3181          |
|    valid_moves          | 130000        |
|    win_rate             | 0.527         |
|    wins                 | 3548          |
| rollout/                |               |
|    ep_len_mean          | 19.5          |
|    ep_rew_mean          | -10.1         |
| time/                   |               |
|    fps                  | 1785          |
|    iterations           | 2             |
|    time_elapsed         | 73            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 0.00042183918 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | -0.000759     |
|    learning_rate        | 0.0001        |
|    loss                 | 743           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.00416      |
|    value_loss           | 1.45e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 9944         |
|    invalid_moves        | 0            |
|    losses               | 4537         |
|    valid_moves          | 190000       |
|    win_rate             | 0.544        |
|    wins                 | 5407         |
| rollout/                |              |
|    ep_len_mean          | 18.5         |
|    ep_rew_mean          | 40.9         |
| time/                   |              |
|    fps                  | 1762         |
|    iterations           | 3            |
|    time_elapsed         | 111          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0005008647 |
|    clip_fraction        | 5.34e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.00145      |
|    learning_rate        | 0.0001       |
|    loss                 | 721          |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00439     |
|    value_loss           | 1.46e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13669        |
|    invalid_moves        | 0            |
|    losses               | 6044         |
|    valid_moves          | 260000       |
|    win_rate             | 0.558        |
|    wins                 | 7625         |
| rollout/                |              |
|    ep_len_mean          | 18.7         |
|    ep_rew_mean          | 53.4         |
| time/                   |              |
|    fps                  | 1752         |
|    iterations           | 4            |
|    time_elapsed         | 149          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0006389634 |
|    clip_fraction        | 0.000211     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.00341      |
|    learning_rate        | 0.0001       |
|    loss                 | 737          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0044      |
|    value_loss           | 1.5e+03      |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 17085        |
|    invalid_moves        | 0            |
|    losses               | 7359         |
|    valid_moves          | 320000       |
|    win_rate             | 0.569        |
|    wins                 | 9726         |
| rollout/                |              |
|    ep_len_mean          | 19.7         |
|    ep_rew_mean          | 36.6         |
| time/                   |              |
|    fps                  | 1743         |
|    iterations           | 5            |
|    time_elapsed         | 187          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0010834492 |
|    clip_fraction        | 0.000906     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.00468      |
|    learning_rate        | 0.0001       |
|    loss                 | 734          |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00532     |
|    value_loss           | 1.49e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 21229        |
|    invalid_moves        | 0            |
|    losses               | 8682         |
|    valid_moves          | 390000       |
|    win_rate             | 0.591        |
|    wins                 | 12547        |
| rollout/                |              |
|    ep_len_mean          | 16.6         |
|    ep_rew_mean          | 60.3         |
| time/                   |              |
|    fps                  | 1734         |
|    iterations           | 6            |
|    time_elapsed         | 226          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0016721914 |
|    clip_fraction        | 0.00243      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.00598      |
|    learning_rate        | 0.0001       |
|    loss                 | 780          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00637     |
|    value_loss           | 1.58e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 25108        |
|    invalid_moves        | 0            |
|    losses               | 9758         |
|    valid_moves          | 450000       |
|    win_rate             | 0.611        |
|    wins                 | 15350        |
| rollout/                |              |
|    ep_len_mean          | 16           |
|    ep_rew_mean          | 40.9         |
| time/                   |              |
|    fps                  | 1725         |
|    iterations           | 7            |
|    time_elapsed         | 265          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0013281123 |
|    clip_fraction        | 0.00108      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.00739      |
|    learning_rate        | 0.0001       |
|    loss                 | 836          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00505     |
|    value_loss           | 1.66e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 30088       |
|    invalid_moves        | 0           |
|    losses               | 10996       |
|    valid_moves          | 520000      |
|    win_rate             | 0.635       |
|    wins                 | 19092       |
| rollout/                |             |
|    ep_len_mean          | 14.7        |
|    ep_rew_mean          | 87.2        |
| time/                   |             |
|    fps                  | 1716        |
|    iterations           | 8           |
|    time_elapsed         | 305         |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.001963569 |
|    clip_fraction        | 0.00278     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.5        |
|    explained_variance   | 0.00621     |
|    learning_rate        | 0.0001      |
|    loss                 | 898         |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00667    |
|    value_loss           | 1.8e+03     |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 34753        |
|    invalid_moves        | 0            |
|    losses               | 11944        |
|    valid_moves          | 580000       |
|    win_rate             | 0.656        |
|    wins                 | 22809        |
| rollout/                |              |
|    ep_len_mean          | 12.4         |
|    ep_rew_mean          | 99.1         |
| time/                   |              |
|    fps                  | 1707         |
|    iterations           | 9            |
|    time_elapsed         | 345          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0019669114 |
|    clip_fraction        | 0.00167      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.00721      |
|    learning_rate        | 0.0001       |
|    loss                 | 999          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00697     |
|    value_loss           | 1.95e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 40683        |
|    invalid_moves        | 0            |
|    losses               | 13019        |
|    valid_moves          | 650000       |
|    win_rate             | 0.68         |
|    wins                 | 27664        |
| rollout/                |              |
|    ep_len_mean          | 12           |
|    ep_rew_mean          | 105          |
| time/                   |              |
|    fps                  | 1697         |
|    iterations           | 10           |
|    time_elapsed         | 385          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0017026997 |
|    clip_fraction        | 0.000958     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.42        |
|    explained_variance   | 0.00794      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.08e+03     |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00612     |
|    value_loss           | 2.1e+03      |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 47011        |
|    invalid_moves        | 0            |
|    losses               | 13965        |
|    valid_moves          | 720000       |
|    win_rate             | 0.703        |
|    wins                 | 33046        |
| rollout/                |              |
|    ep_len_mean          | 8.92         |
|    ep_rew_mean          | 95           |
| time/                   |              |
|    fps                  | 1689         |
|    iterations           | 11           |
|    time_elapsed         | 426          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0013104712 |
|    clip_fraction        | 0.000815     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.00932      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.12e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00441     |
|    value_loss           | 2.29e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 52867        |
|    invalid_moves        | 0            |
|    losses               | 14789        |
|    valid_moves          | 780000       |
|    win_rate             | 0.72         |
|    wins                 | 38078        |
| rollout/                |              |
|    ep_len_mean          | 10.2         |
|    ep_rew_mean          | 133          |
| time/                   |              |
|    fps                  | 1681         |
|    iterations           | 12           |
|    time_elapsed         | 467          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0010425015 |
|    clip_fraction        | 0.00107      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.00867      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.13e+03     |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00301     |
|    value_loss           | 2.4e+03      |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 59937        |
|    invalid_moves        | 0            |
|    losses               | 15684        |
|    valid_moves          | 850000       |
|    win_rate             | 0.738        |
|    wins                 | 44253        |
| rollout/                |              |
|    ep_len_mean          | 8.98         |
|    ep_rew_mean          | 133          |
| time/                   |              |
|    fps                  | 1673         |
|    iterations           | 13           |
|    time_elapsed         | 509          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0009401805 |
|    clip_fraction        | 0.00148      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | 0.00844      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.32e+03     |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00194     |
|    value_loss           | 2.55e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 66361        |
|    invalid_moves        | 0            |
|    losses               | 16426        |
|    valid_moves          | 910000       |
|    win_rate             | 0.752        |
|    wins                 | 49935        |
| rollout/                |              |
|    ep_len_mean          | 11.1         |
|    ep_rew_mean          | 117          |
| time/                   |              |
|    fps                  | 1666         |
|    iterations           | 14           |
|    time_elapsed         | 550          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0008384799 |
|    clip_fraction        | 0.0017       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.0085       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.32e+03     |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00119     |
|    value_loss           | 2.64e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 74204         |
|    invalid_moves        | 0             |
|    losses               | 17263         |
|    valid_moves          | 980000        |
|    win_rate             | 0.767         |
|    wins                 | 56941         |
| rollout/                |               |
|    ep_len_mean          | 8.96          |
|    ep_rew_mean          | 130           |
| time/                   |               |
|    fps                  | 1659          |
|    iterations           | 15            |
|    time_elapsed         | 592           |
|    total_timesteps      | 983040        |
| train/                  |               |
|    approx_kl            | 0.00074796984 |
|    clip_fraction        | 0.00201       |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.16         |
|    explained_variance   | 0.00939       |
|    learning_rate        | 0.0001        |
|    loss                 | 1.34e+03      |
|    n_updates            | 140           |
|    policy_gradient_loss | -0.000706     |
|    value_loss           | 2.76e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 81174        |
|    invalid_moves        | 0            |
|    losses               | 17964        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.779        |
|    wins                 | 63210        |
| rollout/                |              |
|    ep_len_mean          | 9.96         |
|    ep_rew_mean          | 122          |
| time/                   |              |
|    fps                  | 1652         |
|    iterations           | 16           |
|    time_elapsed         | 634          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0006780075 |
|    clip_fraction        | 0.00228      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.00973      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.45e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.000141    |
|    value_loss           | 2.89e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/8_Naive_Transformer_PPO_20250805_024108.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 8_Naive_Transformer_PPO agent...
[0;36m-> Mean Reward: 154.97 +/- 43.89[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 1_PPO[0m
[0;37m   model_path: models/1_PPO_20250805_025158.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '1_PPO' agent using device 'cuda' and '16' parallel environments...
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
MultiInputActorCriticPolicy              --
â”œâ”€CombinedExtractor: 1-1                 --
â”‚    â””â”€ModuleDict: 2-1                   --
â”‚    â”‚    â””â”€Flatten: 3-1                 --
â”‚    â”‚    â””â”€Flatten: 3-2                 --
â”œâ”€CombinedExtractor: 1-2                 --
â”‚    â””â”€ModuleDict: 2-2                   --
â”‚    â”‚    â””â”€Flatten: 3-3                 --
â”‚    â”‚    â””â”€Flatten: 3-4                 --
â”œâ”€CombinedExtractor: 1-3                 --
â”‚    â””â”€ModuleDict: 2-3                   --
â”‚    â”‚    â””â”€Flatten: 3-5                 --
â”‚    â”‚    â””â”€Flatten: 3-6                 --
â”œâ”€MlpExtractor: 1-4                      --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-7                  61,952
â”‚    â”‚    â””â”€Tanh: 3-8                    --
â”‚    â”‚    â””â”€Linear: 3-9                  4,160
â”‚    â”‚    â””â”€Tanh: 3-10                   --
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-11                 61,952
â”‚    â”‚    â””â”€Tanh: 3-12                   --
â”‚    â”‚    â””â”€Linear: 3-13                 4,160
â”‚    â”‚    â””â”€Tanh: 3-14                   --
â”œâ”€Linear: 1-5                            61,230
â”œâ”€Linear: 1-6                            65
=================================================================
Total params: 193,519
Trainable params: 193,519
Non-trainable params: 0
=================================================================
Logging to ./chess_logs/1_PPO_3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99.4     |
|    ep_rew_mean     | -8.29    |
| time/              |          |
|    fps             | 5882     |
|    iterations      | 1        |
|    time_elapsed    | 11       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 2             |
|    invalid_moves        | 128839        |
|    losses               | 0             |
|    valid_moves          | 1161          |
|    win_rate             | 1             |
|    wins                 | 2             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.95         |
| time/                   |               |
|    fps                  | 5450          |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 0.00027715656 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.85         |
|    explained_variance   | -0.0205       |
|    learning_rate        | 0.0001        |
|    loss                 | 0.783         |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.00117      |
|    value_loss           | 0.729         |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 3             |
|    invalid_moves        | 188193        |
|    losses               | 1             |
|    valid_moves          | 1807          |
|    win_rate             | 0.667         |
|    wins                 | 2             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.94         |
| time/                   |               |
|    fps                  | 5358          |
|    iterations           | 3             |
|    time_elapsed         | 36            |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00047441444 |
|    clip_fraction        | 0.000441      |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.85         |
|    explained_variance   | -0.00663      |
|    learning_rate        | 0.0001        |
|    loss                 | -0.0725       |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00188      |
|    value_loss           | 0.435         |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 3            |
|    invalid_moves        | 257404       |
|    losses               | 1            |
|    valid_moves          | 2596         |
|    win_rate             | 0.667        |
|    wins                 | 2            |
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -9.95        |
| time/                   |              |
|    fps                  | 5296         |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0003875096 |
|    clip_fraction        | 0.000175     |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.85        |
|    explained_variance   | -0.0058      |
|    learning_rate        | 0.0001       |
|    loss                 | 0.71         |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00177     |
|    value_loss           | 0.428        |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 7            |
|    invalid_moves        | 316554       |
|    losses               | 4            |
|    valid_moves          | 3446         |
|    win_rate             | 0.429        |
|    wins                 | 3            |
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -9.89        |
| time/                   |              |
|    fps                  | 5268         |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0012164293 |
|    clip_fraction        | 0.00582      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.84        |
|    explained_variance   | -3.23        |
|    learning_rate        | 0.0001       |
|    loss                 | -0.078       |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00539     |
|    value_loss           | 0.00182      |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 8            |
|    invalid_moves        | 385591       |
|    losses               | 5            |
|    valid_moves          | 4409         |
|    win_rate             | 0.375        |
|    wins                 | 3            |
| rollout/                |              |
|    ep_len_mean          | 99.8         |
|    ep_rew_mean          | -11.5        |
| time/                   |              |
|    fps                  | 5246         |
|    iterations           | 6            |
|    time_elapsed         | 74           |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0002717264 |
|    clip_fraction        | 0.000369     |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.84        |
|    explained_variance   | -0.00422     |
|    learning_rate        | 0.0001       |
|    loss                 | 0.0142       |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.0011      |
|    value_loss           | 1.73         |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 10          |
|    invalid_moves        | 444685      |
|    losses               | 7           |
|    valid_moves          | 5315        |
|    win_rate             | 0.3         |
|    wins                 | 3           |
| rollout/                |             |
|    ep_len_mean          | 100         |
|    ep_rew_mean          | -9.92       |
| time/                   |             |
|    fps                  | 5210        |
|    iterations           | 7           |
|    time_elapsed         | 88          |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.000834666 |
|    clip_fraction        | 0.00113     |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.84       |
|    explained_variance   | -0.00606    |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0655     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00255    |
|    value_loss           | 0.431       |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 12           |
|    invalid_moves        | 513559       |
|    losses               | 9            |
|    valid_moves          | 6441         |
|    win_rate             | 0.25         |
|    wins                 | 3            |
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -9.95        |
| time/                   |              |
|    fps                  | 5167         |
|    iterations           | 8            |
|    time_elapsed         | 101          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0005634947 |
|    clip_fraction        | 0.00129      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.84        |
|    explained_variance   | 0.00167      |
|    learning_rate        | 0.0001       |
|    loss                 | 0.798        |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00137     |
|    value_loss           | 0.859        |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 13            |
|    invalid_moves        | 572513        |
|    losses               | 10            |
|    valid_moves          | 7487          |
|    win_rate             | 0.231         |
|    wins                 | 3             |
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -9.94         |
| time/                   |               |
|    fps                  | 5146          |
|    iterations           | 9             |
|    time_elapsed         | 114           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 0.00060748355 |
|    clip_fraction        | 0.00124       |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.83         |
|    explained_variance   | -0.003        |
|    learning_rate        | 0.0001        |
|    loss                 | 0.787         |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.00155      |
|    value_loss           | 0.861         |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 16           |
|    invalid_moves        | 641124       |
|    losses               | 13           |
|    valid_moves          | 8876         |
|    win_rate             | 0.188        |
|    wins                 | 3            |
| rollout/                |              |
|    ep_len_mean          | 99.8         |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 5118         |
|    iterations           | 10           |
|    time_elapsed         | 128          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0013807612 |
|    clip_fraction        | 0.0064       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.83        |
|    explained_variance   | -0.00459     |
|    learning_rate        | 0.0001       |
|    loss                 | 0.000734     |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00257     |
|    value_loss           | 0.429        |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 21            |
|    invalid_moves        | 709682        |
|    losses               | 16            |
|    valid_moves          | 10318         |
|    win_rate             | 0.238         |
|    wins                 | 5             |
| rollout/                |               |
|    ep_len_mean          | 99.5          |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 5092          |
|    iterations           | 11            |
|    time_elapsed         | 141           |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 0.00067596964 |
|    clip_fraction        | 0.00243       |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.82         |
|    explained_variance   | -0.0011       |
|    learning_rate        | 0.0001        |
|    loss                 | 1.57          |
|    n_updates            | 100           |
|    policy_gradient_loss | -0.00136      |
|    value_loss           | 1.71          |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 27           |
|    invalid_moves        | 768475       |
|    losses               | 21           |
|    valid_moves          | 11525        |
|    win_rate             | 0.222        |
|    wins                 | 6            |
| rollout/                |              |
|    ep_len_mean          | 99.7         |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 5064         |
|    iterations           | 12           |
|    time_elapsed         | 155          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0004572417 |
|    clip_fraction        | 0.00174      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.82        |
|    explained_variance   | -0.00299     |
|    learning_rate        | 0.0001       |
|    loss                 | 0.784        |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00121     |
|    value_loss           | 2.16         |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 31           |
|    invalid_moves        | 837102       |
|    losses               | 22           |
|    valid_moves          | 12898        |
|    win_rate             | 0.29         |
|    wins                 | 9            |
| rollout/                |              |
|    ep_len_mean          | 99.6         |
|    ep_rew_mean          | -8.22        |
| time/                   |              |
|    fps                  | 5041         |
|    iterations           | 13           |
|    time_elapsed         | 168          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0005999413 |
|    clip_fraction        | 0.00416      |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.82        |
|    explained_variance   | 0.0004       |
|    learning_rate        | 0.0001       |
|    loss                 | 0.869        |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.0016      |
|    value_loss           | 2.58         |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 35            |
|    invalid_moves        | 895912        |
|    losses               | 25            |
|    valid_moves          | 14088         |
|    win_rate             | 0.286         |
|    wins                 | 10            |
| rollout/                |               |
|    ep_len_mean          | 99.9          |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 5021          |
|    iterations           | 14            |
|    time_elapsed         | 182           |
|    total_timesteps      | 917504        |
| train/                  |               |
|    approx_kl            | 0.00057370757 |
|    clip_fraction        | 0.00238       |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.82         |
|    explained_variance   | -0.000409     |
|    learning_rate        | 0.0001        |
|    loss                 | 0.863         |
|    n_updates            | 130           |
|    policy_gradient_loss | -0.00141      |
|    value_loss           | 1.29          |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 40           |
|    invalid_moves        | 964501       |
|    losses               | 27           |
|    valid_moves          | 15499        |
|    win_rate             | 0.325        |
|    wins                 | 13           |
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -9.89        |
| time/                   |              |
|    fps                  | 4998         |
|    iterations           | 15           |
|    time_elapsed         | 196          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0004460028 |
|    clip_fraction        | 0.0017       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.81        |
|    explained_variance   | 0.0017       |
|    learning_rate        | 0.0001       |
|    loss                 | 0.078        |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00128     |
|    value_loss           | 1.72         |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 43            |
|    invalid_moves        | 1023278       |
|    losses               | 29            |
|    valid_moves          | 16722         |
|    win_rate             | 0.326         |
|    wins                 | 14            |
| rollout/                |               |
|    ep_len_mean          | 99.9          |
|    ep_rew_mean          | -8.26         |
| time/                   |               |
|    fps                  | 4980          |
|    iterations           | 16            |
|    time_elapsed         | 210           |
|    total_timesteps      | 1048576       |
| train/                  |               |
|    approx_kl            | 0.00043244608 |
|    clip_fraction        | 0.002         |
|    clip_range           | 0.2           |
|    entropy_loss         | -6.81         |
|    explained_variance   | -0.00103      |
|    learning_rate        | 0.0001        |
|    loss                 | 1.56          |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.00141      |
|    value_loss           | 2.14          |
-------------------------------------------
[0;32m-> Model saved on models/1_PPO_20250805_025158.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =False, original_step=False
Evaluating 1_PPO agent...
[0;36m-> Mean Reward: -10.00 +/- 0.00[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 2_MaskablePPO_Baseline[0m
[0;37m   model_path: models/2_MaskablePPO_Baseline_20250805_025544.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '2_MaskablePPO_Baseline' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
Active env processes: 16
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
MaskableMultiInputActorCriticPolicy      --
â”œâ”€CombinedExtractor: 1-1                 --
â”‚    â””â”€ModuleDict: 2-1                   --
â”‚    â”‚    â””â”€Flatten: 3-1                 --
â”œâ”€CombinedExtractor: 1-2                 --
â”‚    â””â”€ModuleDict: 2-2                   --
â”‚    â”‚    â””â”€Flatten: 3-2                 --
â”œâ”€CombinedExtractor: 1-3                 --
â”‚    â””â”€ModuleDict: 2-3                   --
â”‚    â”‚    â””â”€Flatten: 3-3                 --
â”œâ”€MlpExtractor: 1-4                      --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-4                  1,664
â”‚    â”‚    â””â”€Tanh: 3-5                    --
â”‚    â”‚    â””â”€Linear: 3-6                  4,160
â”‚    â”‚    â””â”€Tanh: 3-7                    --
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-8                  1,664
â”‚    â”‚    â””â”€Tanh: 3-9                    --
â”‚    â”‚    â””â”€Linear: 3-10                 4,160
â”‚    â”‚    â””â”€Tanh: 3-11                   --
â”œâ”€Linear: 1-5                            61,230
â”œâ”€Linear: 1-6                            65
=================================================================
Total params: 72,943
Trainable params: 72,943
Non-trainable params: 0
=================================================================
Logging to ./chess_logs/2_MaskablePPO_Baseline_3
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3075     |
|    invalid_moves   | 0        |
|    losses          | 1472     |
|    valid_moves     | 60000    |
|    win_rate        | 0.521    |
|    wins            | 1603     |
| rollout/           |          |
|    ep_len_mean     | 18.8     |
|    ep_rew_mean     | 16.2     |
| time/              |          |
|    fps             | 2484     |
|    iterations      | 1        |
|    time_elapsed    | 26       |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 6710         |
|    invalid_moves        | 0            |
|    losses               | 3193         |
|    valid_moves          | 130000       |
|    win_rate             | 0.524        |
|    wins                 | 3517         |
| rollout/                |              |
|    ep_len_mean          | 20.1         |
|    ep_rew_mean          | 33.5         |
| time/                   |              |
|    fps                  | 2385         |
|    iterations           | 2            |
|    time_elapsed         | 54           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 9.797899e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | -8.11e-06    |
|    learning_rate        | 0.0001       |
|    loss                 | 741          |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00185     |
|    value_loss           | 1.45e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9840          |
|    invalid_moves        | 0             |
|    losses               | 4659          |
|    valid_moves          | 190000        |
|    win_rate             | 0.527         |
|    wins                 | 5181          |
| rollout/                |               |
|    ep_len_mean          | 18.5          |
|    ep_rew_mean          | -21.9         |
| time/                   |               |
|    fps                  | 2362          |
|    iterations           | 3             |
|    time_elapsed         | 83            |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 9.8998644e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.000676      |
|    learning_rate        | 0.0001        |
|    loss                 | 725           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00175      |
|    value_loss           | 1.46e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13495        |
|    invalid_moves        | 0            |
|    losses               | 6328         |
|    valid_moves          | 260000       |
|    win_rate             | 0.531        |
|    wins                 | 7167         |
| rollout/                |              |
|    ep_len_mean          | 20.7         |
|    ep_rew_mean          | -1.57        |
| time/                   |              |
|    fps                  | 2350         |
|    iterations           | 4            |
|    time_elapsed         | 111          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 9.584202e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.00156      |
|    learning_rate        | 0.0001       |
|    loss                 | 739          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00196     |
|    value_loss           | 1.47e+03     |
------------------------------------------
--------------------------------------------
| custom/                 |                |
|    draws                | 0              |
|    episodes             | 16692          |
|    invalid_moves        | 0              |
|    losses               | 7781           |
|    valid_moves          | 320000         |
|    win_rate             | 0.534          |
|    wins                 | 8911           |
| rollout/                |                |
|    ep_len_mean          | 18             |
|    ep_rew_mean          | 24.4           |
| time/                   |                |
|    fps                  | 2342           |
|    iterations           | 5              |
|    time_elapsed         | 139            |
|    total_timesteps      | 327680         |
| train/                  |                |
|    approx_kl            | 0.000115380535 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -2.58          |
|    explained_variance   | 0.00263        |
|    learning_rate        | 0.0001         |
|    loss                 | 726            |
|    n_updates            | 40             |
|    policy_gradient_loss | -0.00238       |
|    value_loss           | 1.46e+03       |
--------------------------------------------
--------------------------------------------
| custom/                 |                |
|    draws                | 0              |
|    episodes             | 20381          |
|    invalid_moves        | 0              |
|    losses               | 9394           |
|    valid_moves          | 390000         |
|    win_rate             | 0.539          |
|    wins                 | 10987          |
| rollout/                |                |
|    ep_len_mean          | 18.9           |
|    ep_rew_mean          | 11.4           |
| time/                   |                |
|    fps                  | 2337           |
|    iterations           | 6              |
|    time_elapsed         | 168            |
|    total_timesteps      | 393216         |
| train/                  |                |
|    approx_kl            | 0.000104924286 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -2.59          |
|    explained_variance   | 0.00324        |
|    learning_rate        | 0.0001         |
|    loss                 | 727            |
|    n_updates            | 50             |
|    policy_gradient_loss | -0.00233       |
|    value_loss           | 1.51e+03       |
--------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 23617         |
|    invalid_moves        | 0             |
|    losses               | 10778         |
|    valid_moves          | 450000        |
|    win_rate             | 0.544         |
|    wins                 | 12839         |
| rollout/                |               |
|    ep_len_mean          | 19.5          |
|    ep_rew_mean          | 40.3          |
| time/                   |               |
|    fps                  | 2331          |
|    iterations           | 7             |
|    time_elapsed         | 196           |
|    total_timesteps      | 458752        |
| train/                  |               |
|    approx_kl            | 0.00025041297 |
|    clip_fraction        | 3.05e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.00392       |
|    learning_rate        | 0.0001        |
|    loss                 | 718           |
|    n_updates            | 60            |
|    policy_gradient_loss | -0.00347      |
|    value_loss           | 1.47e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 27486         |
|    invalid_moves        | 0             |
|    losses               | 12276         |
|    valid_moves          | 520000        |
|    win_rate             | 0.553         |
|    wins                 | 15210         |
| rollout/                |               |
|    ep_len_mean          | 18.2          |
|    ep_rew_mean          | 29.4          |
| time/                   |               |
|    fps                  | 2327          |
|    iterations           | 8             |
|    time_elapsed         | 225           |
|    total_timesteps      | 524288        |
| train/                  |               |
|    approx_kl            | 0.00022778049 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.00446       |
|    learning_rate        | 0.0001        |
|    loss                 | 725           |
|    n_updates            | 70            |
|    policy_gradient_loss | -0.00323      |
|    value_loss           | 1.52e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 30830         |
|    invalid_moves        | 0             |
|    losses               | 13619         |
|    valid_moves          | 580000        |
|    win_rate             | 0.558         |
|    wins                 | 17211         |
| rollout/                |               |
|    ep_len_mean          | 20.2          |
|    ep_rew_mean          | 39.3          |
| time/                   |               |
|    fps                  | 2324          |
|    iterations           | 9             |
|    time_elapsed         | 253           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 0.00020709564 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.00512       |
|    learning_rate        | 0.0001        |
|    loss                 | 798           |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.00355      |
|    value_loss           | 1.54e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 34825         |
|    invalid_moves        | 0             |
|    losses               | 15105         |
|    valid_moves          | 650000        |
|    win_rate             | 0.566         |
|    wins                 | 19720         |
| rollout/                |               |
|    ep_len_mean          | 19            |
|    ep_rew_mean          | 16            |
| time/                   |               |
|    fps                  | 2319          |
|    iterations           | 10            |
|    time_elapsed         | 282           |
|    total_timesteps      | 655360        |
| train/                  |               |
|    approx_kl            | 0.00030227972 |
|    clip_fraction        | 4.73e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.00553       |
|    learning_rate        | 0.0001        |
|    loss                 | 774           |
|    n_updates            | 90            |
|    policy_gradient_loss | -0.00464      |
|    value_loss           | 1.56e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 38914         |
|    invalid_moves        | 0             |
|    losses               | 16577         |
|    valid_moves          | 720000        |
|    win_rate             | 0.574         |
|    wins                 | 22337         |
| rollout/                |               |
|    ep_len_mean          | 17.8          |
|    ep_rew_mean          | 55.5          |
| time/                   |               |
|    fps                  | 2315          |
|    iterations           | 11            |
|    time_elapsed         | 311           |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 0.00028933468 |
|    clip_fraction        | 4.58e-06      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.55         |
|    explained_variance   | 0.00611       |
|    learning_rate        | 0.0001        |
|    loss                 | 840           |
|    n_updates            | 100           |
|    policy_gradient_loss | -0.00436      |
|    value_loss           | 1.61e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 42480        |
|    invalid_moves        | 0            |
|    losses               | 17774        |
|    valid_moves          | 780000       |
|    win_rate             | 0.582        |
|    wins                 | 24706        |
| rollout/                |              |
|    ep_len_mean          | 15.5         |
|    ep_rew_mean          | 74.3         |
| time/                   |              |
|    fps                  | 2312         |
|    iterations           | 12           |
|    time_elapsed         | 340          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0003593666 |
|    clip_fraction        | 7.63e-06     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.00645      |
|    learning_rate        | 0.0001       |
|    loss                 | 847          |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00504     |
|    value_loss           | 1.63e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 46799        |
|    invalid_moves        | 0            |
|    losses               | 19171        |
|    valid_moves          | 850000       |
|    win_rate             | 0.59         |
|    wins                 | 27628        |
| rollout/                |              |
|    ep_len_mean          | 17.8         |
|    ep_rew_mean          | 96.7         |
| time/                   |              |
|    fps                  | 2307         |
|    iterations           | 13           |
|    time_elapsed         | 369          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0004023365 |
|    clip_fraction        | 1.53e-06     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.00563      |
|    learning_rate        | 0.0001       |
|    loss                 | 843          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00522     |
|    value_loss           | 1.65e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 50685         |
|    invalid_moves        | 0             |
|    losses               | 20298         |
|    valid_moves          | 910000        |
|    win_rate             | 0.6           |
|    wins                 | 30387         |
| rollout/                |               |
|    ep_len_mean          | 16.9          |
|    ep_rew_mean          | 56.3          |
| time/                   |               |
|    fps                  | 2302          |
|    iterations           | 14            |
|    time_elapsed         | 398           |
|    total_timesteps      | 917504        |
| train/                  |               |
|    approx_kl            | 0.00038749698 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.53         |
|    explained_variance   | 0.00828       |
|    learning_rate        | 0.0001        |
|    loss                 | 822           |
|    n_updates            | 130           |
|    policy_gradient_loss | -0.00548      |
|    value_loss           | 1.71e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 55398         |
|    invalid_moves        | 0             |
|    losses               | 21548         |
|    valid_moves          | 980000        |
|    win_rate             | 0.611         |
|    wins                 | 33850         |
| rollout/                |               |
|    ep_len_mean          | 13.8          |
|    ep_rew_mean          | 73.4          |
| time/                   |               |
|    fps                  | 2297          |
|    iterations           | 15            |
|    time_elapsed         | 427           |
|    total_timesteps      | 983040        |
| train/                  |               |
|    approx_kl            | 0.00039899792 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.51         |
|    explained_variance   | 0.00722       |
|    learning_rate        | 0.0001        |
|    loss                 | 874           |
|    n_updates            | 140           |
|    policy_gradient_loss | -0.00534      |
|    value_loss           | 1.79e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 59594         |
|    invalid_moves        | 0             |
|    losses               | 22620         |
|    valid_moves          | 1040000       |
|    win_rate             | 0.62          |
|    wins                 | 36974         |
| rollout/                |               |
|    ep_len_mean          | 12.6          |
|    ep_rew_mean          | 113           |
| time/                   |               |
|    fps                  | 2291          |
|    iterations           | 16            |
|    time_elapsed         | 457           |
|    total_timesteps      | 1048576       |
| train/                  |               |
|    approx_kl            | 0.00028191798 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.49         |
|    explained_variance   | 0.008         |
|    learning_rate        | 0.0001        |
|    loss                 | 925           |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.00452      |
|    value_loss           | 1.85e+03      |
-------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/2_MaskablePPO_Baseline_20250805_025544.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 2_MaskablePPO_Baseline agent...
[0;36m-> Mean Reward: 161.10 +/- 0.95[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 3_MaskableRecurrentPPO[0m
[0;37m   model_path: models/3_MaskableRecurrentPPO_20250805_030333.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '3_MaskableRecurrentPPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableRecurrentMultiInputActorCriticPolicy  --
â”œâ”€CombinedExtractor: 1-1                      --
â”‚    â””â”€ModuleDict: 2-1                        --
â”‚    â”‚    â””â”€Flatten: 3-1                      --
â”œâ”€CombinedExtractor: 1-2                      --
â”‚    â””â”€ModuleDict: 2-2                        --
â”‚    â”‚    â””â”€Flatten: 3-2                      --
â”œâ”€CombinedExtractor: 1-3                      --
â”‚    â””â”€ModuleDict: 2-3                        --
â”‚    â”‚    â””â”€Flatten: 3-3                      --
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-4                        --
â”‚    â”‚    â””â”€Linear: 3-4                       16,448
â”‚    â”‚    â””â”€Tanh: 3-5                         --
â”‚    â”‚    â””â”€Linear: 3-6                       4,160
â”‚    â”‚    â””â”€Tanh: 3-7                         --
â”‚    â””â”€Sequential: 2-5                        --
â”‚    â”‚    â””â”€Linear: 3-8                       16,448
â”‚    â”‚    â””â”€Tanh: 3-9                         --
â”‚    â”‚    â””â”€Linear: 3-10                      4,160
â”‚    â”‚    â””â”€Tanh: 3-11                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
â”œâ”€LSTM: 1-7                                   289,792
â”œâ”€LSTM: 1-8                                   289,792
======================================================================
Total params: 682,095
Trainable params: 682,095
Non-trainable params: 0
======================================================================
Logging to ./chess_logs/3_MaskableRecurrentPPO_3
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3050     |
|    invalid_moves   | 0        |
|    losses          | 1447     |
|    valid_moves     | 60000    |
|    win_rate        | 0.526    |
|    wins            | 1603     |
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 10       |
| time/              |          |
|    fps             | 2132     |
|    iterations      | 1        |
|    time_elapsed    | 30       |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 6631         |
|    invalid_moves        | 0            |
|    losses               | 3206         |
|    valid_moves          | 130000       |
|    win_rate             | 0.517        |
|    wins                 | 3425         |
| rollout/                |              |
|    ep_len_mean          | 18.7         |
|    ep_rew_mean          | -11          |
| time/                   |              |
|    fps                  | 1537         |
|    iterations           | 2            |
|    time_elapsed         | 85           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 9.079889e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.000824     |
|    learning_rate        | 0.0001       |
|    loss                 | 717          |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000441    |
|    value_loss           | 1.44e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9679          |
|    invalid_moves        | 0             |
|    losses               | 4695          |
|    valid_moves          | 190000        |
|    win_rate             | 0.515         |
|    wins                 | 4984          |
| rollout/                |               |
|    ep_len_mean          | 19.5          |
|    ep_rew_mean          | 0.427         |
| time/                   |               |
|    fps                  | 1418          |
|    iterations           | 3             |
|    time_elapsed         | 138           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 1.6162143e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.0036        |
|    learning_rate        | 0.0001        |
|    loss                 | 694           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.000583     |
|    value_loss           | 1.43e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 13296         |
|    invalid_moves        | 0             |
|    losses               | 6398          |
|    valid_moves          | 260000        |
|    win_rate             | 0.519         |
|    wins                 | 6898          |
| rollout/                |               |
|    ep_len_mean          | 21.2          |
|    ep_rew_mean          | -10.7         |
| time/                   |               |
|    fps                  | 1359          |
|    iterations           | 4             |
|    time_elapsed         | 192           |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 1.9525374e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00519       |
|    learning_rate        | 0.0001        |
|    loss                 | 707           |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.00064      |
|    value_loss           | 1.43e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 16397         |
|    invalid_moves        | 0             |
|    losses               | 7908          |
|    valid_moves          | 320000        |
|    win_rate             | 0.518         |
|    wins                 | 8489          |
| rollout/                |               |
|    ep_len_mean          | 19.7          |
|    ep_rew_mean          | -4.25         |
| time/                   |               |
|    fps                  | 1327          |
|    iterations           | 5             |
|    time_elapsed         | 246           |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 1.8810915e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00722       |
|    learning_rate        | 0.0001        |
|    loss                 | 746           |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.000677     |
|    value_loss           | 1.44e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 19983         |
|    invalid_moves        | 0             |
|    losses               | 9590          |
|    valid_moves          | 390000        |
|    win_rate             | 0.52          |
|    wins                 | 10393         |
| rollout/                |               |
|    ep_len_mean          | 18.5          |
|    ep_rew_mean          | -1.25         |
| time/                   |               |
|    fps                  | 1305          |
|    iterations           | 6             |
|    time_elapsed         | 301           |
|    total_timesteps      | 393216        |
| train/                  |               |
|    approx_kl            | 1.9115449e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00725       |
|    learning_rate        | 0.0001        |
|    loss                 | 727           |
|    n_updates            | 50            |
|    policy_gradient_loss | -0.000687     |
|    value_loss           | 1.45e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 23037         |
|    invalid_moves        | 0             |
|    losses               | 11056         |
|    valid_moves          | 450000        |
|    win_rate             | 0.52          |
|    wins                 | 11981         |
| rollout/                |               |
|    ep_len_mean          | 21            |
|    ep_rew_mean          | 0.168         |
| time/                   |               |
|    fps                  | 1290          |
|    iterations           | 7             |
|    time_elapsed         | 355           |
|    total_timesteps      | 458752        |
| train/                  |               |
|    approx_kl            | 1.7689084e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.00857       |
|    learning_rate        | 0.0001        |
|    loss                 | 712           |
|    n_updates            | 60            |
|    policy_gradient_loss | -0.000664     |
|    value_loss           | 1.43e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 26650         |
|    invalid_moves        | 0             |
|    losses               | 12766         |
|    valid_moves          | 520000        |
|    win_rate             | 0.521         |
|    wins                 | 13884         |
| rollout/                |               |
|    ep_len_mean          | 19.7          |
|    ep_rew_mean          | -6.99         |
| time/                   |               |
|    fps                  | 1280          |
|    iterations           | 8             |
|    time_elapsed         | 409           |
|    total_timesteps      | 524288        |
| train/                  |               |
|    approx_kl            | 1.5106594e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.0099        |
|    learning_rate        | 0.0001        |
|    loss                 | 705           |
|    n_updates            | 70            |
|    policy_gradient_loss | -0.000671     |
|    value_loss           | 1.42e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 29783         |
|    invalid_moves        | 0             |
|    losses               | 14178         |
|    valid_moves          | 580000        |
|    win_rate             | 0.524         |
|    wins                 | 15605         |
| rollout/                |               |
|    ep_len_mean          | 20.9          |
|    ep_rew_mean          | 21            |
| time/                   |               |
|    fps                  | 1270          |
|    iterations           | 9             |
|    time_elapsed         | 464           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 1.3364786e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.0108        |
|    learning_rate        | 0.0001        |
|    loss                 | 736           |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.000586     |
|    value_loss           | 1.44e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 33333        |
|    invalid_moves        | 0            |
|    losses               | 15769        |
|    valid_moves          | 650000       |
|    win_rate             | 0.527        |
|    wins                 | 17564        |
| rollout/                |              |
|    ep_len_mean          | 17.9         |
|    ep_rew_mean          | 7.99         |
| time/                   |              |
|    fps                  | 1263         |
|    iterations           | 10           |
|    time_elapsed         | 518          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 1.959762e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.0111       |
|    learning_rate        | 0.0001       |
|    loss                 | 710          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.000763    |
|    value_loss           | 1.44e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 36993         |
|    invalid_moves        | 0             |
|    losses               | 17419         |
|    valid_moves          | 720000        |
|    win_rate             | 0.529         |
|    wins                 | 19574         |
| rollout/                |               |
|    ep_len_mean          | 18.8          |
|    ep_rew_mean          | 7.85          |
| time/                   |               |
|    fps                  | 1256          |
|    iterations           | 11            |
|    time_elapsed         | 573           |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 1.9443713e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.0115        |
|    learning_rate        | 0.0001        |
|    loss                 | 687           |
|    n_updates            | 100           |
|    policy_gradient_loss | -0.000833     |
|    value_loss           | 1.43e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 40134         |
|    invalid_moves        | 0             |
|    losses               | 18835         |
|    valid_moves          | 780000        |
|    win_rate             | 0.531         |
|    wins                 | 21299         |
| rollout/                |               |
|    ep_len_mean          | 17.2          |
|    ep_rew_mean          | 21.5          |
| time/                   |               |
|    fps                  | 1252          |
|    iterations           | 12            |
|    time_elapsed         | 628           |
|    total_timesteps      | 786432        |
| train/                  |               |
|    approx_kl            | 2.5811843e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.00947       |
|    learning_rate        | 0.0001        |
|    loss                 | 722           |
|    n_updates            | 110           |
|    policy_gradient_loss | -0.000937     |
|    value_loss           | 1.45e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 43801        |
|    invalid_moves        | 0            |
|    losses               | 20434        |
|    valid_moves          | 850000       |
|    win_rate             | 0.533        |
|    wins                 | 23367        |
| rollout/                |              |
|    ep_len_mean          | 16.9         |
|    ep_rew_mean          | 29.4         |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 13           |
|    time_elapsed         | 682          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 2.326824e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.00959      |
|    learning_rate        | 0.0001       |
|    loss                 | 720          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.000846    |
|    value_loss           | 1.46e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 46996         |
|    invalid_moves        | 0             |
|    losses               | 21841         |
|    valid_moves          | 910000        |
|    win_rate             | 0.535         |
|    wins                 | 25155         |
| rollout/                |               |
|    ep_len_mean          | 18.7          |
|    ep_rew_mean          | 37.7          |
| time/                   |               |
|    fps                  | 1244          |
|    iterations           | 14            |
|    time_elapsed         | 737           |
|    total_timesteps      | 917504        |
| train/                  |               |
|    approx_kl            | 1.8447416e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | 0.00983       |
|    learning_rate        | 0.0001        |
|    loss                 | 742           |
|    n_updates            | 130           |
|    policy_gradient_loss | -0.000798     |
|    value_loss           | 1.47e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 50641        |
|    invalid_moves        | 0            |
|    losses               | 23383        |
|    valid_moves          | 980000       |
|    win_rate             | 0.538        |
|    wins                 | 27258        |
| rollout/                |              |
|    ep_len_mean          | 19.4         |
|    ep_rew_mean          | 24.9         |
| time/                   |              |
|    fps                  | 1241         |
|    iterations           | 15           |
|    time_elapsed         | 791          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 2.418186e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.0112       |
|    learning_rate        | 0.0001       |
|    loss                 | 758          |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.000886    |
|    value_loss           | 1.47e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 53837         |
|    invalid_moves        | 0             |
|    losses               | 24759         |
|    valid_moves          | 1040000       |
|    win_rate             | 0.54          |
|    wins                 | 29078         |
| rollout/                |               |
|    ep_len_mean          | 19.5          |
|    ep_rew_mean          | 9.2           |
| time/                   |               |
|    fps                  | 1238          |
|    iterations           | 16            |
|    time_elapsed         | 846           |
|    total_timesteps      | 1048576       |
| train/                  |               |
|    approx_kl            | 2.0477175e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.0122        |
|    learning_rate        | 0.0001        |
|    loss                 | 732           |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.000853     |
|    value_loss           | 1.45e+03      |
-------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/3_MaskableRecurrentPPO_20250805_030333.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 3_MaskableRecurrentPPO agent...
[0;36m-> Mean Reward: 161.97 +/- 2.55[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/boards.npy[0m
[0;37m   weights_file_path: weights/ae_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 4_FF_Autoencoder_MaskablePPO[0m
[0;37m   model_path: models/4_FF_Autoencoder_MaskablePPO_20250805_031815.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
MaskableMultiInputActorCriticPolicy      --
â”œâ”€FrozenAEFeatureExtractor: 1-1          --
â”‚    â””â”€Sequential: 2-1                   --
â”‚    â”‚    â””â”€Flatten: 3-1                 --
â”‚    â”‚    â””â”€Linear: 3-2                  (1,664)
â”‚    â”‚    â””â”€ReLU: 3-3                    --
â”‚    â”‚    â””â”€Linear: 3-4                  (520)
â”œâ”€FrozenAEFeatureExtractor: 1-2          (recursive)
â”‚    â””â”€Sequential: 2-2                   (recursive)
â”‚    â”‚    â””â”€Flatten: 3-5                 --
â”‚    â”‚    â””â”€Linear: 3-6                  (recursive)
â”‚    â”‚    â””â”€ReLU: 3-7                    --
â”‚    â”‚    â””â”€Linear: 3-8                  (recursive)
â”œâ”€FrozenAEFeatureExtractor: 1-3          (recursive)
â”‚    â””â”€Sequential: 2-3                   (recursive)
â”‚    â”‚    â””â”€Flatten: 3-9                 --
â”‚    â”‚    â””â”€Linear: 3-10                 (recursive)
â”‚    â”‚    â””â”€ReLU: 3-11                   --
â”‚    â”‚    â””â”€Linear: 3-12                 (recursive)
â”œâ”€MlpExtractor: 1-4                      --
â”‚    â””â”€Sequential: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-13                 576
â”‚    â”‚    â””â”€Tanh: 3-14                   --
â”‚    â”‚    â””â”€Linear: 3-15                 4,160
â”‚    â”‚    â””â”€Tanh: 3-16                   --
â”‚    â””â”€Sequential: 2-5                   --
â”‚    â”‚    â””â”€Linear: 3-17                 576
â”‚    â”‚    â””â”€Tanh: 3-18                   --
â”‚    â”‚    â””â”€Linear: 3-19                 4,160
â”‚    â”‚    â””â”€Tanh: 3-20                   --
â”œâ”€Linear: 1-5                            61,230
â”œâ”€Linear: 1-6                            65
=================================================================
Total params: 72,951
Trainable params: 70,767
Non-trainable params: 2,184
=================================================================
Logging to ./chess_logs/4_FF_Autoencoder_MaskablePPO_3
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3083     |
|    invalid_moves   | 0        |
|    losses          | 1483     |
|    valid_moves     | 60000    |
|    win_rate        | 0.519    |
|    wins            | 1600     |
| rollout/           |          |
|    ep_len_mean     | 19.1     |
|    ep_rew_mean     | 14       |
| time/              |          |
|    fps             | 2459     |
|    iterations      | 1        |
|    time_elapsed    | 26       |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 6696         |
|    invalid_moves        | 0            |
|    losses               | 3183         |
|    valid_moves          | 130000       |
|    win_rate             | 0.525        |
|    wins                 | 3513         |
| rollout/                |              |
|    ep_len_mean          | 19.2         |
|    ep_rew_mean          | 8.63         |
| time/                   |              |
|    fps                  | 2362         |
|    iterations           | 2            |
|    time_elapsed         | 55           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 0.0006023568 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 2.96e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 716          |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00345     |
|    value_loss           | 1.45e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 9831        |
|    invalid_moves        | 0           |
|    losses               | 4524        |
|    valid_moves          | 190000      |
|    win_rate             | 0.54        |
|    wins                 | 5307        |
| rollout/                |             |
|    ep_len_mean          | 17.2        |
|    ep_rew_mean          | 12.4        |
| time/                   |             |
|    fps                  | 2334        |
|    iterations           | 3           |
|    time_elapsed         | 84          |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.001257491 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.59       |
|    explained_variance   | 3.81e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 734         |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0047     |
|    value_loss           | 1.46e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13672        |
|    invalid_moves        | 0            |
|    losses               | 6164         |
|    valid_moves          | 260000       |
|    win_rate             | 0.549        |
|    wins                 | 7508         |
| rollout/                |              |
|    ep_len_mean          | 19           |
|    ep_rew_mean          | 41.3         |
| time/                   |              |
|    fps                  | 2317         |
|    iterations           | 4            |
|    time_elapsed         | 113          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0007547407 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.000171     |
|    learning_rate        | 0.0001       |
|    loss                 | 754          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00425     |
|    value_loss           | 1.47e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 17009        |
|    invalid_moves        | 0            |
|    losses               | 7428         |
|    valid_moves          | 320000       |
|    win_rate             | 0.563        |
|    wins                 | 9581         |
| rollout/                |              |
|    ep_len_mean          | 18.7         |
|    ep_rew_mean          | 48.9         |
| time/                   |              |
|    fps                  | 2307         |
|    iterations           | 5            |
|    time_elapsed         | 141          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0020131534 |
|    clip_fraction        | 0.000372     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.000116     |
|    learning_rate        | 0.0001       |
|    loss                 | 759          |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00633     |
|    value_loss           | 1.55e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 21157        |
|    invalid_moves        | 0            |
|    losses               | 8858         |
|    valid_moves          | 390000       |
|    win_rate             | 0.581        |
|    wins                 | 12299        |
| rollout/                |              |
|    ep_len_mean          | 18.2         |
|    ep_rew_mean          | 60.3         |
| time/                   |              |
|    fps                  | 2297         |
|    iterations           | 6            |
|    time_elapsed         | 171          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0015435265 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.000176     |
|    learning_rate        | 0.0001       |
|    loss                 | 801          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.0071      |
|    value_loss           | 1.57e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 24841        |
|    invalid_moves        | 0            |
|    losses               | 10043        |
|    valid_moves          | 450000       |
|    win_rate             | 0.596        |
|    wins                 | 14798        |
| rollout/                |              |
|    ep_len_mean          | 16           |
|    ep_rew_mean          | 63           |
| time/                   |              |
|    fps                  | 2287         |
|    iterations           | 7            |
|    time_elapsed         | 200          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0009965233 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.000213     |
|    learning_rate        | 0.0001       |
|    loss                 | 856          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00585     |
|    value_loss           | 1.66e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 29300        |
|    invalid_moves        | 0            |
|    losses               | 11356        |
|    valid_moves          | 520000       |
|    win_rate             | 0.612        |
|    wins                 | 17944        |
| rollout/                |              |
|    ep_len_mean          | 13.7         |
|    ep_rew_mean          | 49.5         |
| time/                   |              |
|    fps                  | 2276         |
|    iterations           | 8            |
|    time_elapsed         | 230          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0012199178 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.000139     |
|    learning_rate        | 0.0001       |
|    loss                 | 872          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00657     |
|    value_loss           | 1.72e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 33482        |
|    invalid_moves        | 0            |
|    losses               | 12478        |
|    valid_moves          | 580000       |
|    win_rate             | 0.627        |
|    wins                 | 21004        |
| rollout/                |              |
|    ep_len_mean          | 13.2         |
|    ep_rew_mean          | 66.4         |
| time/                   |              |
|    fps                  | 2266         |
|    iterations           | 9            |
|    time_elapsed         | 260          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0012850737 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.000144     |
|    learning_rate        | 0.0001       |
|    loss                 | 917          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00771     |
|    value_loss           | 1.79e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 38379        |
|    invalid_moves        | 0            |
|    losses               | 13666        |
|    valid_moves          | 650000       |
|    win_rate             | 0.644        |
|    wins                 | 24713        |
| rollout/                |              |
|    ep_len_mean          | 15           |
|    ep_rew_mean          | 91.7         |
| time/                   |              |
|    fps                  | 2258         |
|    iterations           | 10           |
|    time_elapsed         | 290          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0012155406 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.000166     |
|    learning_rate        | 0.0001       |
|    loss                 | 943          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00772     |
|    value_loss           | 1.9e+03      |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 43434        |
|    invalid_moves        | 0            |
|    losses               | 14830        |
|    valid_moves          | 720000       |
|    win_rate             | 0.659        |
|    wins                 | 28604        |
| rollout/                |              |
|    ep_len_mean          | 12.3         |
|    ep_rew_mean          | 80.2         |
| time/                   |              |
|    fps                  | 2249         |
|    iterations           | 11           |
|    time_elapsed         | 320          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0011761436 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.000134     |
|    learning_rate        | 0.0001       |
|    loss                 | 976          |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.0078      |
|    value_loss           | 1.93e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 48113        |
|    invalid_moves        | 0            |
|    losses               | 15740        |
|    valid_moves          | 780000       |
|    win_rate             | 0.673        |
|    wins                 | 32373        |
| rollout/                |              |
|    ep_len_mean          | 12.8         |
|    ep_rew_mean          | 108          |
| time/                   |              |
|    fps                  | 2242         |
|    iterations           | 12           |
|    time_elapsed         | 350          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0014866086 |
|    clip_fraction        | 6.1e-06      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 8.29e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 971          |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00881     |
|    value_loss           | 1.99e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 53880       |
|    invalid_moves        | 0           |
|    losses               | 16800       |
|    valid_moves          | 850000      |
|    win_rate             | 0.688       |
|    wins                 | 37080       |
| rollout/                |             |
|    ep_len_mean          | 13.5        |
|    ep_rew_mean          | 81.4        |
| time/                   |             |
|    fps                  | 2232        |
|    iterations           | 13          |
|    time_elapsed         | 381         |
|    total_timesteps      | 851968      |
| train/                  |             |
|    approx_kl            | 0.001263526 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.36       |
|    explained_variance   | 7.99e-05    |
|    learning_rate        | 0.0001      |
|    loss                 | 1.05e+03    |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.009      |
|    value_loss           | 2.1e+03     |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 59114        |
|    invalid_moves        | 0            |
|    losses               | 17612        |
|    valid_moves          | 910000       |
|    win_rate             | 0.702        |
|    wins                 | 41502        |
| rollout/                |              |
|    ep_len_mean          | 11.5         |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 2223         |
|    iterations           | 14           |
|    time_elapsed         | 412          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0011386456 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 4.41e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.13e+03     |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00834     |
|    value_loss           | 2.22e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 65463        |
|    invalid_moves        | 0            |
|    losses               | 18587        |
|    valid_moves          | 980000       |
|    win_rate             | 0.716        |
|    wins                 | 46876        |
| rollout/                |              |
|    ep_len_mean          | 10.6         |
|    ep_rew_mean          | 113          |
| time/                   |              |
|    fps                  | 2214         |
|    iterations           | 15           |
|    time_elapsed         | 443          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0009471384 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 1.63e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.13e+03     |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00778     |
|    value_loss           | 2.32e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 71141        |
|    invalid_moves        | 0            |
|    losses               | 19385        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.728        |
|    wins                 | 51756        |
| rollout/                |              |
|    ep_len_mean          | 10.6         |
|    ep_rew_mean          | 113          |
| time/                   |              |
|    fps                  | 2205         |
|    iterations           | 16           |
|    time_elapsed         | 475          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0008876666 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.23        |
|    explained_variance   | 3.05e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.21e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00733     |
|    value_loss           | 2.43e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/4_FF_Autoencoder_MaskablePPO_20250805_031815.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 4_FF_Autoencoder_MaskablePPO agent...
[0;36m-> Mean Reward: 161.37 +/- 1.77[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/boards.npy[0m
[0;37m   weights_file_path: weights/ae_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 5_FF_Autoencoder_MaskableRecurrentPPO[0m
[0;37m   model_path: models/5_FF_Autoencoder_MaskableRecurrentPPO_20250805_032625.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '5_FF_Autoencoder_MaskableRecurrentPPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableRecurrentMultiInputActorCriticPolicy  --
â”œâ”€FrozenAEFeatureExtractor: 1-1               --
â”‚    â””â”€Sequential: 2-1                        --
â”‚    â”‚    â””â”€Flatten: 3-1                      --
â”‚    â”‚    â””â”€Linear: 3-2                       (1,664)
â”‚    â”‚    â””â”€ReLU: 3-3                         --
â”‚    â”‚    â””â”€Linear: 3-4                       (520)
â”œâ”€FrozenAEFeatureExtractor: 1-2               (recursive)
â”‚    â””â”€Sequential: 2-2                        (recursive)
â”‚    â”‚    â””â”€Flatten: 3-5                      --
â”‚    â”‚    â””â”€Linear: 3-6                       (recursive)
â”‚    â”‚    â””â”€ReLU: 3-7                         --
â”‚    â”‚    â””â”€Linear: 3-8                       (recursive)
â”œâ”€FrozenAEFeatureExtractor: 1-3               (recursive)
â”‚    â””â”€Sequential: 2-3                        (recursive)
â”‚    â”‚    â””â”€Flatten: 3-9                      --
â”‚    â”‚    â””â”€Linear: 3-10                      (recursive)
â”‚    â”‚    â””â”€ReLU: 3-11                        --
â”‚    â”‚    â””â”€Linear: 3-12                      (recursive)
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-4                        --
â”‚    â”‚    â””â”€Linear: 3-13                      16,448
â”‚    â”‚    â””â”€Tanh: 3-14                        --
â”‚    â”‚    â””â”€Linear: 3-15                      4,160
â”‚    â”‚    â””â”€Tanh: 3-16                        --
â”‚    â””â”€Sequential: 2-5                        --
â”‚    â”‚    â””â”€Linear: 3-17                      16,448
â”‚    â”‚    â””â”€Tanh: 3-18                        --
â”‚    â”‚    â””â”€Linear: 3-19                      4,160
â”‚    â”‚    â””â”€Tanh: 3-20                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
â”œâ”€LSTM: 1-7                                   272,384
â”œâ”€LSTM: 1-8                                   272,384
======================================================================
Total params: 649,463
Trainable params: 647,279
Non-trainable params: 2,184
======================================================================
Logging to ./chess_logs/5_FF_Autoencoder_MaskableRecurrentPPO_3
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3083     |
|    invalid_moves   | 0        |
|    losses          | 1517     |
|    valid_moves     | 60000    |
|    win_rate        | 0.508    |
|    wins            | 1566     |
| rollout/           |          |
|    ep_len_mean     | 17.9     |
|    ep_rew_mean     | 19.7     |
| time/              |          |
|    fps             | 2112     |
|    iterations      | 1        |
|    time_elapsed    | 31       |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 6695         |
|    invalid_moves        | 0            |
|    losses               | 3268         |
|    valid_moves          | 130000       |
|    win_rate             | 0.512        |
|    wins                 | 3427         |
| rollout/                |              |
|    ep_len_mean          | 19.7         |
|    ep_rew_mean          | 9.83         |
| time/                   |              |
|    fps                  | 1521         |
|    iterations           | 2            |
|    time_elapsed         | 86           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 3.199706e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 1.58e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 714          |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000661    |
|    value_loss           | 1.45e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9821          |
|    invalid_moves        | 0             |
|    losses               | 4755          |
|    valid_moves          | 190000        |
|    win_rate             | 0.516         |
|    wins                 | 5066          |
| rollout/                |               |
|    ep_len_mean          | 17.2          |
|    ep_rew_mean          | 1.56          |
| time/                   |               |
|    fps                  | 1394          |
|    iterations           | 3             |
|    time_elapsed         | 140           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00028139516 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 0.000222      |
|    learning_rate        | 0.0001        |
|    loss                 | 723           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00205      |
|    value_loss           | 1.45e+03      |
-------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 13467       |
|    invalid_moves        | 0           |
|    losses               | 6419        |
|    valid_moves          | 260000      |
|    win_rate             | 0.523       |
|    wins                 | 7048        |
| rollout/                |             |
|    ep_len_mean          | 17.6        |
|    ep_rew_mean          | 22.9        |
| time/                   |             |
|    fps                  | 1337        |
|    iterations           | 4           |
|    time_elapsed         | 195         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.000614348 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.000835    |
|    learning_rate        | 0.0001      |
|    loss                 | 741         |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00345    |
|    value_loss           | 1.47e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 16659        |
|    invalid_moves        | 0            |
|    losses               | 7792         |
|    valid_moves          | 320000       |
|    win_rate             | 0.532        |
|    wins                 | 8867         |
| rollout/                |              |
|    ep_len_mean          | 18.4         |
|    ep_rew_mean          | 33.5         |
| time/                   |              |
|    fps                  | 1307         |
|    iterations           | 5            |
|    time_elapsed         | 250          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0007793616 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.00133      |
|    learning_rate        | 0.0001       |
|    loss                 | 703          |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00353     |
|    value_loss           | 1.47e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 20639        |
|    invalid_moves        | 0            |
|    losses               | 9223         |
|    valid_moves          | 390000       |
|    win_rate             | 0.553        |
|    wins                 | 11416        |
| rollout/                |              |
|    ep_len_mean          | 18           |
|    ep_rew_mean          | 51.8         |
| time/                   |              |
|    fps                  | 1286         |
|    iterations           | 6            |
|    time_elapsed         | 305          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0061237356 |
|    clip_fraction        | 0.0184       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.00178      |
|    learning_rate        | 0.0001       |
|    loss                 | 736          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00966     |
|    value_loss           | 1.5e+03      |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 24394        |
|    invalid_moves        | 0            |
|    losses               | 10347        |
|    valid_moves          | 450000       |
|    win_rate             | 0.576        |
|    wins                 | 14047        |
| rollout/                |              |
|    ep_len_mean          | 16.2         |
|    ep_rew_mean          | 75.4         |
| time/                   |              |
|    fps                  | 1262         |
|    iterations           | 7            |
|    time_elapsed         | 363          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0063905558 |
|    clip_fraction        | 0.0159       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.00331      |
|    learning_rate        | 0.0001       |
|    loss                 | 792          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.0105      |
|    value_loss           | 1.59e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 28983        |
|    invalid_moves        | 0            |
|    losses               | 11475        |
|    valid_moves          | 520000       |
|    win_rate             | 0.604        |
|    wins                 | 17508        |
| rollout/                |              |
|    ep_len_mean          | 14.7         |
|    ep_rew_mean          | 81.9         |
| time/                   |              |
|    fps                  | 1237         |
|    iterations           | 8            |
|    time_elapsed         | 423          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0048312303 |
|    clip_fraction        | 0.0107       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.00558      |
|    learning_rate        | 0.0001       |
|    loss                 | 848          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.013       |
|    value_loss           | 1.72e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 33267        |
|    invalid_moves        | 0            |
|    losses               | 12396        |
|    valid_moves          | 580000       |
|    win_rate             | 0.627        |
|    wins                 | 20871        |
| rollout/                |              |
|    ep_len_mean          | 14.4         |
|    ep_rew_mean          | 103          |
| time/                   |              |
|    fps                  | 1219         |
|    iterations           | 9            |
|    time_elapsed         | 483          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0030218395 |
|    clip_fraction        | 0.00179      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | 0.00863      |
|    learning_rate        | 0.0001       |
|    loss                 | 902          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.0114      |
|    value_loss           | 1.81e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 38554        |
|    invalid_moves        | 0            |
|    losses               | 13437        |
|    valid_moves          | 650000       |
|    win_rate             | 0.651        |
|    wins                 | 25117        |
| rollout/                |              |
|    ep_len_mean          | 12.8         |
|    ep_rew_mean          | 104          |
| time/                   |              |
|    fps                  | 1198         |
|    iterations           | 10           |
|    time_elapsed         | 546          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0032293731 |
|    clip_fraction        | 0.00312      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.00926      |
|    learning_rate        | 0.0001       |
|    loss                 | 969          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.0127      |
|    value_loss           | 1.92e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 44459       |
|    invalid_moves        | 0           |
|    losses               | 14365       |
|    valid_moves          | 720000      |
|    win_rate             | 0.677       |
|    wins                 | 30094       |
| rollout/                |             |
|    ep_len_mean          | 11.4        |
|    ep_rew_mean          | 116         |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 11          |
|    time_elapsed         | 610         |
|    total_timesteps      | 720896      |
| train/                  |             |
|    approx_kl            | 0.002933147 |
|    clip_fraction        | 0.00199     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | 0.00956     |
|    learning_rate        | 0.0001      |
|    loss                 | 1.02e+03    |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0125     |
|    value_loss           | 2.05e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 49997        |
|    invalid_moves        | 0            |
|    losses               | 15103        |
|    valid_moves          | 780000       |
|    win_rate             | 0.698        |
|    wins                 | 34894        |
| rollout/                |              |
|    ep_len_mean          | 11.5         |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 1160         |
|    iterations           | 12           |
|    time_elapsed         | 677          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0021855533 |
|    clip_fraction        | 0.000542     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.0131       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.1e+03      |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.0115      |
|    value_loss           | 2.23e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 56688        |
|    invalid_moves        | 0            |
|    losses               | 15957        |
|    valid_moves          | 850000       |
|    win_rate             | 0.719        |
|    wins                 | 40731        |
| rollout/                |              |
|    ep_len_mean          | 11.9         |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 1141         |
|    iterations           | 13           |
|    time_elapsed         | 746          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0017875136 |
|    clip_fraction        | 2.9e-05      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.0126       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.2e+03      |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.0107      |
|    value_loss           | 2.39e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 62627        |
|    invalid_moves        | 0            |
|    losses               | 16620        |
|    valid_moves          | 910000       |
|    win_rate             | 0.735        |
|    wins                 | 46007        |
| rollout/                |              |
|    ep_len_mean          | 9.43         |
|    ep_rew_mean          | 117          |
| time/                   |              |
|    fps                  | 1123         |
|    iterations           | 14           |
|    time_elapsed         | 816          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0015318228 |
|    clip_fraction        | 1.53e-06     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.0132       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.23e+03     |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00949     |
|    value_loss           | 2.48e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 70038        |
|    invalid_moves        | 0            |
|    losses               | 17420        |
|    valid_moves          | 980000       |
|    win_rate             | 0.751        |
|    wins                 | 52618        |
| rollout/                |              |
|    ep_len_mean          | 9.56         |
|    ep_rew_mean          | 141          |
| time/                   |              |
|    fps                  | 1104         |
|    iterations           | 15           |
|    time_elapsed         | 890          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0012708908 |
|    clip_fraction        | 1.53e-06     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.0158       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.26e+03     |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00846     |
|    value_loss           | 2.56e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 76576        |
|    invalid_moves        | 0            |
|    losses               | 18081        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.764        |
|    wins                 | 58495        |
| rollout/                |              |
|    ep_len_mean          | 9.13         |
|    ep_rew_mean          | 138          |
| time/                   |              |
|    fps                  | 1087         |
|    iterations           | 16           |
|    time_elapsed         | 964          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0010406793 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.0165       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.38e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00736     |
|    value_loss           | 2.7e+03      |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/5_FF_Autoencoder_MaskableRecurrentPPO_20250805_032625.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 5_FF_Autoencoder_MaskableRecurrentPPO agent...
[0;36m-> Mean Reward: 149.90 +/- 60.23[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/board_seqs.npy[0m
[0;37m   weights_file_path: weights/ae_rnn_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 6_LSTM_Autoencoder_MaskablePPO[0m
[0;37m   model_path: models/6_LSTM_Autoencoder_MaskablePPO_20250805_034322.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '6_LSTM_Autoencoder_MaskablePPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/DRL/Chess_6_LSTM_Autoencoder_MaskablePPO.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ae.load_state_dict(torch.load(AE_WEIGHTS_PATH, map_location=device))
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableMultiInputActorCriticPolicy           --
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-1        --
â”‚    â””â”€SimpleLSTMAutoencoder: 2-1             --
â”‚    â”‚    â””â”€LSTM: 3-1                         (23,296)
â”‚    â”‚    â””â”€Linear: 3-2                       (520)
â”‚    â”‚    â””â”€Linear: 3-3                       (576)
â”‚    â”‚    â””â”€LSTM: 3-4                         (33,280)
â”‚    â”‚    â””â”€Linear: 3-5                       (1,625)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-2             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-6                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-7                       (recursive)
â”‚    â”‚    â””â”€Linear: 3-8                       (recursive)
â”‚    â”‚    â””â”€LSTM: 3-9                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-10                      (recursive)
â”‚    â””â”€LSTM: 2-3                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-2        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-4             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-11                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-12                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-13                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-14                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-15                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-5             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-16                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-17                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-18                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-19                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-20                      (recursive)
â”‚    â””â”€LSTM: 2-6                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-3        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-7             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-21                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-22                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-23                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-24                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-25                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-8             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-26                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-27                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-28                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-29                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-30                      (recursive)
â”‚    â””â”€LSTM: 2-9                              (recursive)
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-10                       --
â”‚    â”‚    â””â”€Linear: 3-31                      576
â”‚    â”‚    â””â”€Tanh: 3-32                        --
â”‚    â”‚    â””â”€Linear: 3-33                      4,160
â”‚    â”‚    â””â”€Tanh: 3-34                        --
â”‚    â””â”€Sequential: 2-11                       --
â”‚    â”‚    â””â”€Linear: 3-35                      576
â”‚    â”‚    â””â”€Tanh: 3-36                        --
â”‚    â”‚    â””â”€Linear: 3-37                      4,160
â”‚    â”‚    â””â”€Tanh: 3-38                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
======================================================================
Total params: 130,064
Trainable params: 70,767
Non-trainable params: 59,297
======================================================================
Logging to ./chess_logs/6_LSTM_Autoencoder_MaskablePPO_3
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3059     |
|    invalid_moves   | 0        |
|    losses          | 1518     |
|    valid_moves     | 60000    |
|    win_rate        | 0.504    |
|    wins            | 1541     |
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | -8.26    |
| time/              |          |
|    fps             | 2372     |
|    iterations      | 1        |
|    time_elapsed    | 27       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6715          |
|    invalid_moves        | 0             |
|    losses               | 3311          |
|    valid_moves          | 130000        |
|    win_rate             | 0.507         |
|    wins                 | 3404          |
| rollout/                |               |
|    ep_len_mean          | 18.6          |
|    ep_rew_mean          | -19.2         |
| time/                   |               |
|    fps                  | 2283          |
|    iterations           | 2             |
|    time_elapsed         | 57            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 0.00012405022 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | -7.14e-05     |
|    learning_rate        | 0.0001        |
|    loss                 | 713           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.00143      |
|    value_loss           | 1.44e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9838          |
|    invalid_moves        | 0             |
|    losses               | 4786          |
|    valid_moves          | 190000        |
|    win_rate             | 0.514         |
|    wins                 | 5052          |
| rollout/                |               |
|    ep_len_mean          | 16.7          |
|    ep_rew_mean          | 32.5          |
| time/                   |               |
|    fps                  | 2261          |
|    iterations           | 3             |
|    time_elapsed         | 86            |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00030858643 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.59         |
|    explained_variance   | -4.42e-05     |
|    learning_rate        | 0.0001        |
|    loss                 | 747           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00226      |
|    value_loss           | 1.47e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 13529         |
|    invalid_moves        | 0             |
|    losses               | 6445          |
|    valid_moves          | 260000        |
|    win_rate             | 0.524         |
|    wins                 | 7084          |
| rollout/                |               |
|    ep_len_mean          | 20.1          |
|    ep_rew_mean          | 26.5          |
| time/                   |               |
|    fps                  | 2252          |
|    iterations           | 4             |
|    time_elapsed         | 116           |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 0.00042818536 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | -6.91e-06     |
|    learning_rate        | 0.0001        |
|    loss                 | 718           |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.00273      |
|    value_loss           | 1.48e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 16726         |
|    invalid_moves        | 0             |
|    losses               | 7793          |
|    valid_moves          | 320000        |
|    win_rate             | 0.534         |
|    wins                 | 8933          |
| rollout/                |               |
|    ep_len_mean          | 18.6          |
|    ep_rew_mean          | 24.1          |
| time/                   |               |
|    fps                  | 2244          |
|    iterations           | 5             |
|    time_elapsed         | 146           |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 0.00049259845 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 1.82e-05      |
|    learning_rate        | 0.0001        |
|    loss                 | 777           |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.00304      |
|    value_loss           | 1.47e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 20430         |
|    invalid_moves        | 0             |
|    losses               | 9337          |
|    valid_moves          | 390000        |
|    win_rate             | 0.543         |
|    wins                 | 11093         |
| rollout/                |               |
|    ep_len_mean          | 19.9          |
|    ep_rew_mean          | 26.1          |
| time/                   |               |
|    fps                  | 2240          |
|    iterations           | 6             |
|    time_elapsed         | 175           |
|    total_timesteps      | 393216        |
| train/                  |               |
|    approx_kl            | 0.00049389503 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 4.83e-05      |
|    learning_rate        | 0.0001        |
|    loss                 | 755           |
|    n_updates            | 50            |
|    policy_gradient_loss | -0.00339      |
|    value_loss           | 1.5e+03       |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 23790        |
|    invalid_moves        | 0            |
|    losses               | 10608        |
|    valid_moves          | 450000       |
|    win_rate             | 0.554        |
|    wins                 | 13182        |
| rollout/                |              |
|    ep_len_mean          | 17.8         |
|    ep_rew_mean          | 46.5         |
| time/                   |              |
|    fps                  | 2234         |
|    iterations           | 7            |
|    time_elapsed         | 205          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0009103275 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 4.91e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 729          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00434     |
|    value_loss           | 1.49e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 27810        |
|    invalid_moves        | 0            |
|    losses               | 12060        |
|    valid_moves          | 520000       |
|    win_rate             | 0.566        |
|    wins                 | 15750        |
| rollout/                |              |
|    ep_len_mean          | 17.9         |
|    ep_rew_mean          | 65.8         |
| time/                   |              |
|    fps                  | 2228         |
|    iterations           | 8            |
|    time_elapsed         | 235          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0010149067 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 8.99e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 828          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.0054      |
|    value_loss           | 1.57e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 31296        |
|    invalid_moves        | 0            |
|    losses               | 13245        |
|    valid_moves          | 580000       |
|    win_rate             | 0.577        |
|    wins                 | 18051        |
| rollout/                |              |
|    ep_len_mean          | 17.6         |
|    ep_rew_mean          | 31.6         |
| time/                   |              |
|    fps                  | 2222         |
|    iterations           | 9            |
|    time_elapsed         | 265          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0008220852 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.55        |
|    explained_variance   | 9.95e-05     |
|    learning_rate        | 0.0001       |
|    loss                 | 801          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00515     |
|    value_loss           | 1.62e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 35604        |
|    invalid_moves        | 0            |
|    losses               | 14570        |
|    valid_moves          | 650000       |
|    win_rate             | 0.591        |
|    wins                 | 21034        |
| rollout/                |              |
|    ep_len_mean          | 14.2         |
|    ep_rew_mean          | 66.2         |
| time/                   |              |
|    fps                  | 2216         |
|    iterations           | 10           |
|    time_elapsed         | 295          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0010078992 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.000104     |
|    learning_rate        | 0.0001       |
|    loss                 | 803          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00581     |
|    value_loss           | 1.64e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 40082        |
|    invalid_moves        | 0            |
|    losses               | 15857        |
|    valid_moves          | 720000       |
|    win_rate             | 0.604        |
|    wins                 | 24225        |
| rollout/                |              |
|    ep_len_mean          | 14.6         |
|    ep_rew_mean          | 69.4         |
| time/                   |              |
|    fps                  | 2209         |
|    iterations           | 11           |
|    time_elapsed         | 326          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0010450433 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.000106     |
|    learning_rate        | 0.0001       |
|    loss                 | 863          |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00654     |
|    value_loss           | 1.72e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 44090        |
|    invalid_moves        | 0            |
|    losses               | 16890        |
|    valid_moves          | 780000       |
|    win_rate             | 0.617        |
|    wins                 | 27200        |
| rollout/                |              |
|    ep_len_mean          | 14.9         |
|    ep_rew_mean          | 46.4         |
| time/                   |              |
|    fps                  | 2202         |
|    iterations           | 12           |
|    time_elapsed         | 357          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0010750985 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.000139     |
|    learning_rate        | 0.0001       |
|    loss                 | 892          |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00681     |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 48949        |
|    invalid_moves        | 0            |
|    losses               | 18047        |
|    valid_moves          | 850000       |
|    win_rate             | 0.631        |
|    wins                 | 30902        |
| rollout/                |              |
|    ep_len_mean          | 13.4         |
|    ep_rew_mean          | 112          |
| time/                   |              |
|    fps                  | 2196         |
|    iterations           | 13           |
|    time_elapsed         | 387          |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0011560372 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.000153     |
|    learning_rate        | 0.0001       |
|    loss                 | 927          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00759     |
|    value_loss           | 1.84e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 53398        |
|    invalid_moves        | 0            |
|    losses               | 18967        |
|    valid_moves          | 910000       |
|    win_rate             | 0.645        |
|    wins                 | 34431        |
| rollout/                |              |
|    ep_len_mean          | 13.7         |
|    ep_rew_mean          | 93.2         |
| time/                   |              |
|    fps                  | 2189         |
|    iterations           | 14           |
|    time_elapsed         | 418          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0011692597 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.42        |
|    explained_variance   | 0.000145     |
|    learning_rate        | 0.0001       |
|    loss                 | 953          |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.0079      |
|    value_loss           | 1.92e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 58871        |
|    invalid_moves        | 0            |
|    losses               | 19994        |
|    valid_moves          | 980000       |
|    win_rate             | 0.66         |
|    wins                 | 38877        |
| rollout/                |              |
|    ep_len_mean          | 11.3         |
|    ep_rew_mean          | 106          |
| time/                   |              |
|    fps                  | 2182         |
|    iterations           | 15           |
|    time_elapsed         | 450          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0010741273 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.000148     |
|    learning_rate        | 0.0001       |
|    loss                 | 1.01e+03     |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00786     |
|    value_loss           | 2.02e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 63874        |
|    invalid_moves        | 0            |
|    losses               | 20875        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.673        |
|    wins                 | 42999        |
| rollout/                |              |
|    ep_len_mean          | 11.6         |
|    ep_rew_mean          | 99.2         |
| time/                   |              |
|    fps                  | 2174         |
|    iterations           | 16           |
|    time_elapsed         | 482          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0010030812 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.00015      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.02e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00785     |
|    value_loss           | 2.13e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/6_LSTM_Autoencoder_MaskablePPO_20250805_034322.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 6_LSTM_Autoencoder_MaskablePPO agent...
[0;36m-> Mean Reward: 155.22 +/- 48.55[0m
[0;37mParsed arguments:[0m
[0;37m   n_samples: 1000000[0m
[0;37m   board_file_path: boards/board_seqs.npy[0m
[0;37m   weights_file_path: weights/ae_rnn_pretrained.pth[0m
[0;37m   n_epochs: 20[0m
[0;37m   force_clean: False[0m
Skipping autoencoder training, weights already exists
[0;37mParsed arguments:[0m
[0;37m   agent_name: 7_LSTM_Autoencoder_MaskableRecurrentPPO[0m
[0;37m   model_path: models/7_LSTM_Autoencoder_MaskableRecurrentPPO_20250805_035139.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '7_LSTM_Autoencoder_MaskableRecurrentPPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/DRL/Chess_7_LSTM_Autoencoder_MaskableRecurrentPPO.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ae.load_state_dict(torch.load(AE_WEIGHTS_PATH, map_location=device))
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
MaskableRecurrentMultiInputActorCriticPolicy  --
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-1        --
â”‚    â””â”€SimpleLSTMAutoencoder: 2-1             --
â”‚    â”‚    â””â”€LSTM: 3-1                         (23,296)
â”‚    â”‚    â””â”€Linear: 3-2                       (520)
â”‚    â”‚    â””â”€Linear: 3-3                       (576)
â”‚    â”‚    â””â”€LSTM: 3-4                         (33,280)
â”‚    â”‚    â””â”€Linear: 3-5                       (1,625)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-2             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-6                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-7                       (recursive)
â”‚    â”‚    â””â”€Linear: 3-8                       (recursive)
â”‚    â”‚    â””â”€LSTM: 3-9                         (recursive)
â”‚    â”‚    â””â”€Linear: 3-10                      (recursive)
â”‚    â””â”€LSTM: 2-3                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-2        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-4             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-11                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-12                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-13                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-14                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-15                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-5             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-16                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-17                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-18                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-19                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-20                      (recursive)
â”‚    â””â”€LSTM: 2-6                              (recursive)
â”œâ”€LSTMAutoencoderFeatureExtractor: 1-3        (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-7             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-21                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-22                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-23                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-24                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-25                      (recursive)
â”‚    â””â”€SimpleLSTMAutoencoder: 2-8             (recursive)
â”‚    â”‚    â””â”€LSTM: 3-26                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-27                      (recursive)
â”‚    â”‚    â””â”€Linear: 3-28                      (recursive)
â”‚    â”‚    â””â”€LSTM: 3-29                        (recursive)
â”‚    â”‚    â””â”€Linear: 3-30                      (recursive)
â”‚    â””â”€LSTM: 2-9                              (recursive)
â”œâ”€MlpExtractor: 1-4                           --
â”‚    â””â”€Sequential: 2-10                       --
â”‚    â”‚    â””â”€Linear: 3-31                      16,448
â”‚    â”‚    â””â”€Tanh: 3-32                        --
â”‚    â”‚    â””â”€Linear: 3-33                      4,160
â”‚    â”‚    â””â”€Tanh: 3-34                        --
â”‚    â””â”€Sequential: 2-11                       --
â”‚    â”‚    â””â”€Linear: 3-35                      16,448
â”‚    â”‚    â””â”€Tanh: 3-36                        --
â”‚    â”‚    â””â”€Linear: 3-37                      4,160
â”‚    â”‚    â””â”€Tanh: 3-38                        --
â”œâ”€Linear: 1-5                                 61,230
â”œâ”€Linear: 1-6                                 65
â”œâ”€LSTM: 1-7                                   272,384
â”œâ”€LSTM: 1-8                                   272,384
======================================================================
Total params: 706,576
Trainable params: 647,279
Non-trainable params: 59,297
======================================================================
Logging to ./chess_logs/7_LSTM_Autoencoder_MaskableRecurrentPPO_3
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3100     |
|    invalid_moves   | 0        |
|    losses          | 1519     |
|    valid_moves     | 60000    |
|    win_rate        | 0.51     |
|    wins            | 1581     |
| rollout/           |          |
|    ep_len_mean     | 17.6     |
|    ep_rew_mean     | 4.12     |
| time/              |          |
|    fps             | 2049     |
|    iterations      | 1        |
|    time_elapsed    | 31       |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 6771         |
|    invalid_moves        | 0            |
|    losses               | 3339         |
|    valid_moves          | 130000       |
|    win_rate             | 0.507        |
|    wins                 | 3432         |
| rollout/                |              |
|    ep_len_mean          | 18.2         |
|    ep_rew_mean          | -1.92        |
| time/                   |              |
|    fps                  | 1470         |
|    iterations           | 2            |
|    time_elapsed         | 89           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 5.065233e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 4.11e-06     |
|    learning_rate        | 0.0001       |
|    loss                 | 728          |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000877    |
|    value_loss           | 1.46e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9890          |
|    invalid_moves        | 0             |
|    losses               | 4795          |
|    valid_moves          | 190000        |
|    win_rate             | 0.515         |
|    wins                 | 5095          |
| rollout/                |               |
|    ep_len_mean          | 20.9          |
|    ep_rew_mean          | 25.2          |
| time/                   |               |
|    fps                  | 1347          |
|    iterations           | 3             |
|    time_elapsed         | 145           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00050225324 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | 7.68e-05      |
|    learning_rate        | 0.0001        |
|    loss                 | 733           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00255      |
|    value_loss           | 1.48e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13748        |
|    invalid_moves        | 0            |
|    losses               | 6374         |
|    valid_moves          | 260000       |
|    win_rate             | 0.536        |
|    wins                 | 7374         |
| rollout/                |              |
|    ep_len_mean          | 17.8         |
|    ep_rew_mean          | 37.2         |
| time/                   |              |
|    fps                  | 1292         |
|    iterations           | 4            |
|    time_elapsed         | 202          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0070872814 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.000139     |
|    learning_rate        | 0.0001       |
|    loss                 | 737          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00868     |
|    value_loss           | 1.46e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 17337       |
|    invalid_moves        | 0           |
|    losses               | 7529        |
|    valid_moves          | 320000      |
|    win_rate             | 0.566       |
|    wins                 | 9808        |
| rollout/                |             |
|    ep_len_mean          | 17.6        |
|    ep_rew_mean          | 61.8        |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 5           |
|    time_elapsed         | 260         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.009288129 |
|    clip_fraction        | 0.037       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.55       |
|    explained_variance   | 0.000596    |
|    learning_rate        | 0.0001      |
|    loss                 | 816         |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 1.56e+03    |
-----------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 21799       |
|    invalid_moves        | 0           |
|    losses               | 8774        |
|    valid_moves          | 390000      |
|    win_rate             | 0.598       |
|    wins                 | 13025       |
| rollout/                |             |
|    ep_len_mean          | 18.1        |
|    ep_rew_mean          | 96.6        |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 6           |
|    time_elapsed         | 320         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.004105857 |
|    clip_fraction        | 0.00542     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.5        |
|    explained_variance   | 0.00242     |
|    learning_rate        | 0.0001      |
|    loss                 | 818         |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00995    |
|    value_loss           | 1.66e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 25867        |
|    invalid_moves        | 0            |
|    losses               | 9761         |
|    valid_moves          | 450000       |
|    win_rate             | 0.623        |
|    wins                 | 16106        |
| rollout/                |              |
|    ep_len_mean          | 14.1         |
|    ep_rew_mean          | 103          |
| time/                   |              |
|    fps                  | 1199         |
|    iterations           | 7            |
|    time_elapsed         | 382          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0023449895 |
|    clip_fraction        | 0.000418     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.00566      |
|    learning_rate        | 0.0001       |
|    loss                 | 862          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.0111      |
|    value_loss           | 1.76e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 30741       |
|    invalid_moves        | 0           |
|    losses               | 10844       |
|    valid_moves          | 520000      |
|    win_rate             | 0.647       |
|    wins                 | 19897       |
| rollout/                |             |
|    ep_len_mean          | 15.2        |
|    ep_rew_mean          | 93.3        |
| time/                   |             |
|    fps                  | 1177        |
|    iterations           | 8           |
|    time_elapsed         | 445         |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.001203641 |
|    clip_fraction        | 1.53e-06    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.43       |
|    explained_variance   | 0.00764     |
|    learning_rate        | 0.0001      |
|    loss                 | 923         |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0078     |
|    value_loss           | 1.84e+03    |
-----------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 35147         |
|    invalid_moves        | 0             |
|    losses               | 11727         |
|    valid_moves          | 580000        |
|    win_rate             | 0.666         |
|    wins                 | 23420         |
| rollout/                |               |
|    ep_len_mean          | 13.5          |
|    ep_rew_mean          | 121           |
| time/                   |               |
|    fps                  | 1160          |
|    iterations           | 9             |
|    time_elapsed         | 508           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 0.00091490103 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.41         |
|    explained_variance   | 0.00982       |
|    learning_rate        | 0.0001        |
|    loss                 | 963           |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.00744      |
|    value_loss           | 1.89e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 40442        |
|    invalid_moves        | 0            |
|    losses               | 12670        |
|    valid_moves          | 650000       |
|    win_rate             | 0.687        |
|    wins                 | 27772        |
| rollout/                |              |
|    ep_len_mean          | 13.1         |
|    ep_rew_mean          | 119          |
| time/                   |              |
|    fps                  | 1143         |
|    iterations           | 10           |
|    time_elapsed         | 573          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0008149943 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.0113       |
|    learning_rate        | 0.0001       |
|    loss                 | 957          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00694     |
|    value_loss           | 1.97e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 45936        |
|    invalid_moves        | 0            |
|    losses               | 13605        |
|    valid_moves          | 720000       |
|    win_rate             | 0.704        |
|    wins                 | 32331        |
| rollout/                |              |
|    ep_len_mean          | 12.5         |
|    ep_rew_mean          | 90.8         |
| time/                   |              |
|    fps                  | 1127         |
|    iterations           | 11           |
|    time_elapsed         | 639          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0007882265 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.0121       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.01e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00693     |
|    value_loss           | 2.02e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 50805        |
|    invalid_moves        | 0            |
|    losses               | 14407        |
|    valid_moves          | 780000       |
|    win_rate             | 0.716        |
|    wins                 | 36398        |
| rollout/                |              |
|    ep_len_mean          | 11.2         |
|    ep_rew_mean          | 119          |
| time/                   |              |
|    fps                  | 1114         |
|    iterations           | 12           |
|    time_elapsed         | 705          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0008801371 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.0114       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.06e+03     |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00716     |
|    value_loss           | 2.09e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 56847       |
|    invalid_moves        | 0           |
|    losses               | 15321       |
|    valid_moves          | 850000      |
|    win_rate             | 0.73        |
|    wins                 | 41526       |
| rollout/                |             |
|    ep_len_mean          | 12          |
|    ep_rew_mean          | 116         |
| time/                   |             |
|    fps                  | 1099        |
|    iterations           | 13          |
|    time_elapsed         | 774         |
|    total_timesteps      | 851968      |
| train/                  |             |
|    approx_kl            | 0.000624818 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.31       |
|    explained_variance   | 0.0121      |
|    learning_rate        | 0.0001      |
|    loss                 | 1.08e+03    |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00623    |
|    value_loss           | 2.15e+03    |
-----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 62309        |
|    invalid_moves        | 0            |
|    losses               | 16082        |
|    valid_moves          | 910000       |
|    win_rate             | 0.742        |
|    wins                 | 46227        |
| rollout/                |              |
|    ep_len_mean          | 11.4         |
|    ep_rew_mean          | 115          |
| time/                   |              |
|    fps                  | 1087         |
|    iterations           | 14           |
|    time_elapsed         | 843          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0008872585 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.0129       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.17e+03     |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00735     |
|    value_loss           | 2.26e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 68794        |
|    invalid_moves        | 0            |
|    losses               | 16863        |
|    valid_moves          | 980000       |
|    win_rate             | 0.755        |
|    wins                 | 51931        |
| rollout/                |              |
|    ep_len_mean          | 10.4         |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 1074         |
|    iterations           | 15           |
|    time_elapsed         | 915          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0008115856 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.014        |
|    learning_rate        | 0.0001       |
|    loss                 | 1.18e+03     |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00726     |
|    value_loss           | 2.37e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 74527        |
|    invalid_moves        | 0            |
|    losses               | 17542        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.765        |
|    wins                 | 56985        |
| rollout/                |              |
|    ep_len_mean          | 10.8         |
|    ep_rew_mean          | 143          |
| time/                   |              |
|    fps                  | 1062         |
|    iterations           | 16           |
|    time_elapsed         | 987          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0007483843 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.0145       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.17e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00672     |
|    value_loss           | 2.38e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/7_LSTM_Autoencoder_MaskableRecurrentPPO_20250805_035139.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 7_LSTM_Autoencoder_MaskableRecurrentPPO agent...
[0;36m-> Mean Reward: 149.62 +/- 60.95[0m
[0;37mParsed arguments:[0m
[0;37m   agent_name: 8_Naive_Transformer_PPO[0m
[0;37m   model_path: models/8_Naive_Transformer_PPO_20250805_040900.zip[0m
[0;37m   log_dir: ./chess_logs[0m
[0;37m   total_timesteps: 1000000[0m
[0;37m   n_envs: 16[0m
[0;37m   n_steps: 4096[0m
[0;37m   batch_size: 16384[0m
[0;37m   n_epochs: 10[0m
[0;37m   n_samples_ae: 1000000[0m
[0;37m   n_epochs_ae: 20[0m
[0;37m   force_clean_ae: False[0m
[0;37m   share_features_extractor: True[0m
[0;37m   print_model_only: False[0m
Training '8_Naive_Transformer_PPO' agent using device 'cuda' and '16' parallel environments...
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:214: UserWarning: constant_fn() is deprecated, please use ConstantSchedule() instead
  warnings.warn("constant_fn() is deprecated, please use ConstantSchedule() instead")
[0;35m-> share_features_extractor: True[0m
Using cuda device
[0;36m-> Model summary:[0m
=====================================================================================
Layer (type:depth-idx)                                       Param #
=====================================================================================
MaskableMultiInputActorCriticPolicy                          --
â”œâ”€TransformerFeatureExtractor: 1-1                           --
â”‚    â””â”€TinyGPT2Encoder: 2-1                                  --
â”‚    â”‚    â””â”€GPT2Model: 3-1                                   108,096
â”‚    â””â”€Linear: 2-2                                           1,664
â”œâ”€TransformerFeatureExtractor: 1-2                           (recursive)
â”‚    â””â”€TinyGPT2Encoder: 2-3                                  (recursive)
â”‚    â”‚    â””â”€GPT2Model: 3-2                                   (recursive)
â”‚    â””â”€Linear: 2-4                                           (recursive)
â”œâ”€TransformerFeatureExtractor: 1-3                           (recursive)
â”‚    â””â”€TinyGPT2Encoder: 2-5                                  (recursive)
â”‚    â”‚    â””â”€GPT2Model: 3-3                                   (recursive)
â”‚    â””â”€Linear: 2-6                                           (recursive)
â”œâ”€MlpExtractor: 1-4                                          --
â”‚    â””â”€Sequential: 2-7                                       --
â”‚    â”‚    â””â”€Linear: 3-4                                      4,160
â”‚    â”‚    â””â”€Tanh: 3-5                                        --
â”‚    â”‚    â””â”€Linear: 3-6                                      4,160
â”‚    â”‚    â””â”€Tanh: 3-7                                        --
â”‚    â””â”€Sequential: 2-8                                       --
â”‚    â”‚    â””â”€Linear: 3-8                                      4,160
â”‚    â”‚    â””â”€Tanh: 3-9                                        --
â”‚    â”‚    â””â”€Linear: 3-10                                     4,160
â”‚    â”‚    â””â”€Tanh: 3-11                                       --
â”œâ”€Linear: 1-5                                                61,230
â”œâ”€Linear: 1-6                                                65
=====================================================================================
Total params: 187,695
Trainable params: 187,695
Non-trainable params: 0
=====================================================================================
Logging to ./chess_logs/8_Naive_Transformer_PPO_3
---------------------------------
| custom/            |          |
|    draws           | 0        |
|    episodes        | 3121     |
|    invalid_moves   | 0        |
|    losses          | 1551     |
|    valid_moves     | 60000    |
|    win_rate        | 0.503    |
|    wins            | 1570     |
| rollout/           |          |
|    ep_len_mean     | 19.9     |
|    ep_rew_mean     | -14.1    |
| time/              |          |
|    fps             | 1849     |
|    iterations      | 1        |
|    time_elapsed    | 35       |
|    total_timesteps | 65536    |
---------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 6750          |
|    invalid_moves        | 0             |
|    losses               | 3263          |
|    valid_moves          | 130000        |
|    win_rate             | 0.517         |
|    wins                 | 3487          |
| rollout/                |               |
|    ep_len_mean          | 21.1          |
|    ep_rew_mean          | 2.3           |
| time/                   |               |
|    fps                  | 1776          |
|    iterations           | 2             |
|    time_elapsed         | 73            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 0.00038147852 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.58         |
|    explained_variance   | -0.00248      |
|    learning_rate        | 0.0001        |
|    loss                 | 744           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.00387      |
|    value_loss           | 1.47e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 9874          |
|    invalid_moves        | 0             |
|    losses               | 4673          |
|    valid_moves          | 190000        |
|    win_rate             | 0.527         |
|    wins                 | 5201          |
| rollout/                |               |
|    ep_len_mean          | 18.5          |
|    ep_rew_mean          | 24.9          |
| time/                   |               |
|    fps                  | 1756          |
|    iterations           | 3             |
|    time_elapsed         | 111           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00042986745 |
|    clip_fraction        | 4.58e-06      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.6          |
|    explained_variance   | -7.89e-05     |
|    learning_rate        | 0.0001        |
|    loss                 | 713           |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00396      |
|    value_loss           | 1.46e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 13653        |
|    invalid_moves        | 0            |
|    losses               | 6283         |
|    valid_moves          | 260000       |
|    win_rate             | 0.54         |
|    wins                 | 7370         |
| rollout/                |              |
|    ep_len_mean          | 18.8         |
|    ep_rew_mean          | 49           |
| time/                   |              |
|    fps                  | 1743         |
|    iterations           | 4            |
|    time_elapsed         | 150          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0006419808 |
|    clip_fraction        | 0.000243     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.00201      |
|    learning_rate        | 0.0001       |
|    loss                 | 724          |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00444     |
|    value_loss           | 1.46e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 16949        |
|    invalid_moves        | 0            |
|    losses               | 7532         |
|    valid_moves          | 320000       |
|    win_rate             | 0.556        |
|    wins                 | 9417         |
| rollout/                |              |
|    ep_len_mean          | 19           |
|    ep_rew_mean          | 1.41         |
| time/                   |              |
|    fps                  | 1735         |
|    iterations           | 5            |
|    time_elapsed         | 188          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0008743968 |
|    clip_fraction        | 0.000652     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.0041       |
|    learning_rate        | 0.0001       |
|    loss                 | 727          |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00484     |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 21032        |
|    invalid_moves        | 0            |
|    losses               | 8916         |
|    valid_moves          | 390000       |
|    win_rate             | 0.576        |
|    wins                 | 12116        |
| rollout/                |              |
|    ep_len_mean          | 16.1         |
|    ep_rew_mean          | 46           |
| time/                   |              |
|    fps                  | 1727         |
|    iterations           | 6            |
|    time_elapsed         | 227          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0012673952 |
|    clip_fraction        | 0.0014       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.00504      |
|    learning_rate        | 0.0001       |
|    loss                 | 760          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00553     |
|    value_loss           | 1.53e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 24888        |
|    invalid_moves        | 0            |
|    losses               | 10065        |
|    valid_moves          | 450000       |
|    win_rate             | 0.596        |
|    wins                 | 14823        |
| rollout/                |              |
|    ep_len_mean          | 18.2         |
|    ep_rew_mean          | 47           |
| time/                   |              |
|    fps                  | 1719         |
|    iterations           | 7            |
|    time_elapsed         | 266          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0014409765 |
|    clip_fraction        | 0.0015       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.00617      |
|    learning_rate        | 0.0001       |
|    loss                 | 805          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00555     |
|    value_loss           | 1.64e+03     |
------------------------------------------
-----------------------------------------
| custom/                 |             |
|    draws                | 0           |
|    episodes             | 29720       |
|    invalid_moves        | 0           |
|    losses               | 11263       |
|    valid_moves          | 520000      |
|    win_rate             | 0.621       |
|    wins                 | 18457       |
| rollout/                |             |
|    ep_len_mean          | 13.8        |
|    ep_rew_mean          | 94.6        |
| time/                   |             |
|    fps                  | 1708        |
|    iterations           | 8           |
|    time_elapsed         | 306         |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.001950199 |
|    clip_fraction        | 0.00332     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.51       |
|    explained_variance   | 0.00716     |
|    learning_rate        | 0.0001      |
|    loss                 | 919         |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00697    |
|    value_loss           | 1.77e+03    |
-----------------------------------------
----------------------------------------
| custom/                 |            |
|    draws                | 0          |
|    episodes             | 34245      |
|    invalid_moves        | 0          |
|    losses               | 12215      |
|    valid_moves          | 580000     |
|    win_rate             | 0.643      |
|    wins                 | 22030      |
| rollout/                |            |
|    ep_len_mean          | 12.9       |
|    ep_rew_mean          | 96.1       |
| time/                   |            |
|    fps                  | 1700       |
|    iterations           | 9          |
|    time_elapsed         | 346        |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.00177958 |
|    clip_fraction        | 0.00149    |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.47      |
|    explained_variance   | 0.00733    |
|    learning_rate        | 0.0001     |
|    loss                 | 961        |
|    n_updates            | 80         |
|    policy_gradient_loss | -0.00632   |
|    value_loss           | 1.91e+03   |
----------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 39906        |
|    invalid_moves        | 0            |
|    losses               | 13255        |
|    valid_moves          | 650000       |
|    win_rate             | 0.668        |
|    wins                 | 26651        |
| rollout/                |              |
|    ep_len_mean          | 12.2         |
|    ep_rew_mean          | 101          |
| time/                   |              |
|    fps                  | 1692         |
|    iterations           | 10           |
|    time_elapsed         | 387          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0018797235 |
|    clip_fraction        | 0.00126      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.00605      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.01e+03     |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00652     |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 46206        |
|    invalid_moves        | 0            |
|    losses               | 14242        |
|    valid_moves          | 720000       |
|    win_rate             | 0.692        |
|    wins                 | 31964        |
| rollout/                |              |
|    ep_len_mean          | 11           |
|    ep_rew_mean          | 120          |
| time/                   |              |
|    fps                  | 1683         |
|    iterations           | 11           |
|    time_elapsed         | 428          |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0016023499 |
|    clip_fraction        | 0.00103      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.00898      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.07e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00544     |
|    value_loss           | 2.19e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 52015        |
|    invalid_moves        | 0            |
|    losses               | 15044        |
|    valid_moves          | 780000       |
|    win_rate             | 0.711        |
|    wins                 | 36971        |
| rollout/                |              |
|    ep_len_mean          | 10.3         |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 1675         |
|    iterations           | 12           |
|    time_elapsed         | 469          |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0012016093 |
|    clip_fraction        | 0.000893     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.0096       |
|    learning_rate        | 0.0001       |
|    loss                 | 1.19e+03     |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.0033      |
|    value_loss           | 2.39e+03     |
------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 59026         |
|    invalid_moves        | 0             |
|    losses               | 15933         |
|    valid_moves          | 850000        |
|    win_rate             | 0.73          |
|    wins                 | 43093         |
| rollout/                |               |
|    ep_len_mean          | 9.77          |
|    ep_rew_mean          | 133           |
| time/                   |               |
|    fps                  | 1668          |
|    iterations           | 13            |
|    time_elapsed         | 510           |
|    total_timesteps      | 851968        |
| train/                  |               |
|    approx_kl            | 0.00096866983 |
|    clip_fraction        | 0.00118       |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.27         |
|    explained_variance   | 0.0101        |
|    learning_rate        | 0.0001        |
|    loss                 | 1.29e+03      |
|    n_updates            | 120           |
|    policy_gradient_loss | -0.00205      |
|    value_loss           | 2.52e+03      |
-------------------------------------------
-------------------------------------------
| custom/                 |               |
|    draws                | 0             |
|    episodes             | 65367         |
|    invalid_moves        | 0             |
|    losses               | 16640         |
|    valid_moves          | 910000        |
|    win_rate             | 0.745         |
|    wins                 | 48727         |
| rollout/                |               |
|    ep_len_mean          | 9.08          |
|    ep_rew_mean          | 127           |
| time/                   |               |
|    fps                  | 1660          |
|    iterations           | 14            |
|    time_elapsed         | 552           |
|    total_timesteps      | 917504        |
| train/                  |               |
|    approx_kl            | 0.00086544175 |
|    clip_fraction        | 0.00131       |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.23         |
|    explained_variance   | 0.00932       |
|    learning_rate        | 0.0001        |
|    loss                 | 1.32e+03      |
|    n_updates            | 130           |
|    policy_gradient_loss | -0.00125      |
|    value_loss           | 2.62e+03      |
-------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 73084        |
|    invalid_moves        | 0            |
|    losses               | 17438        |
|    valid_moves          | 980000       |
|    win_rate             | 0.761        |
|    wins                 | 55646        |
| rollout/                |              |
|    ep_len_mean          | 8.81         |
|    ep_rew_mean          | 136          |
| time/                   |              |
|    fps                  | 1653         |
|    iterations           | 15           |
|    time_elapsed         | 594          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0007303759 |
|    clip_fraction        | 0.00154      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.01         |
|    learning_rate        | 0.0001       |
|    loss                 | 1.39e+03     |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.000468    |
|    value_loss           | 2.75e+03     |
------------------------------------------
------------------------------------------
| custom/                 |              |
|    draws                | 0            |
|    episodes             | 80034        |
|    invalid_moves        | 0            |
|    losses               | 18129        |
|    valid_moves          | 1040000      |
|    win_rate             | 0.773        |
|    wins                 | 61905        |
| rollout/                |              |
|    ep_len_mean          | 8.8          |
|    ep_rew_mean          | 137          |
| time/                   |              |
|    fps                  | 1647         |
|    iterations           | 16           |
|    time_elapsed         | 636          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0006948339 |
|    clip_fraction        | 0.00188      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.00891      |
|    learning_rate        | 0.0001       |
|    loss                 | 1.4e+03      |
|    n_updates            | 150          |
|    policy_gradient_loss | -6.74e-05    |
|    value_loss           | 2.83e+03     |
------------------------------------------
/home/herreramaxi/miniconda3/envs/gymnasium-env/lib/python3.11/site-packages/stable_baselines3/common/utils.py:168: UserWarning: get_schedule_fn() is deprecated, please use FloatSchedule() instead
  warnings.warn("get_schedule_fn() is deprecated, please use FloatSchedule() instead")
[0;32m-> Model saved on models/8_Naive_Transformer_PPO_20250805_040900.zip[0m
Initializing MiniChessEnv: 5x5 board with invalid action masking =True, original_step=False
Evaluating 8_Naive_Transformer_PPO agent...
[0;36m-> Mean Reward: 161.12 +/- 1.98[0m
[0;36m-> Starting experiments...[0m
[0;37mParsed arguments:[0m
[0;37m  parallel: False[0m
[0;37m  max_workers: 3[0m
[0;37m  num_repeats: 3[0m
[0;37mArguments to be forwarded: ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;36m-> Running Preprocessing Tasks...[0m
[0;35m-> Running script: ae_pretrain.py with args ['--n-samples', '100000', '--n-epochs', '20', '--force-clean', 'False'][0m
[0;32m-> [ae_pretrain.py] Finished in 3.0s[0m
[0;35m-> Running script: ae_rnn_pretrain.py with args ['--n-samples', '100000', '--n-epochs', '20', '--force-clean', 'False'][0m
[0;32m-> [ae_rnn_pretrain.py] Finished in 2.7s[0m
[0;35m-> Running experiments, num_repeats: 3, mode: Sequential[0m
[0;36m-> Iteration: 1[0m
[0;35m-> Running script: Chess_1_PPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_1_PPO.py] Finished in 226.6s[0m
[0;35m-> Running script: Chess_2_MaskablePPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_2_MaskablePPO.py] Finished in 475.6s[0m
[0;35m-> Running script: Chess_3_MaskableRecurrentPPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_3_MaskableRecurrentPPO.py] Finished in 889.9s[0m
[0;35m-> Running script: Chess_4_FF_AutoEncoder_MaskablePPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_4_FF_AutoEncoder_MaskablePPO.py] Finished in 491.0s[0m
[0;35m-> Running script: Chess_5_FF_Autoencoder_MaskableRecurrentPPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_5_FF_Autoencoder_MaskableRecurrentPPO.py] Finished in 1026.3s[0m
[0;35m-> Running script: Chess_6_LSTM_Autoencoder_MaskablePPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_6_LSTM_Autoencoder_MaskablePPO.py] Finished in 497.2s[0m
[0;35m-> Running script: Chess_7_LSTM_Autoencoder_MaskableRecurrentPPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_7_LSTM_Autoencoder_MaskableRecurrentPPO.py] Finished in 1054.9s[0m
[0;35m-> Running script: Chess_8_Transformer.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_8_Transformer.py] Finished in 653.2s[0m
[0;36m-> Iteration 1 has completed in 88.58 minutes (5314.6s)[0m
[0;36m-> Iteration: 2[0m
[0;35m-> Running script: Chess_1_PPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_1_PPO.py] Finished in 225.0s[0m
[0;35m-> Running script: Chess_2_MaskablePPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_2_MaskablePPO.py] Finished in 479.0s[0m
[0;35m-> Running script: Chess_3_MaskableRecurrentPPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_3_MaskableRecurrentPPO.py] Finished in 883.9s[0m
[0;35m-> Running script: Chess_4_FF_AutoEncoder_MaskablePPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_4_FF_AutoEncoder_MaskablePPO.py] Finished in 490.7s[0m
[0;35m-> Running script: Chess_5_FF_Autoencoder_MaskableRecurrentPPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_5_FF_Autoencoder_MaskableRecurrentPPO.py] Finished in 1024.6s[0m
[0;35m-> Running script: Chess_6_LSTM_Autoencoder_MaskablePPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_6_LSTM_Autoencoder_MaskablePPO.py] Finished in 493.8s[0m
[0;35m-> Running script: Chess_7_LSTM_Autoencoder_MaskableRecurrentPPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_7_LSTM_Autoencoder_MaskableRecurrentPPO.py] Finished in 1042.7s[0m
[0;35m-> Running script: Chess_8_Transformer.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_8_Transformer.py] Finished in 652.7s[0m
[0;36m-> Iteration 2 has completed in 88.21 minutes (5292.3s)[0m
[0;36m-> Iteration: 3[0m
[0;35m-> Running script: Chess_1_PPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_1_PPO.py] Finished in 225.5s[0m
[0;35m-> Running script: Chess_2_MaskablePPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_2_MaskablePPO.py] Finished in 469.5s[0m
[0;35m-> Running script: Chess_3_MaskableRecurrentPPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_3_MaskableRecurrentPPO.py] Finished in 881.4s[0m
[0;35m-> Running script: Chess_4_FF_AutoEncoder_MaskablePPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_4_FF_AutoEncoder_MaskablePPO.py] Finished in 490.1s[0m
[0;35m-> Running script: Chess_5_FF_Autoencoder_MaskableRecurrentPPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_5_FF_Autoencoder_MaskableRecurrentPPO.py] Finished in 1017.0s[0m
[0;35m-> Running script: Chess_6_LSTM_Autoencoder_MaskablePPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_6_LSTM_Autoencoder_MaskablePPO.py] Finished in 497.0s[0m
[0;35m-> Running script: Chess_7_LSTM_Autoencoder_MaskableRecurrentPPO.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_7_LSTM_Autoencoder_MaskableRecurrentPPO.py] Finished in 1038.9s[0m
[0;35m-> Running script: Chess_8_Transformer.py with args ['--n-envs', '16', '--total-timesteps', '1000000', '--batch-size', '16384', '--n-steps', '4096', '--n-epochs', '10', '--share-features-extractor'][0m
[0;32m-> [Chess_8_Transformer.py] Finished in 655.1s[0m
[0;36m-> Iteration 3 has completed in 87.91 minutes (5274.6s)[0m
[0;32m-> Experiments have completed in 264.69 minutes (15881.5s)[0m
[0;32m-> All done in 264.79 minutes (15887.2s)[0m
